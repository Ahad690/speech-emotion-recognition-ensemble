{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-26T13:07:00.912294Z","iopub.execute_input":"2025-10-26T13:07:00.913084Z","iopub.status.idle":"2025-10-26T13:07:00.917567Z","shell.execute_reply.started":"2025-10-26T13:07:00.913048Z","shell.execute_reply":"2025-10-26T13:07:00.916913Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"# ============================================\n# CELL 1: Setup and Installation\n# ============================================","metadata":{}},{"cell_type":"code","source":"# ============================================\n# CELL 1: Setup and Installation (FINAL VERSION)\n# ============================================\n\"\"\"\nSpeech Emotion Recognition System\nFor: Speech Processing & ANN/DL Course\nAuthor: Ahad Imran\n\"\"\"\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Check what's already installed\nimport sys\nprint(f\"Python: {sys.version}\")\n\n# Check librosa\ntry:\n    import librosa\n    print(f\"‚úì librosa {librosa.__version__}\")\nexcept:\n    print(\"Installing librosa...\")\n    !pip install -q librosa\n\n# Skip audiomentations - not critical, we have built-in augmentation\n\n# Import all required packages\nimport os\nimport gc\nimport random\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom pathlib import Path\nfrom tqdm.auto import tqdm\nfrom typing import Dict, List, Tuple, Optional\nimport pickle\nimport json\nfrom collections import Counter\n\n# Audio processing\nimport librosa\nimport librosa.display\nimport soundfile as sf\nimport IPython.display as ipd\n\n# Deep Learning\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader, random_split\nimport torchaudio\nimport torchaudio.transforms as T\n\n# Machine Learning\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Visualization\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\n# Set seeds\ndef set_seed(seed=42):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n\nset_seed(42)\n\n# Check GPU\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"\\nUsing device: {device}\")\nif torch.cuda.is_available():\n    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n\nprint(\"\\n Setup complete! Ready to proceed.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T13:30:54.049787Z","iopub.execute_input":"2025-10-26T13:30:54.050724Z","iopub.status.idle":"2025-10-26T13:30:54.066570Z","shell.execute_reply.started":"2025-10-26T13:30:54.050690Z","shell.execute_reply":"2025-10-26T13:30:54.065786Z"}},"outputs":[{"name":"stdout","text":"Python: 3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]\n‚úì librosa 0.11.0\n\nUsing device: cuda\nGPU: Tesla T4\nMemory: 15.83 GB\n\n Setup complete! Ready to proceed.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"# ============================================\n# CELL 1a: Setup for Dual T4 GPUs\n# ============================================","metadata":{}},{"cell_type":"code","source":"from torch.nn.parallel import DataParallel\n\n# Check available GPUs\nprint(f\"GPUs available: {torch.cuda.device_count()}\")\nfor i in range(torch.cuda.device_count()):\n    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n    print(f\"Memory: {torch.cuda.get_device_properties(i).total_memory / 1e9:.2f} GB\")\n\nif torch.cuda.device_count() > 1:\n    print(\"\\n‚úÖ Multiple GPUs detected! Will use DataParallel for faster training.\")\nelse:\n    print(\"\\n‚úÖ Single GPU detected. Will proceed with standard training.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T13:31:13.266703Z","iopub.execute_input":"2025-10-26T13:31:13.267003Z","iopub.status.idle":"2025-10-26T13:31:13.272492Z","shell.execute_reply.started":"2025-10-26T13:31:13.266982Z","shell.execute_reply":"2025-10-26T13:31:13.271929Z"}},"outputs":[{"name":"stdout","text":"GPUs available: 2\nGPU 0: Tesla T4\nMemory: 15.83 GB\nGPU 1: Tesla T4\nMemory: 15.83 GB\n\n‚úÖ Multiple GPUs detected! Will use DataParallel for faster training.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"# ============================================\n# CELL 2: Download and Prepare Datasets\n# ============================================","metadata":{}},{"cell_type":"markdown","source":"To set up environment variables for the Kaggle API using Python, you can use the `os` module to assign your credentials directly in your script. This is especially useful when you don‚Äôt want to rely on a `kaggle.json` file. Here's how to do it:\n\n---\n\n### üîë Step-by-Step: Set Kaggle API Key with `os.environ`\n\n```python\nimport os\n\n# Set your Kaggle credentials\nos.environ['KAGGLE_USERNAME'] = 'your_kaggle_username'\nos.environ['KAGGLE_KEY'] = 'your_kaggle_api_key'\n```\n\nReplace `'your_kaggle_username'` and `'your_kaggle_api_key'` with the actual values from your [Kaggle account settings](https://www.kaggle.com/settings).\n\n---\n\n### üì¶ Then You Can Download Datasets Like This\n\n```python\n!pip install kaggle\n\n# Example: Download Titanic dataset\n!kaggle competitions download -c titanic\n```\n\nThis will work in environments like Jupyter, Colab, or Kaggle Notebooks ‚Äî as long as the API key is valid and you've accepted the competition rules (if required).\n\n## Usage Example\n```python\n# !kaggle competitions download -c titanic\n\n\n# import zipfile\n\n# with zipfile.ZipFile('/kaggle/working/titanic.zip', 'r') as zip_ref:\n#    zip_ref.extractall('/kaggle/working')\n```","metadata":{}},{"cell_type":"code","source":"\"\"\"\nUsing Kaggle datasets for emotion recognition\n\"\"\"\n\nimport os\nimport zipfile\nfrom pathlib import Path\n\n# Setup Kaggle API credentials using Secrets\ntry:\n    from kaggle_secrets import UserSecretsClient\n    user_secrets = UserSecretsClient()\n    \n    os.environ['KAGGLE_USERNAME'] = user_secrets.get_secret(\"kaggle_username\")\n    os.environ['KAGGLE_KEY'] = user_secrets.get_secret(\"kaggle_key\")\n    \n    print(\"‚úì Kaggle API configured with secrets\")\n    api_available = True\nexcept Exception as e:\n    print(f\"‚ö†Ô∏è Kaggle secrets not found: {e}\")\n    print(\"Please add datasets via 'Add Data' button or configure secrets.\")\n    api_available = False\n\n# Create directory structure\nos.makedirs('/kaggle/working/data', exist_ok=True)\nos.makedirs('/kaggle/working/models', exist_ok=True)\nos.makedirs('/kaggle/working/results', exist_ok=True)\n\n# Check if datasets are already added via UI\ndatasets_found = False\nif os.path.exists('/kaggle/input/'):\n    input_datasets = os.listdir('/kaggle/input/')\n    if len(input_datasets) > 0:\n        print(\"Datasets found in /kaggle/input/:\")\n        for dataset in input_datasets:\n            print(f\"  ‚úì {dataset}\")\n        datasets_found = True\n        DATA_PATH = '/kaggle/input/'\n\n# Method 2: Download if not added via UI (only if API is available)\nif not datasets_found and api_available:  # <-- FIXED: Added api_available check\n    print(\"\\nNo datasets found in input. Downloading...\")\n    \n    # Only download if not already present\n    if not os.path.exists('/kaggle/working/ravdess'):\n        print(\"Downloading RAVDESS...\")\n        !kaggle datasets download -d uwrfkaggler/ravdess-emotional-speech-audio -p /kaggle/working --quiet\n        \n        if os.path.exists('/kaggle/working/ravdess-emotional-speech-audio.zip'):\n            with zipfile.ZipFile('/kaggle/working/ravdess-emotional-speech-audio.zip', 'r') as zip_ref:\n                zip_ref.extractall('/kaggle/working/ravdess')\n            os.remove('/kaggle/working/ravdess-emotional-speech-audio.zip')\n            print(\"‚úì RAVDESS downloaded\")\n    \n    if not os.path.exists('/kaggle/working/tess'):\n        print(\"Downloading TESS...\")\n        !kaggle datasets download -d ejlok1/toronto-emotional-speech-set-tess -p /kaggle/working --quiet\n        \n        if os.path.exists('/kaggle/working/toronto-emotional-speech-set-tess.zip'):\n            with zipfile.ZipFile('/kaggle/working/toronto-emotional-speech-set-tess.zip', 'r') as zip_ref:\n                zip_ref.extractall('/kaggle/working/tess')\n            os.remove('/kaggle/working/toronto-emotional-speech-set-tess.zip')\n            print(\"‚úì TESS downloaded\")\n    \n    if not os.path.exists('/kaggle/working/cremad'):\n        print(\"Downloading CREMA-D...\")\n        !kaggle datasets download -d ejlok1/cremad -p /kaggle/working --quiet\n        \n        if os.path.exists('/kaggle/working/cremad.zip'):\n            with zipfile.ZipFile('/kaggle/working/cremad.zip', 'r') as zip_ref:\n                zip_ref.extractall('/kaggle/working/cremad')\n            os.remove('/kaggle/working/cremad.zip')\n            print(\"‚úì CREMA-D downloaded\")\n    \n    DATA_PATH = '/kaggle/working/'\n\nelif not datasets_found and not api_available:\n    print(\"\\n‚ö†Ô∏è No datasets found and API not configured.\")\n    print(\"Please either:\")\n    print(\"1. Add datasets using the 'Add Data' button, or\")\n    print(\"2. Configure Kaggle API secrets (kaggle_username and kaggle_key)\")\n    DATA_PATH = '/kaggle/working/'  # Set default path anyway\n\nelse:\n    # Datasets already found\n    pass\n\n# Verify final state\nprint(f\"\\nUsing DATA_PATH: {DATA_PATH}\")\nif os.path.exists(DATA_PATH):\n    contents = os.listdir(DATA_PATH)\n    if contents:\n        print(f\"Found {len(contents)} items in {DATA_PATH}\")\n    else:\n        print(\"‚ö†Ô∏è DATA_PATH is empty. Please add datasets.\")\n\nprint(\"\\n Setup complete!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T13:44:38.561959Z","iopub.execute_input":"2025-10-26T13:44:38.562605Z","iopub.status.idle":"2025-10-26T13:45:08.107276Z","shell.execute_reply.started":"2025-10-26T13:44:38.562580Z","shell.execute_reply":"2025-10-26T13:45:08.106270Z"}},"outputs":[{"name":"stdout","text":"‚úì Kaggle API configured with secrets\n\nNo datasets found in input. Downloading...\nDownloading RAVDESS...\nDataset URL: https://www.kaggle.com/datasets/uwrfkaggler/ravdess-emotional-speech-audio\nLicense(s): CC-BY-NC-SA-4.0\n‚úì RAVDESS downloaded\nDownloading TESS...\nDataset URL: https://www.kaggle.com/datasets/ejlok1/toronto-emotional-speech-set-tess\nLicense(s): Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)\n‚úì TESS downloaded\nDownloading CREMA-D...\nDataset URL: https://www.kaggle.com/datasets/ejlok1/cremad\nLicense(s): ODC Attribution License (ODC-By)\n‚úì CREMA-D downloaded\n\nUsing DATA_PATH: /kaggle/working/\nFound 7 items in /kaggle/working/\n\n Setup complete!\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Quick Debug: Check what's actually in the directories\n# DEBUG CELL: Check dataset structure\nimport os\n\nfor dataset in ['ravdess', 'tess', 'cremad']:\n    path = f'/kaggle/working/{dataset}'\n    if os.path.exists(path):\n        print(f\"\\n{dataset.upper()} structure:\")\n        for root, dirs, files in os.walk(path):\n            level = root.replace(path, '').count(os.sep)\n            if level < 3:  # Only show first 3 levels\n                indent = ' ' * 2 * level\n                print(f\"{indent}{os.path.basename(root)}/\")\n                if level < 2:\n                    wav_files = [f for f in files if f.endswith('.wav')]\n                    if wav_files:\n                        print(f\"{indent}  [{len(wav_files)} .wav files]\")\n                        print(f\"{indent}  Sample: {wav_files[0]}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T13:54:21.255654Z","iopub.execute_input":"2025-10-26T13:54:21.256026Z","iopub.status.idle":"2025-10-26T13:54:21.280187Z","shell.execute_reply.started":"2025-10-26T13:54:21.256003Z","shell.execute_reply":"2025-10-26T13:54:21.279316Z"}},"outputs":[{"name":"stdout","text":"\nRAVDESS structure:\nravdess/\n  Actor_11/\n    [60 .wav files]\n    Sample: 03-01-04-01-02-01-11.wav\n  Actor_19/\n    [60 .wav files]\n    Sample: 03-01-02-01-01-01-19.wav\n  Actor_20/\n    [60 .wav files]\n    Sample: 03-01-07-02-01-02-20.wav\n  Actor_01/\n    [60 .wav files]\n    Sample: 03-01-06-02-01-01-01.wav\n  Actor_08/\n    [60 .wav files]\n    Sample: 03-01-03-01-01-01-08.wav\n  Actor_15/\n    [60 .wav files]\n    Sample: 03-01-04-02-02-02-15.wav\n  Actor_14/\n    [60 .wav files]\n    Sample: 03-01-01-01-01-02-14.wav\n  Actor_10/\n    [60 .wav files]\n    Sample: 03-01-05-01-01-02-10.wav\n  Actor_13/\n    [60 .wav files]\n    Sample: 03-01-03-02-01-01-13.wav\n  Actor_06/\n    [60 .wav files]\n    Sample: 03-01-05-02-01-01-06.wav\n  Actor_17/\n    [60 .wav files]\n    Sample: 03-01-03-01-02-02-17.wav\n  Actor_05/\n    [60 .wav files]\n    Sample: 03-01-08-01-02-02-05.wav\n  Actor_18/\n    [60 .wav files]\n    Sample: 03-01-06-01-01-01-18.wav\n  Actor_03/\n    [60 .wav files]\n    Sample: 03-01-08-01-02-01-03.wav\n  Actor_04/\n    [60 .wav files]\n    Sample: 03-01-04-01-02-02-04.wav\n  Actor_23/\n    [60 .wav files]\n    Sample: 03-01-07-02-01-01-23.wav\n  audio_speech_actors_01-24/\n    Actor_11/\n    Actor_19/\n    Actor_20/\n    Actor_01/\n    Actor_08/\n    Actor_15/\n    Actor_14/\n    Actor_10/\n    Actor_13/\n    Actor_06/\n    Actor_17/\n    Actor_05/\n    Actor_18/\n    Actor_03/\n    Actor_04/\n    Actor_23/\n    Actor_21/\n    Actor_02/\n    Actor_22/\n    Actor_09/\n    Actor_24/\n    Actor_07/\n    Actor_12/\n    Actor_16/\n  Actor_21/\n    [60 .wav files]\n    Sample: 03-01-07-02-02-01-21.wav\n  Actor_02/\n    [60 .wav files]\n    Sample: 03-01-01-01-01-01-02.wav\n  Actor_22/\n    [60 .wav files]\n    Sample: 03-01-03-01-02-01-22.wav\n  Actor_09/\n    [60 .wav files]\n    Sample: 03-01-07-02-02-02-09.wav\n  Actor_24/\n    [60 .wav files]\n    Sample: 03-01-08-01-01-01-24.wav\n  Actor_07/\n    [60 .wav files]\n    Sample: 03-01-05-02-02-02-07.wav\n  Actor_12/\n    [60 .wav files]\n    Sample: 03-01-03-02-02-02-12.wav\n  Actor_16/\n    [60 .wav files]\n    Sample: 03-01-02-02-01-01-16.wav\n\nTESS structure:\ntess/\n  tess toronto emotional speech set data/\n    TESS Toronto emotional speech set data/\n  TESS Toronto emotional speech set data/\n    OAF_Fear/\n    YAF_happy/\n    YAF_sad/\n    YAF_disgust/\n    YAF_neutral/\n    OAF_neutral/\n    YAF_angry/\n    YAF_fear/\n    OAF_disgust/\n    OAF_Pleasant_surprise/\n    OAF_Sad/\n    OAF_angry/\n    OAF_happy/\n    YAF_pleasant_surprised/\n\nCREMAD structure:\ncremad/\n  AudioWAV/\n    [7442 .wav files]\n    Sample: 1017_WSI_DIS_XX.wav\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"# ============================================\n# CELL 3: Configuration\n# ============================================","metadata":{}},{"cell_type":"code","source":"# ============================================\n# MODIFIED Config for Dual T4 GPUs\n# ============================================\nclass Config:\n    \"\"\"Configuration optimized for dual T4 GPUs\"\"\"\n    \n    # Project\n    project_name = \"Speech Emotion Recognition\"\n    \n    # Data\n    sample_rate = 16000\n    duration = 3.0\n    n_classes = 8\n    \n    # Features\n    n_mfcc = 40\n    n_mels = 128\n    n_fft = 2048\n    hop_length = 512\n    \n    # Data splits\n    train_size = 0.7\n    val_size = 0.15\n    test_size = 0.15\n    \n    # Training - Optimized for T4 √ó2\n    batch_size = 64  # Increased for dual GPU (was 32)\n    epochs = 100  # Can train longer with faster GPUs\n    learning_rate = 1e-3\n    early_stopping_patience = 10\n    \n    # Model\n    model_type = 'ensemble'\n    dropout = 0.3\n    \n    # Augmentation\n    use_augmentation = True\n    augment_prob = 0.5\n    \n    # Memory optimization\n    gradient_accumulation_steps = 2  # For even larger effective batch size\n    mixed_precision = True  # T4 supports mixed precision well\n    \n    # Paths\n    data_path = DATA_PATH\n    save_path = '/kaggle/working/'\n    \nconfig = Config()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T13:45:19.517560Z","iopub.execute_input":"2025-10-26T13:45:19.517898Z","iopub.status.idle":"2025-10-26T13:45:19.523467Z","shell.execute_reply.started":"2025-10-26T13:45:19.517849Z","shell.execute_reply":"2025-10-26T13:45:19.522907Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"# ============================================\n# CELL 4: Dataset Class with Memory Optimization\n# ============================================","metadata":{}},{"cell_type":"code","source":"class EmotionDataset(Dataset):\n    \"\"\"\n    Memory-efficient dataset for Kaggle\n    \"\"\"\n    \n    def __init__(\n        self, \n        file_paths: List[str],\n        labels: List[int],\n        config: Config,\n        transform=None,\n        augment=False\n    ):\n        self.file_paths = file_paths\n        self.labels = labels\n        self.config = config\n        self.transform = transform\n        self.augment = augment\n        \n        # Pre-calculate fixed length\n        self.target_length = int(config.sample_rate * config.duration)\n        \n    def __len__(self):\n        return len(self.file_paths)\n    \n    def __getitem__(self, idx):\n        # Load audio on-demand to save memory\n        audio_path = self.file_paths[idx]\n        label = self.labels[idx]\n        \n        try:\n            # Load audio\n            waveform, sr = librosa.load(audio_path, sr=self.config.sample_rate, mono=True)\n            \n            # Pad or truncate\n            if len(waveform) > self.target_length:\n                waveform = waveform[:self.target_length]\n            else:\n                waveform = np.pad(waveform, (0, self.target_length - len(waveform)))\n            \n            # Convert to tensor\n            waveform = torch.FloatTensor(waveform).unsqueeze(0)\n            \n            # Apply augmentation\n            if self.augment and random.random() < self.config.augment_prob:\n                waveform = self.augment_audio(waveform)\n            \n            # Extract features\n            features = self.extract_features(waveform)\n            \n            return features, label\n            \n        except Exception as e:\n            print(f\"Error loading {audio_path}: {e}\")\n            # Return zeros if error\n            return torch.zeros((self.config.n_mels, 94)), label\n    \n    def augment_audio(self, waveform):\n        \"\"\"Simple augmentation\"\"\"\n        # Add noise\n        if random.random() > 0.5:\n            noise = torch.randn_like(waveform) * 0.005\n            waveform = waveform + noise\n        \n        # Time shift\n        if random.random() > 0.5:\n            shift = int(random.uniform(-0.1, 0.1) * waveform.shape[1])\n            waveform = torch.roll(waveform, shift, dims=1)\n        \n        return waveform\n    \n    def extract_features(self, waveform):\n        \"\"\"Extract mel-spectrogram features\"\"\"\n        mel_transform = T.MelSpectrogram(\n            sample_rate=self.config.sample_rate,\n            n_mels=self.config.n_mels,\n            n_fft=self.config.n_fft,\n            hop_length=self.config.hop_length\n        )\n        \n        mel_spec = mel_transform(waveform)\n        mel_spec_db = T.AmplitudeToDB()(mel_spec)\n        \n        return mel_spec_db.squeeze(0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T13:45:31.211607Z","iopub.execute_input":"2025-10-26T13:45:31.211920Z","iopub.status.idle":"2025-10-26T13:45:31.221640Z","shell.execute_reply.started":"2025-10-26T13:45:31.211894Z","shell.execute_reply":"2025-10-26T13:45:31.220909Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"# ============================================\n# CELL 5: Data Loading and Preparation\n# ============================================","metadata":{}},{"cell_type":"code","source":"def prepare_data(config):\n    \"\"\"\n    Load and prepare datasets with correct paths\n    \"\"\"\n    all_files = []\n    all_labels = []\n    \n    # Emotion mapping\n    emotion_map = {\n        'neutral': 0, 'calm': 0,  # Merge calm into neutral\n        'happy': 1, 'sad': 2, 'angry': 3,\n        'fearful': 4, 'fear': 4,  # Handle variations\n        'disgust': 5, 'surprised': 6, 'surprise': 6\n    }\n    \n    base_path = Path('/kaggle/working')\n    \n    # RAVDESS dataset - files are in Actor_XX folders\n    ravdess_path = base_path / 'ravdess'\n    if ravdess_path.exists():\n        print(\"Loading RAVDESS dataset...\")\n        # Look for Actor folders\n        for actor_folder in ravdess_path.glob('Actor_*'):\n            if actor_folder.is_dir():\n                for audio_file in actor_folder.glob('*.wav'):\n                    # Parse RAVDESS filename (03-01-06-01-02-01-12.wav)\n                    parts = audio_file.stem.split('-')\n                    if len(parts) >= 3:\n                        emotion_code = int(parts[2])\n                        ravdess_emotions = {\n                            1: 'neutral', 2: 'calm', 3: 'happy', 4: 'sad',\n                            5: 'angry', 6: 'fear', 7: 'disgust', 8: 'surprise'\n                        }\n                        if emotion_code in ravdess_emotions:\n                            emotion = ravdess_emotions[emotion_code]\n                            all_files.append(str(audio_file))\n                            all_labels.append(emotion_map[emotion])\n        print(f\"  Found {len(all_files)} RAVDESS files\")\n    \n    # TESS dataset - files are in emotion-specific folders\n    tess_path = base_path / 'tess' / 'TESS Toronto emotional speech set data'\n    if tess_path.exists():\n        print(\"Loading TESS dataset...\")\n        initial_count = len(all_files)\n        \n        # TESS has folders like OAF_angry, YAF_happy, etc.\n        for emotion_folder in tess_path.glob('*'):\n            if emotion_folder.is_dir():\n                folder_name = emotion_folder.name.lower()\n                \n                # Extract emotion from folder name\n                if 'angry' in folder_name:\n                    emotion = 'angry'\n                elif 'disgust' in folder_name:\n                    emotion = 'disgust'\n                elif 'fear' in folder_name:\n                    emotion = 'fear'\n                elif 'happy' in folder_name:\n                    emotion = 'happy'\n                elif 'sad' in folder_name:\n                    emotion = 'sad'\n                elif 'neutral' in folder_name:\n                    emotion = 'neutral'\n                elif 'surprise' in folder_name or 'surprised' in folder_name:\n                    emotion = 'surprise'\n                else:\n                    continue  # Skip unknown folders\n                \n                # Add all wav files from this emotion folder\n                for audio_file in emotion_folder.glob('*.wav'):\n                    all_files.append(str(audio_file))\n                    all_labels.append(emotion_map[emotion])\n        \n        print(f\"  Found {len(all_files) - initial_count} TESS files\")\n    \n    # CREMA-D dataset - files are in AudioWAV folder\n    cremad_path = base_path / 'cremad' / 'AudioWAV'\n    if cremad_path.exists():\n        print(\"Loading CREMA-D dataset...\")\n        initial_count = len(all_files)\n        \n        for audio_file in cremad_path.glob('*.wav'):\n            # CREMA-D format: 1001_DFA_ANG_XX.wav\n            filename = audio_file.stem\n            if '_' in filename:\n                parts = filename.split('_')\n                if len(parts) >= 3:\n                    emotion_code = parts[2]\n                    cremad_emotions = {\n                        'ANG': 'angry', 'DIS': 'disgust', 'FEA': 'fear',\n                        'HAP': 'happy', 'NEU': 'neutral', 'SAD': 'sad'\n                    }\n                    if emotion_code in cremad_emotions:\n                        emotion = cremad_emotions[emotion_code]\n                        all_files.append(str(audio_file))\n                        all_labels.append(emotion_map[emotion])\n        \n        print(f\"  Found {len(all_files) - initial_count} CREMA-D files\")\n    \n    # Summary\n    if len(all_files) == 0:\n        print(\"\\n‚ö†Ô∏è No audio files found. Please check dataset paths.\")\n        print(\"Creating synthetic data for testing...\")\n        for i in range(100):\n            all_files.append(f\"dummy_{i}.wav\")\n            all_labels.append(random.randint(0, 6))\n    else:\n        print(f\"\\n‚úÖ Successfully loaded all datasets!\")\n    \n    print(f\"Total samples: {len(all_files)}\")\n    \n    # Show label distribution\n    label_counts = Counter(all_labels)\n    emotion_names = {v: k for k, v in emotion_map.items()}\n    print(\"\\nEmotion distribution:\")\n    for label, count in sorted(label_counts.items()):\n        emotion_name = [k for k, v in emotion_map.items() if v == label][0]\n        print(f\"  {emotion_name}: {count} samples\")\n    \n    # Update number of classes\n    config.n_classes = len(set(all_labels))\n    print(f\"\\nNumber of emotion classes: {config.n_classes}\")\n    \n    return all_files, all_labels\n\n# Load data with the fixed function\nfile_paths, labels = prepare_data(config)\n\n# Split data\nX_temp, X_test, y_temp, y_test = train_test_split(\n    file_paths, labels, test_size=config.test_size, \n    stratify=labels, random_state=42\n)\n\nX_train, X_val, y_train, y_val = train_test_split(\n    X_temp, y_temp, test_size=config.val_size/(1-config.test_size),\n    stratify=y_temp, random_state=42\n)\n\nprint(f\"\\nDataset splits:\")\nprint(f\"  Train: {len(X_train)} samples\")\nprint(f\"  Val: {len(X_val)} samples\")\nprint(f\"  Test: {len(X_test)} samples\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T13:55:50.618572Z","iopub.execute_input":"2025-10-26T13:55:50.618898Z","iopub.status.idle":"2025-10-26T13:55:50.692318Z","shell.execute_reply.started":"2025-10-26T13:55:50.618879Z","shell.execute_reply":"2025-10-26T13:55:50.691704Z"}},"outputs":[{"name":"stdout","text":"Loading RAVDESS dataset...\n  Found 1440 RAVDESS files\nLoading TESS dataset...\n  Found 2800 TESS files\nLoading CREMA-D dataset...\n  Found 7442 CREMA-D files\n\n‚úÖ Successfully loaded all datasets!\nTotal samples: 11682\n\nEmotion distribution:\n  neutral: 1775 samples\n  happy: 1863 samples\n  sad: 1863 samples\n  angry: 1863 samples\n  fearful: 1863 samples\n  disgust: 1863 samples\n  surprised: 592 samples\n\nNumber of emotion classes: 7\n\nDataset splits:\n  Train: 8176 samples\n  Val: 1753 samples\n  Test: 1753 samples\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"# ============================================\n# CELL 6: Model Architectures\n# ============================================","metadata":{}},{"cell_type":"code","source":"class CNNModel(nn.Module):\n    \"\"\"CNN for emotion recognition\"\"\"\n    \n    def __init__(self, config):\n        super().__init__()\n        \n        self.conv1 = nn.Sequential(\n            nn.Conv2d(1, 64, kernel_size=3, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.MaxPool2d(2)\n        )\n        \n        self.conv2 = nn.Sequential(\n            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(),\n            nn.MaxPool2d(2)\n        )\n        \n        self.conv3 = nn.Sequential(\n            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(),\n            nn.MaxPool2d(2)\n        )\n        \n        # Global pooling\n        self.global_pool = nn.AdaptiveAvgPool2d((1, 1))\n        \n        # Classifier\n        self.classifier = nn.Sequential(\n            nn.Linear(256, 128),\n            nn.ReLU(),\n            nn.Dropout(config.dropout),\n            nn.Linear(128, 64),\n            nn.ReLU(),\n            nn.Dropout(config.dropout),\n            nn.Linear(64, config.n_classes)\n        )\n        \n    def forward(self, x):\n        # Add channel dimension if needed\n        if x.dim() == 3:\n            x = x.unsqueeze(1)\n        \n        x = self.conv1(x)\n        x = self.conv2(x)\n        x = self.conv3(x)\n        x = self.global_pool(x)\n        x = x.view(x.size(0), -1)\n        x = self.classifier(x)\n        \n        return x\n\n\nclass LSTMModel(nn.Module):\n    \"\"\"LSTM for emotion recognition\"\"\"\n    \n    def __init__(self, config):\n        super().__init__()\n        \n        self.lstm = nn.LSTM(\n            input_size=config.n_mels,\n            hidden_size=128,\n            num_layers=2,\n            batch_first=True,\n            dropout=config.dropout,\n            bidirectional=True\n        )\n        \n        self.attention = nn.Sequential(\n            nn.Linear(256, 128),\n            nn.Tanh(),\n            nn.Linear(128, 1)\n        )\n        \n        self.classifier = nn.Sequential(\n            nn.Linear(256, 128),\n            nn.ReLU(),\n            nn.Dropout(config.dropout),\n            nn.Linear(128, config.n_classes)\n        )\n        \n    def forward(self, x):\n        # Reshape for LSTM (batch, time, features)\n        if x.dim() == 4:\n            x = x.squeeze(1)\n        x = x.transpose(1, 2)\n        \n        lstm_out, _ = self.lstm(x)\n        \n        # Attention\n        attn_weights = self.attention(lstm_out)\n        attn_weights = F.softmax(attn_weights, dim=1)\n        attended = torch.sum(lstm_out * attn_weights, dim=1)\n        \n        return self.classifier(attended)\n\n\nclass TransformerModel(nn.Module):\n    \"\"\"Transformer for emotion recognition\"\"\"\n    \n    def __init__(self, config):\n        super().__init__()\n        \n        self.input_projection = nn.Linear(config.n_mels, 256)\n        \n        encoder_layer = nn.TransformerEncoderLayer(\n            d_model=256,\n            nhead=8,\n            dim_feedforward=512,\n            dropout=config.dropout,\n            batch_first=True\n        )\n        \n        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=4)\n        \n        self.classifier = nn.Sequential(\n            nn.Linear(256, 128),\n            nn.ReLU(),\n            nn.Dropout(config.dropout),\n            nn.Linear(128, config.n_classes)\n        )\n        \n    def forward(self, x):\n        # Reshape (batch, time, features)\n        if x.dim() == 4:\n            x = x.squeeze(1)\n        x = x.transpose(1, 2)\n        \n        x = self.input_projection(x)\n        x = self.transformer(x)\n        \n        # Global average pooling\n        x = x.mean(dim=1)\n        \n        return self.classifier(x)\n\n\nclass EnsembleModel(nn.Module):\n    \"\"\"Ensemble of multiple models\"\"\"\n    \n    def __init__(self, config):\n        super().__init__()\n        \n        self.cnn = CNNModel(config)\n        self.lstm = LSTMModel(config)\n        self.transformer = TransformerModel(config)\n        \n        # Learnable weights for ensemble\n        self.weights = nn.Parameter(torch.ones(3) / 3)\n        \n    def forward(self, x):\n        cnn_out = self.cnn(x)\n        lstm_out = self.lstm(x)\n        transformer_out = self.transformer(x)\n        \n        # Weighted average\n        w = F.softmax(self.weights, dim=0)\n        output = w[0] * cnn_out + w[1] * lstm_out + w[2] * transformer_out\n        \n        return output","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T13:56:05.786430Z","iopub.execute_input":"2025-10-26T13:56:05.786921Z","iopub.status.idle":"2025-10-26T13:56:05.803031Z","shell.execute_reply.started":"2025-10-26T13:56:05.786898Z","shell.execute_reply":"2025-10-26T13:56:05.802196Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"# ============================================\n# CELL 7: Training Functions\n# ============================================","metadata":{}},{"cell_type":"code","source":"# ============================================\n# OPTIMIZED Trainer with Mixed Precision for T4\n# ============================================\nfrom torch.cuda.amp import autocast, GradScaler\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom tqdm import tqdm\nimport gc\n\nclass Trainer:\n    \"\"\"Training manager optimized for T4 GPUs\"\"\"\n    \n    def __init__(self, model, config, device):\n        self.model = model.to(device)  # FIXED: Added .to(device)\n        self.config = config\n        self.device = device\n        \n        self.criterion = nn.CrossEntropyLoss()\n        self.optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n            self.optimizer, mode='min', patience=3, factor=0.5\n        )\n        \n        # Mixed precision for T4\n        self.scaler = GradScaler()\n        \n        self.train_losses = []\n        self.val_losses = []\n        self.train_accs = []\n        self.val_accs = []\n        \n    def train_epoch(self, dataloader):\n        self.model.train()\n        total_loss = 0\n        correct = 0\n        total = 0\n        \n        for batch_idx, (features, labels) in enumerate(tqdm(dataloader, desc=\"Training\")):\n            features = features.to(self.device)\n            labels = labels.to(self.device)\n            \n            self.optimizer.zero_grad()\n            \n            # Mixed precision training\n            with autocast():\n                outputs = self.model(features)\n                loss = self.criterion(outputs, labels)\n            \n            # Scaled backprop for mixed precision\n            self.scaler.scale(loss).backward()\n            \n            # Gradient clipping\n            self.scaler.unscale_(self.optimizer)\n            torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\n            \n            self.scaler.step(self.optimizer)\n            self.scaler.update()\n            \n            total_loss += loss.item()\n            _, predicted = outputs.max(1)\n            total += labels.size(0)\n            correct += predicted.eq(labels).sum().item()\n            \n            # Clear cache periodically\n            if batch_idx % 10 == 0:\n                torch.cuda.empty_cache()\n        \n        return total_loss / len(dataloader), 100. * correct / total\n    \n    def validate(self, dataloader):\n        self.model.eval()\n        total_loss = 0\n        correct = 0\n        total = 0\n        \n        with torch.no_grad():\n            # Use mixed precision for validation too\n            with autocast():\n                for features, labels in tqdm(dataloader, desc=\"Validation\"):\n                    features = features.to(self.device)\n                    labels = labels.to(self.device)\n                    \n                    outputs = self.model(features)\n                    loss = self.criterion(outputs, labels)\n                    \n                    total_loss += loss.item()\n                    _, predicted = outputs.max(1)\n                    total += labels.size(0)\n                    correct += predicted.eq(labels).sum().item()\n        \n        return total_loss / len(dataloader), 100. * correct / total\n    \n    def fit(self, train_loader, val_loader):\n        best_val_acc = 0\n        patience_counter = 0\n        \n        for epoch in range(self.config.epochs):\n            print(f\"\\nEpoch {epoch+1}/{self.config.epochs}\")\n            \n            # Training\n            train_loss, train_acc = self.train_epoch(train_loader)\n            self.train_losses.append(train_loss)\n            self.train_accs.append(train_acc)\n            \n            # Validation\n            val_loss, val_acc = self.validate(val_loader)\n            self.val_losses.append(val_loss)\n            self.val_accs.append(val_acc)\n            \n            # Scheduler\n            self.scheduler.step(val_loss)\n            \n            print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n            print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n            \n            # Save best model\n            if val_acc > best_val_acc:\n                best_val_acc = val_acc\n                torch.save({\n                    'epoch': epoch,\n                    'model_state_dict': self.model.state_dict(),\n                    'optimizer_state_dict': self.optimizer.state_dict(),\n                    'val_acc': val_acc,\n                    'config': self.config\n                }, '/kaggle/working/best_model.pth')\n                patience_counter = 0\n                print(f\"‚úì Saved best model with {val_acc:.2f}% accuracy\")\n            else:\n                patience_counter += 1\n            \n            # Early stopping\n            if patience_counter >= self.config.early_stopping_patience:\n                print(f\"Early stopping at epoch {epoch+1}\")\n                break\n            \n            # Memory cleanup\n            gc.collect()\n            torch.cuda.empty_cache()\n        \n        return self.model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T13:56:24.984394Z","iopub.execute_input":"2025-10-26T13:56:24.985103Z","iopub.status.idle":"2025-10-26T13:56:24.998217Z","shell.execute_reply.started":"2025-10-26T13:56:24.985076Z","shell.execute_reply":"2025-10-26T13:56:24.997569Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"# ============================================\n# CELL 8: Create DataLoaders\n# ============================================","metadata":{}},{"cell_type":"code","source":"# Create datasets\ntrain_dataset = EmotionDataset(X_train, y_train, config, augment=True)\nval_dataset = EmotionDataset(X_val, y_val, config, augment=False)\ntest_dataset = EmotionDataset(X_test, y_test, config, augment=False)\n\n# Create dataloaders with num_workers=0 for Kaggle\ntrain_loader = DataLoader(\n    train_dataset, batch_size=config.batch_size, \n    shuffle=True, num_workers=0, pin_memory=True\n)\n\nval_loader = DataLoader(\n    val_dataset, batch_size=config.batch_size, \n    shuffle=False, num_workers=0, pin_memory=True\n)\n\ntest_loader = DataLoader(\n    test_dataset, batch_size=config.batch_size, \n    shuffle=False, num_workers=0, pin_memory=True\n)\n\nprint(f\"DataLoaders created successfully!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T13:56:34.463488Z","iopub.execute_input":"2025-10-26T13:56:34.464190Z","iopub.status.idle":"2025-10-26T13:56:34.470260Z","shell.execute_reply.started":"2025-10-26T13:56:34.464165Z","shell.execute_reply":"2025-10-26T13:56:34.469351Z"}},"outputs":[{"name":"stdout","text":"DataLoaders created successfully!\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"# ============================================\n# CELL 9: Train Model with DataParallel\n# ============================================","metadata":{}},{"cell_type":"code","source":"# ============================================\n# CELL 9: Train Model (COMPLETE VERSION)\n# ============================================\n\n# Select model based on config\nif config.model_type == 'cnn':\n    model = CNNModel(config)\nelif config.model_type == 'lstm':\n    model = LSTMModel(config)\nelif config.model_type == 'transformer':\n    model = TransformerModel(config)\nelse:  # ensemble\n    model = EnsembleModel(config)\n\n# Use DataParallel if multiple GPUs available\nif torch.cuda.device_count() > 1:\n    print(f\"Using {torch.cuda.device_count()} GPUs!\")\n    model = DataParallel(model)\n\nprint(f\"Model: {config.model_type}\")\nprint(f\"Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n\n# Create trainer and actually train the model\ntrainer = Trainer(model, config, device)\n\n# THIS IS THE IMPORTANT PART - Actually run training!\nprint(\"\\n\" + \"=\"*50)\nprint(\"Starting Training...\")\nprint(\"=\"*50)\n\ntrained_model = trainer.fit(train_loader, val_loader)\n\nprint(\"\\n\" + \"=\"*50)\nprint(\"Training Complete!\")\nprint(\"=\"*50)\n\n# Verify the model was saved\nimport os\nif os.path.exists('/kaggle/working/best_model.pth'):\n    print(\"‚úÖ Model saved successfully!\")\n    file_size = os.path.getsize('/kaggle/working/best_model.pth') / (1024*1024)\n    print(f\"Model file size: {file_size:.2f} MB\")\nelse:\n    print(\"‚ö†Ô∏è Model file not found. Training may have failed.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T13:59:06.196300Z","iopub.execute_input":"2025-10-26T13:59:06.196615Z","iopub.status.idle":"2025-10-26T14:28:52.106940Z","shell.execute_reply.started":"2025-10-26T13:59:06.196594Z","shell.execute_reply":"2025-10-26T14:28:52.106285Z"}},"outputs":[{"name":"stdout","text":"Using 2 GPUs!\nModel: ensemble\nParameters: 3,313,689\n\n==================================================\nStarting Training...\n==================================================\n\nEpoch 1/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 128/128 [00:58<00:00,  2.21it/s]\nValidation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28/28 [00:07<00:00,  3.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.5105, Train Acc: 38.94%\nVal Loss: 1.2533, Val Acc: 50.94%\n‚úì Saved best model with 50.94% accuracy\n\nEpoch 2/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 128/128 [00:42<00:00,  2.99it/s]\nValidation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28/28 [00:07<00:00,  3.72it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.2124, Train Acc: 52.54%\nVal Loss: 1.0757, Val Acc: 58.36%\n‚úì Saved best model with 58.36% accuracy\n\nEpoch 3/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 128/128 [00:42<00:00,  3.04it/s]\nValidation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28/28 [00:07<00:00,  3.72it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.0941, Train Acc: 57.18%\nVal Loss: 1.0337, Val Acc: 58.36%\n\nEpoch 4/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 128/128 [00:40<00:00,  3.19it/s]\nValidation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28/28 [00:07<00:00,  3.90it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.0394, Train Acc: 58.72%\nVal Loss: 1.0121, Val Acc: 60.30%\n‚úì Saved best model with 60.30% accuracy\n\nEpoch 5/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 128/128 [00:39<00:00,  3.21it/s]\nValidation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28/28 [00:07<00:00,  3.97it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.0034, Train Acc: 60.49%\nVal Loss: 0.9761, Val Acc: 63.03%\n‚úì Saved best model with 63.03% accuracy\n\nEpoch 6/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 128/128 [00:40<00:00,  3.19it/s]\nValidation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28/28 [00:07<00:00,  3.93it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.9627, Train Acc: 62.40%\nVal Loss: 0.9803, Val Acc: 61.15%\n\nEpoch 7/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 128/128 [00:40<00:00,  3.20it/s]\nTraining: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 128/128 [00:40<00:00,  3.15it/s]\nValidation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28/28 [00:07<00:00,  3.90it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.8598, Train Acc: 66.87%\nVal Loss: 1.0081, Val Acc: 61.67%\n\nEpoch 11/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 128/128 [00:39<00:00,  3.20it/s]\nValidation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28/28 [00:07<00:00,  3.98it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.8310, Train Acc: 68.08%\nVal Loss: 0.8980, Val Acc: 66.00%\n‚úì Saved best model with 66.00% accuracy\n\nEpoch 12/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 128/128 [00:39<00:00,  3.22it/s]\nValidation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28/28 [00:07<00:00,  3.87it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.8045, Train Acc: 69.18%\nVal Loss: 0.9948, Val Acc: 63.61%\n\nEpoch 13/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 128/128 [00:39<00:00,  3.25it/s]\nValidation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28/28 [00:07<00:00,  3.90it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.7922, Train Acc: 69.58%\nVal Loss: 0.9857, Val Acc: 63.26%\n\nEpoch 14/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 128/128 [00:39<00:00,  3.21it/s]\nValidation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28/28 [00:07<00:00,  3.86it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.7670, Train Acc: 70.91%\nVal Loss: 0.9593, Val Acc: 64.69%\n\nEpoch 15/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 128/128 [00:39<00:00,  3.23it/s]\nValidation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28/28 [00:07<00:00,  3.97it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.7466, Train Acc: 71.69%\nVal Loss: 0.9257, Val Acc: 66.57%\n‚úì Saved best model with 66.57% accuracy\n\nEpoch 16/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 128/128 [00:39<00:00,  3.22it/s]\nValidation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28/28 [00:06<00:00,  4.02it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.6715, Train Acc: 75.12%\nVal Loss: 0.9064, Val Acc: 66.97%\n‚úì Saved best model with 66.97% accuracy\n\nEpoch 17/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 128/128 [00:39<00:00,  3.23it/s]\nValidation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28/28 [00:07<00:00,  3.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.6279, Train Acc: 76.11%\nVal Loss: 0.9581, Val Acc: 67.43%\n‚úì Saved best model with 67.43% accuracy\n\nEpoch 18/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 128/128 [00:40<00:00,  3.18it/s]\nValidation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28/28 [00:07<00:00,  3.92it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.5885, Train Acc: 77.65%\nVal Loss: 0.9136, Val Acc: 68.28%\n‚úì Saved best model with 68.28% accuracy\n\nEpoch 19/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 128/128 [00:40<00:00,  3.13it/s]\nValidation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28/28 [00:07<00:00,  3.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.5677, Train Acc: 78.60%\nVal Loss: 0.9850, Val Acc: 67.77%\n\nEpoch 20/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 128/128 [00:39<00:00,  3.22it/s]\nValidation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28/28 [00:07<00:00,  3.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.5279, Train Acc: 80.33%\nVal Loss: 0.9385, Val Acc: 68.34%\n‚úì Saved best model with 68.34% accuracy\n\nEpoch 21/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 128/128 [00:39<00:00,  3.27it/s]\nValidation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28/28 [00:07<00:00,  3.95it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.4883, Train Acc: 81.74%\nVal Loss: 1.0077, Val Acc: 69.25%\n‚úì Saved best model with 69.25% accuracy\n\nEpoch 22/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 128/128 [00:39<00:00,  3.25it/s]\nValidation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28/28 [00:07<00:00,  3.87it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.4693, Train Acc: 82.52%\nVal Loss: 0.9761, Val Acc: 69.25%\n\nEpoch 23/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 128/128 [00:40<00:00,  3.16it/s]\nValidation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28/28 [00:07<00:00,  3.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.4473, Train Acc: 83.17%\nVal Loss: 0.9775, Val Acc: 68.68%\n\nEpoch 24/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 128/128 [00:41<00:00,  3.07it/s]\nValidation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28/28 [00:07<00:00,  3.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.4245, Train Acc: 84.44%\nVal Loss: 0.9993, Val Acc: 69.02%\n\nEpoch 25/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 128/128 [00:42<00:00,  2.99it/s]\nValidation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28/28 [00:07<00:00,  3.95it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.4121, Train Acc: 84.41%\nVal Loss: 1.0176, Val Acc: 69.48%\n‚úì Saved best model with 69.48% accuracy\n\nEpoch 26/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 128/128 [00:40<00:00,  3.19it/s]\nValidation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28/28 [00:07<00:00,  3.91it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.3976, Train Acc: 85.42%\nVal Loss: 1.0290, Val Acc: 69.65%\n‚úì Saved best model with 69.65% accuracy\n\nEpoch 27/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 128/128 [00:41<00:00,  3.11it/s]\nValidation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28/28 [00:07<00:00,  3.76it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.3932, Train Acc: 85.65%\nVal Loss: 1.0331, Val Acc: 70.05%\n‚úì Saved best model with 70.05% accuracy\n\nEpoch 28/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 128/128 [00:39<00:00,  3.22it/s]\nValidation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28/28 [00:07<00:00,  3.96it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.3717, Train Acc: 86.46%\nVal Loss: 1.0506, Val Acc: 70.05%\n\nEpoch 29/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 128/128 [00:39<00:00,  3.24it/s]\nValidation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28/28 [00:07<00:00,  3.97it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.3663, Train Acc: 86.20%\nVal Loss: 1.0745, Val Acc: 69.88%\n\nEpoch 30/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 128/128 [00:39<00:00,  3.25it/s]\nValidation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28/28 [00:07<00:00,  3.97it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.3554, Train Acc: 86.75%\nVal Loss: 1.0787, Val Acc: 69.71%\n\nEpoch 31/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 128/128 [00:39<00:00,  3.26it/s]\nValidation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28/28 [00:07<00:00,  3.97it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.3543, Train Acc: 86.75%\nVal Loss: 1.0799, Val Acc: 69.82%\n\nEpoch 32/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 128/128 [00:39<00:00,  3.26it/s]\nValidation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28/28 [00:07<00:00,  3.92it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.3459, Train Acc: 87.52%\nVal Loss: 1.0878, Val Acc: 69.48%\n\nEpoch 33/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 128/128 [00:39<00:00,  3.26it/s]\nValidation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28/28 [00:07<00:00,  3.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.3422, Train Acc: 87.50%\nVal Loss: 1.0867, Val Acc: 70.05%\n\nEpoch 34/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 128/128 [00:39<00:00,  3.25it/s]\nValidation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28/28 [00:07<00:00,  3.93it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.3460, Train Acc: 87.16%\nVal Loss: 1.0956, Val Acc: 69.71%\n\nEpoch 35/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 128/128 [00:39<00:00,  3.24it/s]\nValidation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28/28 [00:06<00:00,  4.00it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.3388, Train Acc: 87.38%\nVal Loss: 1.0987, Val Acc: 69.77%\n\nEpoch 36/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 128/128 [00:40<00:00,  3.17it/s]\nValidation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28/28 [00:07<00:00,  3.94it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.3385, Train Acc: 87.68%\nVal Loss: 1.0981, Val Acc: 69.88%\n\nEpoch 37/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 128/128 [00:40<00:00,  3.19it/s]\nValidation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28/28 [00:07<00:00,  3.85it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.3360, Train Acc: 87.65%\nVal Loss: 1.1078, Val Acc: 69.54%\nEarly stopping at epoch 37\n\n==================================================\nTraining Complete!\n==================================================\n‚úÖ Model saved successfully!\nModel file size: 38.04 MB\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"# ============================================\n# CELL 10: Evaluation and Visualization\n# ============================================","metadata":{}},{"cell_type":"code","source":"def evaluate_model(model, test_loader, device):\n    \"\"\"Comprehensive model evaluation\"\"\"\n    model.eval()\n    all_preds = []\n    all_labels = []\n    all_probs = []\n    \n    with torch.no_grad():\n        for features, labels in tqdm(test_loader, desc=\"Testing\"):\n            features = features.to(device)\n            outputs = model(features)\n            probs = F.softmax(outputs, dim=1)\n            _, predicted = outputs.max(1)\n            \n            all_preds.extend(predicted.cpu().numpy())\n            all_labels.extend(labels.numpy())\n            all_probs.extend(probs.cpu().numpy())\n    \n    return np.array(all_preds), np.array(all_labels), np.array(all_probs)\n\n# Load best model - FIXED for PyTorch 2.6\ncheckpoint = torch.load('/kaggle/working/best_model.pth', weights_only=False)  # <-- Added weights_only=False\nmodel.load_state_dict(checkpoint['model_state_dict'])\nprint(f\"‚úÖ Loaded best model from epoch {checkpoint['epoch']} with {checkpoint['val_acc']:.2f}% validation accuracy\")\n\n# Evaluate on test set\nprint(\"\\nEvaluating on test set...\")\npreds, labels, probs = evaluate_model(model, test_loader, device)\n\n# Calculate metrics\naccuracy = accuracy_score(labels, preds)\nprint(f\"\\nüéØ Test Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n\n# Classification report\nemotion_names = ['neutral', 'happy', 'sad', 'angry', 'fear', 'disgust', 'surprise']\nprint(\"\\n\" + \"=\"*60)\nprint(\"Classification Report:\")\nprint(\"=\"*60)\nprint(classification_report(labels, preds, target_names=emotion_names[:config.n_classes], digits=3))\n\n# Confusion Matrix\ncm = confusion_matrix(labels, preds)\nprint(\"\\n\" + \"=\"*60)\nprint(\"Confusion Matrix:\")\nprint(\"=\"*60)\nprint(cm)\n\n# Calculate per-class accuracy\nper_class_acc = cm.diagonal() / cm.sum(axis=1)\nprint(\"\\n\" + \"=\"*60)\nprint(\"Per-Class Accuracy:\")\nprint(\"=\"*60)\nfor i, emotion in enumerate(emotion_names[:config.n_classes]):\n    if i < len(per_class_acc):\n        print(f\"  {emotion:10s}: {per_class_acc[i]:.3f} ({per_class_acc[i]*100:.1f}%)\")\n\nprint(\"\\n‚úÖ Evaluation complete!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T15:19:29.811680Z","iopub.execute_input":"2025-10-26T15:19:29.812396Z","iopub.status.idle":"2025-10-26T15:19:37.368416Z","shell.execute_reply.started":"2025-10-26T15:19:29.812365Z","shell.execute_reply":"2025-10-26T15:19:37.367717Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Loaded best model from epoch 26 with 70.05% validation accuracy\n\nEvaluating on test set...\n","output_type":"stream"},{"name":"stderr","text":"Testing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28/28 [00:07<00:00,  3.76it/s]","output_type":"stream"},{"name":"stdout","text":"\nüéØ Test Accuracy: 0.7193 (71.93%)\n\n============================================================\nClassification Report:\n============================================================\n              precision    recall  f1-score   support\n\n     neutral      0.717     0.782     0.748       266\n       happy      0.663     0.682     0.673       280\n         sad      0.633     0.706     0.668       279\n       angry      0.811     0.796     0.804       280\n        fear      0.775     0.564     0.653       280\n     disgust      0.692     0.710     0.701       279\n    surprise      0.869     0.966     0.915        89\n\n    accuracy                          0.719      1753\n   macro avg      0.737     0.744     0.737      1753\nweighted avg      0.723     0.719     0.718      1753\n\n\n============================================================\nConfusion Matrix:\n============================================================\n[[208  13  27   3   3  12   0]\n [ 17 191   6  29  16  17   4]\n [ 30   7 197   0  17  24   4]\n [  5  26   3 223   2  18   3]\n [  6  36  52   9 158  17   2]\n [ 24  13  25  11   8 198   0]\n [  0   2   1   0   0   0  86]]\n\n============================================================\nPer-Class Accuracy:\n============================================================\n  neutral   : 0.782 (78.2%)\n  happy     : 0.682 (68.2%)\n  sad       : 0.706 (70.6%)\n  angry     : 0.796 (79.6%)\n  fear      : 0.564 (56.4%)\n  disgust   : 0.710 (71.0%)\n  surprise  : 0.966 (96.6%)\n\n‚úÖ Evaluation complete!\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":21},{"cell_type":"markdown","source":"# ============================================\n# CELL 11: Advanced Visualizations\n# ============================================","metadata":{}},{"cell_type":"code","source":"# 1. Training History\nfig = make_subplots(\n    rows=1, cols=2,\n    subplot_titles=('Loss', 'Accuracy')\n)\n\nfig.add_trace(\n    go.Scatter(y=trainer.train_losses, name='Train Loss', mode='lines'),\n    row=1, col=1\n)\nfig.add_trace(\n    go.Scatter(y=trainer.val_losses, name='Val Loss', mode='lines'),\n    row=1, col=1\n)\n\nfig.add_trace(\n    go.Scatter(y=trainer.train_accs, name='Train Acc', mode='lines'),\n    row=1, col=2\n)\nfig.add_trace(\n    go.Scatter(y=trainer.val_accs, name='Val Acc', mode='lines'),\n    row=1, col=2\n)\n\nfig.update_layout(height=400, title_text=\"Training History\")\nfig.show()\n\n# 2. Confusion Matrix Heatmap\nfig = px.imshow(\n    cm,\n    labels=dict(x=\"Predicted\", y=\"True\", color=\"Count\"),\n    x=emotion_names[:config.n_classes],\n    y=emotion_names[:config.n_classes],\n    title=\"Confusion Matrix\",\n    color_continuous_scale=\"Blues\",\n    text_auto=True\n)\nfig.update_layout(width=600, height=500)\nfig.show()\n\n# 3. Per-class Performance\nper_class_acc = cm.diagonal() / cm.sum(axis=1)\nfig = go.Figure(data=[\n    go.Bar(x=emotion_names[:config.n_classes], y=per_class_acc)\n])\nfig.update_layout(\n    title=\"Per-Class Accuracy\",\n    xaxis_title=\"Emotion\",\n    yaxis_title=\"Accuracy\",\n    yaxis_range=[0, 1]\n)\nfig.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T15:19:47.294475Z","iopub.execute_input":"2025-10-26T15:19:47.295076Z","iopub.status.idle":"2025-10-26T15:19:50.157553Z","shell.execute_reply.started":"2025-10-26T15:19:47.295052Z","shell.execute_reply":"2025-10-26T15:19:50.156789Z"}},"outputs":[{"output_type":"display_data","data":{"text/html":"<html>\n<head><meta charset=\"utf-8\" /></head>\n<body>\n    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"0632c18b-89d3-407e-8770-bc5d7fc5adca\" class=\"plotly-graph-div\" style=\"height:400px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"0632c18b-89d3-407e-8770-bc5d7fc5adca\")) {                    Plotly.newPlot(                        \"0632c18b-89d3-407e-8770-bc5d7fc5adca\",                        [{\"mode\":\"lines\",\"name\":\"Train Loss\",\"y\":[1.510503038764,1.2124040685594082,1.0940576330758631,1.039359720889479,1.0034060166217387,0.9626947557553649,0.9354874030686915,0.9076627613976598,0.8964708228595555,0.8598378892056644,0.830959893297404,0.8044817540794611,0.7921841363422573,0.766991529148072,0.7465753525029868,0.6715068363118917,0.6279375154990703,0.5885477680712938,0.5677277413196862,0.5279459916055202,0.4883130363887176,0.4693463786970824,0.44732621510047466,0.42447770468425006,0.4120776146883145,0.39759170275647193,0.39324083435349166,0.37173551111482084,0.36631448240950704,0.35541894380003214,0.35426095058210194,0.3458980203140527,0.3421635573031381,0.3460399470059201,0.3387715136632323,0.3385283370735124,0.33596675971057266],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"mode\":\"lines\",\"name\":\"Val Loss\",\"y\":[1.253346255847386,1.075655745608466,1.0336992208446776,1.0120984081711089,0.9760697675602776,0.9802720525435039,0.9844062690223966,0.9766572777714048,0.9296900842870984,1.0081062827791487,0.8980378316981452,0.9947642279522759,0.9857136373009,0.9593337497540882,0.9257450188909259,0.9063536162887301,0.9580933621951512,0.9136469300304141,0.985000763620649,0.9385456783430917,1.0076903871127538,0.97609301337174,0.977493880050523,0.9992742112704686,1.0176153523581368,1.0290065322603499,1.0331303136689323,1.0505531110933848,1.0745073152439935,1.0786616376468114,1.079947401370321,1.087776935526303,1.0866972612483161,1.095553240605763,1.0986731627157755,1.0980768437896455,1.1077746067728316],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"mode\":\"lines\",\"name\":\"Train Acc\",\"y\":[38.94324853228963,52.5440313111546,57.179549902152644,58.7206457925636,60.49412915851272,62.40215264187867,63.47847358121331,64.79941291585128,64.99510763209393,66.86643835616438,68.07729941291585,69.17808219178082,69.58170254403132,70.91487279843444,71.68542074363992,75.12230919765166,76.11301369863014,77.6541095890411,78.5958904109589,80.33268101761253,81.73923679060665,82.5220156555773,83.17025440313111,84.44227005870842,84.40557729941291,85.42074363992172,85.65313111545989,86.46037181996086,86.20352250489236,86.75391389432485,86.75391389432485,87.52446183953033,87.5,87.15753424657534,87.37769080234834,87.6834637964775,87.64677103718199],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"mode\":\"lines\",\"name\":\"Val Acc\",\"y\":[50.94124358243012,58.35710211066743,58.35710211066743,60.29663434112949,63.03479749001711,61.152310325156876,62.57843696520251,62.29321163719338,64.86023958927552,61.6657159155733,66.00114090131204,63.605248146035365,63.26297775242441,64.68910439247006,66.5715915573303,66.97090701654307,67.42726754135768,68.28294352538505,67.76953793496862,68.33998859098688,69.25270964061609,69.25270964061609,68.68225898459784,69.02452937820878,69.48088990302338,69.65202509982886,70.05134055904165,70.05134055904165,69.88020536223617,69.70907016543069,69.82316029663434,69.48088990302338,70.05134055904165,69.70907016543069,69.76611523103251,69.88020536223617,69.53793496862521],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.45]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0]},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.55,1.0]},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.0,1.0]},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Loss\",\"x\":0.225,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Accuracy\",\"x\":0.775,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"title\":{\"text\":\"Training History\"},\"height\":400},                        {\"responsive\": true}                    ).then(function(){\n                            \nvar gd = document.getElementById('0632c18b-89d3-407e-8770-bc5d7fc5adca');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })                };                            </script>        </div>\n</body>\n</html>"},"metadata":{}},{"output_type":"display_data","data":{"text/html":"<html>\n<head><meta charset=\"utf-8\" /></head>\n<body>\n    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"0f3a9f4c-3b19-458c-b58a-b56efc143555\" class=\"plotly-graph-div\" style=\"height:500px; width:600px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"0f3a9f4c-3b19-458c-b58a-b56efc143555\")) {                    Plotly.newPlot(                        \"0f3a9f4c-3b19-458c-b58a-b56efc143555\",                        [{\"coloraxis\":\"coloraxis\",\"name\":\"0\",\"texttemplate\":\"%{z}\",\"x\":[\"neutral\",\"happy\",\"sad\",\"angry\",\"fear\",\"disgust\",\"surprise\"],\"y\":[\"neutral\",\"happy\",\"sad\",\"angry\",\"fear\",\"disgust\",\"surprise\"],\"z\":[[208,13,27,3,3,12,0],[17,191,6,29,16,17,4],[30,7,197,0,17,24,4],[5,26,3,223,2,18,3],[6,36,52,9,158,17,2],[24,13,25,11,8,198,0],[0,2,1,0,0,0,86]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"Predicted: %{x}\\u003cbr\\u003eTrue: %{y}\\u003cbr\\u003eCount: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"scaleanchor\":\"y\",\"constrain\":\"domain\",\"title\":{\"text\":\"Predicted\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"autorange\":\"reversed\",\"constrain\":\"domain\",\"title\":{\"text\":\"True\"}},\"coloraxis\":{\"colorbar\":{\"title\":{\"text\":\"Count\"}},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]]},\"title\":{\"text\":\"Confusion Matrix\"},\"width\":600,\"height\":500},                        {\"responsive\": true}                    ).then(function(){\n                            \nvar gd = document.getElementById('0f3a9f4c-3b19-458c-b58a-b56efc143555');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })                };                            </script>        </div>\n</body>\n</html>"},"metadata":{}},{"output_type":"display_data","data":{"text/html":"<html>\n<head><meta charset=\"utf-8\" /></head>\n<body>\n    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"c23db263-662d-4371-b88c-12faa5143f76\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"c23db263-662d-4371-b88c-12faa5143f76\")) {                    Plotly.newPlot(                        \"c23db263-662d-4371-b88c-12faa5143f76\",                        [{\"x\":[\"neutral\",\"happy\",\"sad\",\"angry\",\"fear\",\"disgust\",\"surprise\"],\"y\":[0.7819548872180451,0.6821428571428572,0.7060931899641577,0.7964285714285714,0.5642857142857143,0.7096774193548387,0.9662921348314607],\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"yaxis\":{\"title\":{\"text\":\"Accuracy\"},\"range\":[0,1]},\"title\":{\"text\":\"Per-Class Accuracy\"},\"xaxis\":{\"title\":{\"text\":\"Emotion\"}}},                        {\"responsive\": true}                    ).then(function(){\n                            \nvar gd = document.getElementById('c23db263-662d-4371-b88c-12faa5143f76');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })                };                            </script>        </div>\n</body>\n</html>"},"metadata":{}}],"execution_count":22},{"cell_type":"markdown","source":"# ============================================\n# CELL 12: Feature Importance Analysis\n# ============================================","metadata":{}},{"cell_type":"code","source":"def extract_features_classical(file_paths, config):\n    \"\"\"Extract features for classical ML\"\"\"\n    features = []\n    \n    for path in tqdm(file_paths[:100], desc=\"Extracting features\"):  # Limit for demo\n        try:\n            y, sr = librosa.load(path, sr=config.sample_rate)\n            \n            # MFCC\n            mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=config.n_mfcc)\n            mfcc_mean = np.mean(mfcc, axis=1)\n            mfcc_std = np.std(mfcc, axis=1)\n            \n            # Chroma\n            chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n            chroma_mean = np.mean(chroma, axis=1)\n            chroma_std = np.std(chroma, axis=1)\n            \n            # Spectral features\n            spec_cent = np.mean(librosa.feature.spectral_centroid(y=y, sr=sr))\n            spec_bw = np.mean(librosa.feature.spectral_bandwidth(y=y, sr=sr))\n            rolloff = np.mean(librosa.feature.spectral_rolloff(y=y, sr=sr))\n            zcr = np.mean(librosa.feature.zero_crossing_rate(y))\n            \n            # Combine features\n            feature_vector = np.hstack([\n                mfcc_mean, mfcc_std,\n                chroma_mean, chroma_std,\n                spec_cent, spec_bw, rolloff, zcr\n            ])\n            \n            features.append(feature_vector)\n        except:\n            features.append(np.zeros(104))  # Default feature size\n    \n    return np.array(features)\n\n# Extract features for classical ML comparison\nprint(\"Extracting classical features for comparison...\")\nX_train_classical = extract_features_classical(X_train[:100], config)\ny_train_classical = y_train[:100]\n\n# Train Random Forest for comparison\nrf_model = RandomForestClassifier(n_estimators=100, random_state=42)\nrf_model.fit(X_train_classical, y_train_classical)\n\n# Feature importance\nfeature_names = (\n    [f'MFCC_{i}_mean' for i in range(config.n_mfcc)] +\n    [f'MFCC_{i}_std' for i in range(config.n_mfcc)] +\n    [f'Chroma_{i}_mean' for i in range(12)] +\n    [f'Chroma_{i}_std' for i in range(12)] +\n    ['Spec_Centroid', 'Spec_Bandwidth', 'Rolloff', 'ZCR']\n)\n\nimportances = rf_model.feature_importances_\ntop_features_idx = np.argsort(importances)[-20:]\n\nfig = go.Figure(data=[\n    go.Bar(\n        x=importances[top_features_idx],\n        y=[feature_names[i] for i in top_features_idx],\n        orientation='h'\n    )\n])\nfig.update_layout(\n    title=\"Top 20 Most Important Features (Random Forest)\",\n    xaxis_title=\"Importance\",\n    yaxis_title=\"Feature\",\n    height=500\n)\nfig.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T15:20:35.994066Z","iopub.execute_input":"2025-10-26T15:20:35.994655Z","iopub.status.idle":"2025-10-26T15:20:38.863496Z","shell.execute_reply.started":"2025-10-26T15:20:35.994632Z","shell.execute_reply":"2025-10-26T15:20:38.862901Z"}},"outputs":[{"name":"stdout","text":"Extracting classical features for comparison...\n","output_type":"stream"},{"name":"stderr","text":"Extracting features: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:02<00:00, 36.99it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/html":"<html>\n<head><meta charset=\"utf-8\" /></head>\n<body>\n    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"03124913-c986-4def-8b83-88fda580ce06\" class=\"plotly-graph-div\" style=\"height:500px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"03124913-c986-4def-8b83-88fda580ce06\")) {                    Plotly.newPlot(                        \"03124913-c986-4def-8b83-88fda580ce06\",                        [{\"orientation\":\"h\",\"x\":[0.011738304228711322,0.01181086616329872,0.011951192070078838,0.011965512885437856,0.012461818917456095,0.013101937953067827,0.013122993088117657,0.01359156187859313,0.013803261239903008,0.013913336241422852,0.014018329298864103,0.014198183430610155,0.014323364026694603,0.014935591940070393,0.015120594662525138,0.01679696461270434,0.01684707081824864,0.019415363002023567,0.021602755167548244,0.03682415380807073],\"y\":[\"MFCC_7_std\",\"MFCC_3_std\",\"Chroma_8_mean\",\"Chroma_6_std\",\"Chroma_0_std\",\"MFCC_19_std\",\"MFCC_7_mean\",\"MFCC_9_std\",\"MFCC_27_mean\",\"MFCC_38_mean\",\"MFCC_5_mean\",\"MFCC_25_std\",\"Chroma_5_mean\",\"MFCC_2_mean\",\"MFCC_19_mean\",\"MFCC_25_mean\",\"MFCC_0_std\",\"MFCC_3_mean\",\"MFCC_4_std\",\"MFCC_0_mean\"],\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"Top 20 Most Important Features (Random Forest)\"},\"xaxis\":{\"title\":{\"text\":\"Importance\"}},\"yaxis\":{\"title\":{\"text\":\"Feature\"}},\"height\":500},                        {\"responsive\": true}                    ).then(function(){\n                            \nvar gd = document.getElementById('03124913-c986-4def-8b83-88fda580ce06');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })                };                            </script>        </div>\n</body>\n</html>"},"metadata":{}}],"execution_count":24},{"cell_type":"markdown","source":"# ============================================\n# CELL 13: Model Interpretation (Attention Weights)\n# ============================================","metadata":{}},{"cell_type":"code","source":"# ============================================\n# CELL 13: Model Interpretation (MODIFIED)\n# ============================================\n\n# Since we're using ensemble, let's analyze ensemble weights\nif config.model_type == 'ensemble':\n    # Check if model is wrapped in DataParallel\n    if isinstance(model, DataParallel):\n        weights = model.module.weights\n    else:\n        weights = model.weights\n    \n    weights_normalized = F.softmax(weights, dim=0)\n    \n    print(\"Ensemble Model Weights:\")\n    print(f\"  CNN Weight: {weights_normalized[0].item():.3f}\")\n    print(f\"  LSTM Weight: {weights_normalized[1].item():.3f}\")\n    print(f\"  Transformer Weight: {weights_normalized[2].item():.3f}\")\n    \n    # Visualize ensemble weights\n    import plotly.graph_objects as go\n    \n    fig = go.Figure(data=[\n        go.Bar(\n            x=['CNN', 'LSTM', 'Transformer'],\n            y=weights_normalized.detach().cpu().numpy(),\n            marker_color=['blue', 'green', 'red']\n        )\n    ])\n    fig.update_layout(\n        title=\"Ensemble Model Contribution Weights\",\n        yaxis_title=\"Weight\",\n        yaxis_range=[0, 1]\n    )\n    fig.show()\n\n# Analyze common misclassifications\nprint(\"\\n\" + \"=\"*60)\nprint(\"Most Common Misclassifications:\")\nprint(\"=\"*60)\n\n# Create confusion pairs\nconfusion_pairs = []\nfor true_idx in range(len(cm)):\n    for pred_idx in range(len(cm)):\n        if true_idx != pred_idx and cm[true_idx, pred_idx] > 10:\n            true_emotion = emotion_names[true_idx]\n            pred_emotion = emotion_names[pred_idx]\n            count = cm[true_idx, pred_idx]\n            confusion_pairs.append((true_emotion, pred_emotion, count))\n\n# Sort by frequency\nconfusion_pairs.sort(key=lambda x: x[2], reverse=True)\n\nfor true_em, pred_em, count in confusion_pairs[:10]:\n    print(f\"  {true_em:10s} misclassified as {pred_em:10s}: {count} times\")\n\n# Success rate by emotion\nprint(\"\\n\" + \"=\"*60)\nprint(\"Performance Summary by Emotion:\")\nprint(\"=\"*60)\n\nperformance = []\nfor i, emotion in enumerate(emotion_names[:config.n_classes]):\n    if i < len(per_class_acc):\n        total = cm[i].sum()\n        correct = cm[i, i]\n        performance.append({\n            'Emotion': emotion,\n            'Accuracy': per_class_acc[i],\n            'Correct': correct,\n            'Total': total,\n            'Errors': total - correct\n        })\n\n# Sort by accuracy\nperformance.sort(key=lambda x: x['Accuracy'], reverse=True)\n\nprint(f\"{'Rank':<5} {'Emotion':<10} {'Accuracy':<10} {'Correct/Total':<15}\")\nprint(\"-\" * 50)\nfor rank, perf in enumerate(performance, 1):\n    print(f\"{rank:<5} {perf['Emotion']:<10} {perf['Accuracy']*100:>6.1f}%    {perf['Correct']:>3}/{perf['Total']:<3}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T15:23:32.123390Z","iopub.execute_input":"2025-10-26T15:23:32.123912Z","iopub.status.idle":"2025-10-26T15:23:32.143523Z","shell.execute_reply.started":"2025-10-26T15:23:32.123879Z","shell.execute_reply":"2025-10-26T15:23:32.142754Z"}},"outputs":[{"name":"stdout","text":"Ensemble Model Weights:\n  CNN Weight: 0.266\n  LSTM Weight: 0.510\n  Transformer Weight: 0.225\n","output_type":"stream"},{"output_type":"display_data","data":{"text/html":"<html>\n<head><meta charset=\"utf-8\" /></head>\n<body>\n    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"2ba61c40-d715-4497-929d-ba538e9f811f\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"2ba61c40-d715-4497-929d-ba538e9f811f\")) {                    Plotly.newPlot(                        \"2ba61c40-d715-4497-929d-ba538e9f811f\",                        [{\"marker\":{\"color\":[\"blue\",\"green\",\"red\"]},\"x\":[\"CNN\",\"LSTM\",\"Transformer\"],\"y\":[0.26555607,0.5099371,0.22450684],\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"yaxis\":{\"title\":{\"text\":\"Weight\"},\"range\":[0,1]},\"title\":{\"text\":\"Ensemble Model Contribution Weights\"}},                        {\"responsive\": true}                    ).then(function(){\n                            \nvar gd = document.getElementById('2ba61c40-d715-4497-929d-ba538e9f811f');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })                };                            </script>        </div>\n</body>\n</html>"},"metadata":{}},{"name":"stdout","text":"\n============================================================\nMost Common Misclassifications:\n============================================================\n  fear       misclassified as sad       : 52 times\n  fear       misclassified as happy     : 36 times\n  sad        misclassified as neutral   : 30 times\n  happy      misclassified as angry     : 29 times\n  neutral    misclassified as sad       : 27 times\n  angry      misclassified as happy     : 26 times\n  disgust    misclassified as sad       : 25 times\n  sad        misclassified as disgust   : 24 times\n  disgust    misclassified as neutral   : 24 times\n  angry      misclassified as disgust   : 18 times\n\n============================================================\nPerformance Summary by Emotion:\n============================================================\nRank  Emotion    Accuracy   Correct/Total  \n--------------------------------------------------\n1     surprise     96.6%     86/89 \n2     angry        79.6%    223/280\n3     neutral      78.2%    208/266\n4     disgust      71.0%    198/279\n5     sad          70.6%    197/279\n6     happy        68.2%    191/280\n7     fear         56.4%    158/280\n","output_type":"stream"}],"execution_count":26},{"cell_type":"markdown","source":"# ============================================\n# CELL 14: Error Analysis\n# ============================================","metadata":{}},{"cell_type":"code","source":"def error_analysis(preds, labels, probs, emotion_names):\n    \"\"\"Analyze model errors\"\"\"\n    \n    # Find misclassified samples\n    errors = preds != labels\n    error_indices = np.where(errors)[0]\n    \n    if len(error_indices) > 0:\n        print(f\"Total errors: {len(error_indices)} / {len(labels)} ({100*len(error_indices)/len(labels):.1f}%)\")\n        \n        # Confusion pairs\n        confusion_pairs = {}\n        for idx in error_indices:\n            true_label = emotion_names[labels[idx]]\n            pred_label = emotion_names[preds[idx]]\n            pair = f\"{true_label} -> {pred_label}\"\n            confusion_pairs[pair] = confusion_pairs.get(pair, 0) + 1\n        \n        # Most common confusions\n        sorted_pairs = sorted(confusion_pairs.items(), key=lambda x: x[1], reverse=True)\n        \n        print(\"\\nMost Common Confusions:\")\n        for pair, count in sorted_pairs[:10]:\n            print(f\"  {pair}: {count} times\")\n        \n        # Confidence analysis\n        correct_confidence = probs[~errors].max(axis=1).mean()\n        error_confidence = probs[errors].max(axis=1).mean()\n        \n        print(f\"\\nAverage Confidence:\")\n        print(f\"  Correct predictions: {correct_confidence:.3f}\")\n        print(f\"  Incorrect predictions: {error_confidence:.3f}\")\n        \n        # Plot confidence distribution\n        fig = go.Figure()\n        fig.add_trace(go.Histogram(\n            x=probs[~errors].max(axis=1),\n            name='Correct',\n            opacity=0.7,\n            nbinsx=30\n        ))\n        fig.add_trace(go.Histogram(\n            x=probs[errors].max(axis=1),\n            name='Incorrect',\n            opacity=0.7,\n            nbinsx=30\n        ))\n        fig.update_layout(\n            title=\"Confidence Distribution\",\n            xaxis_title=\"Confidence\",\n            yaxis_title=\"Count\",\n            barmode='overlay'\n        )\n        fig.show()\n\n# Perform error analysis\nerror_analysis(preds, labels, probs, emotion_names[:config.n_classes])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T15:24:01.281826Z","iopub.execute_input":"2025-10-26T15:24:01.282117Z","iopub.status.idle":"2025-10-26T15:24:01.303304Z","shell.execute_reply.started":"2025-10-26T15:24:01.282096Z","shell.execute_reply":"2025-10-26T15:24:01.302669Z"}},"outputs":[{"name":"stdout","text":"Total errors: 492 / 1753 (28.1%)\n\nMost Common Confusions:\n  fear -> sad: 52 times\n  fear -> happy: 36 times\n  sad -> neutral: 30 times\n  happy -> angry: 29 times\n  neutral -> sad: 27 times\n  angry -> happy: 26 times\n  disgust -> sad: 25 times\n  disgust -> neutral: 24 times\n  sad -> disgust: 24 times\n  angry -> disgust: 18 times\n\nAverage Confidence:\n  Correct predictions: 0.879\n  Incorrect predictions: 0.668\n","output_type":"stream"},{"output_type":"display_data","data":{"text/html":"<html>\n<head><meta charset=\"utf-8\" /></head>\n<body>\n    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"adcf52e3-f368-4529-a2fa-0f4b56a9fa2f\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"adcf52e3-f368-4529-a2fa-0f4b56a9fa2f\")) {                    Plotly.newPlot(                        \"adcf52e3-f368-4529-a2fa-0f4b56a9fa2f\",                        [{\"name\":\"Correct\",\"nbinsx\":30,\"opacity\":0.7,\"x\":[0.69906557,0.9999927,0.6214,0.9999943,0.99990904,0.8581228,0.99999976,0.9928427,0.9995115,0.99985933,0.653114,0.85970443,0.99999917,0.9316269,0.9449916,0.99999535,0.52143645,0.547552,0.99507564,0.9999939,0.67372274,0.6113575,0.44819784,0.9999975,0.9998678,0.9992219,1.0,0.9999714,0.9999958,0.99882966,0.9999989,0.86124736,0.40584812,0.9999093,0.36893585,0.65397394,0.4907569,0.88695633,0.9999989,0.9086109,0.86442846,0.5442195,0.9999876,0.94295853,0.6814408,0.34717762,0.72647,0.99933213,0.99999964,0.6425299,0.9999999,0.9543344,1.0,0.99940395,0.87922424,0.9999999,0.98618084,0.99954945,0.66056263,0.93255365,0.99911195,0.9999999,0.9048435,0.86650276,0.79009,0.81067634,0.9567845,0.99972326,0.9997714,0.9999974,0.99991643,0.44631982,0.9294584,0.9964539,0.9987727,0.5484828,0.52759683,0.75789964,0.95022315,0.99776864,0.9999999,0.44103578,0.89388955,0.84994304,0.99813336,0.9999995,0.91549826,0.9221297,0.9999951,0.99963844,0.9999999,0.96841866,0.6241395,0.99990773,0.9877857,0.4845135,0.9981135,0.9999975,0.8286634,0.7002082,0.99994695,0.67208445,0.63362473,0.9773417,0.9925107,0.97148794,0.99998677,0.9998543,0.6113585,0.89432466,0.95485336,0.94092435,0.9998996,0.9999989,0.9999931,0.9940501,0.8455033,0.7385766,0.524655,0.99999344,0.89487725,0.73330796,0.950157,0.88887215,0.9999999,0.9757228,0.9397076,0.9997559,0.9999715,0.9790703,0.7532697,0.5713522,0.9642046,0.9885473,0.99999964,0.9999825,0.9999747,0.97532994,1.0,0.9999989,0.9999995,0.7414754,0.999998,0.7318774,0.9998481,0.69838744,0.9993106,0.99998987,0.99972576,0.9999789,0.9981096,0.88247585,0.43792722,0.51018274,0.99928325,0.999744,0.96569544,0.578615,0.99854904,0.9999689,0.5186724,0.9999989,0.99986947,0.99999976,0.622258,0.7746599,0.99999464,0.99995744,0.9034042,0.99999726,0.99999976,0.99999845,0.7064297,0.9988405,0.69839734,0.99999785,0.6987769,0.977037,0.47035852,0.9998035,0.4254318,0.945619,0.94127554,0.38452408,0.99999964,0.99999917,0.73610723,0.9999999,0.8611893,0.99999905,0.60052353,0.758716,0.9999989,0.9998826,0.99999905,0.9999502,0.9993556,0.50928944,0.9999975,0.8935393,0.99999917,0.9999999,0.9999937,0.951061,0.6059229,0.790446,0.9999342,0.9999995,0.9986198,0.66900384,0.9999895,0.86899924,0.7601094,0.999998,0.9004553,0.99993825,0.6535506,0.9999715,0.9162261,0.99299556,0.42552903,0.91719276,0.7336891,0.98160213,0.9577404,0.9931537,0.655207,0.99999905,0.8759673,0.7747333,0.99886477,0.6810434,0.99999976,0.9999945,0.9999999,0.9999994,0.9987978,0.99998,0.47538158,0.9992404,0.99999547,0.72926337,0.9999335,0.99998343,0.24767435,0.9999678,0.9999995,0.58311397,0.9999999,0.5618117,0.99999964,0.7074798,0.72705734,0.9999999,0.5419818,0.99999976,0.99999416,1.0,0.9999995,0.2889675,0.8368799,0.999936,0.9999989,0.9999956,0.99999917,0.9988795,0.6732383,0.999997,0.9995247,0.48915395,0.7238992,0.51668817,0.69046247,0.88588893,0.9999993,0.84116787,1.0,0.60041845,0.99999976,0.59810543,0.9538255,0.99999845,0.8043913,0.9999999,0.99952364,0.9209791,0.99980694,0.9952668,0.92685944,0.72873676,0.99999964,0.9999844,0.9999906,0.99999714,0.9999995,0.8904503,0.59554553,0.99999917,0.99999976,0.4262802,0.66437304,0.9999956,0.9719448,0.96769387,0.99999917,0.8771667,0.78105885,0.9999994,0.9972161,0.9999994,0.96276885,0.7252644,0.99041814,0.5903348,0.8325722,0.5766769,0.999987,0.9999999,0.99999976,0.9067104,0.99997604,0.9999989,0.99961686,0.9999937,0.74027187,0.99999404,0.7446567,0.9999943,0.9999995,0.5592891,0.9999999,0.62575954,0.9995441,0.9999988,0.9999999,0.65122515,0.59999174,0.99999976,0.9554713,0.99999917,0.9999938,0.9999944,0.9828426,0.9617708,0.99992454,0.95232564,0.34387845,0.73883665,0.5491162,0.8603175,0.99999976,0.9970892,0.61367893,0.95199317,0.99999547,0.9973368,0.91356325,0.55810046,0.7572064,0.9789474,0.99999034,0.9998894,0.49861446,0.7993219,0.88630104,0.99996376,0.9822483,0.9999238,0.9926109,0.9999956,1.0,0.8084855,0.59246653,1.0,0.9999683,0.98455596,0.9998493,0.9998281,0.82291156,0.79963154,0.621663,0.746406,1.0,0.99998295,0.99796414,0.7345694,0.8986518,0.9647484,0.9999999,0.989664,0.9530182,1.0,0.8304495,0.99957305,0.9865645,0.99999845,0.99999917,0.99959725,0.9414122,0.9991984,1.0,0.99999976,0.9427129,0.9968219,0.96138555,0.6886241,0.9999552,0.9999981,0.74003655,0.84266686,0.5915697,0.9965519,0.99984276,0.81920046,0.5690525,0.58410704,0.99999833,0.9999988,1.0,0.7064969,0.99968493,0.4215842,0.8873887,0.73419166,1.0,0.9958081,0.9200425,0.99999774,0.76358867,0.99999356,0.99999964,0.9309283,0.9999999,0.9925938,0.99999964,0.9936718,0.99999416,0.9744844,0.7803939,0.9995521,0.90403163,0.999997,0.99999964,0.99842936,0.9999999,0.9880861,0.9233517,0.9999534,0.82834375,0.762033,0.99999785,0.44265282,0.89145476,0.9999118,0.99385756,0.9625058,0.7160659,0.99999046,0.48262492,0.9947061,0.99999976,0.99999976,0.99999976,0.8834533,0.99999714,0.51967,0.99659616,0.78877383,0.99999094,0.4999801,0.61204416,0.9999987,0.9999987,0.80669534,0.99999976,0.9030546,0.9995908,0.8005127,0.9999962,1.0,0.8054706,0.999253,0.7227706,0.99999845,0.5368555,0.9999988,0.97700363,0.9463342,0.9999989,0.9999869,0.9909865,0.9933089,0.9997274,0.9718238,0.99523157,0.99999917,0.7473422,0.6637669,0.9804621,0.99986005,0.927897,0.8252771,1.0,0.9999993,0.999997,0.7555357,0.99999595,0.7526258,0.9996463,0.46029776,0.78777,0.3769618,0.99996495,0.83160305,0.65797454,0.9999821,0.9999993,0.9996301,0.9933507,0.997789,0.99999976,0.9999641,0.4990776,0.9999895,0.9999534,0.9674928,0.9998734,0.6166936,0.9999547,0.99999964,0.89833885,0.9999993,0.9801191,0.9999994,0.98098594,0.746173,0.600898,0.99999976,0.99999833,0.6370084,0.99999905,0.62703604,0.99999356,0.9658144,0.9999937,0.90854317,0.566169,0.9999951,0.9998043,0.9999794,0.9999893,0.86030614,0.7505006,0.9999819,0.99999976,0.98955953,0.9365556,0.69190425,0.9999722,0.9996842,0.8719345,0.9825717,0.9998294,0.9998367,0.9948426,0.99988294,0.9999995,0.97570205,0.9999268,0.64477956,0.99999464,0.7613167,0.84750247,0.99848264,0.7114936,0.6210715,0.99984,0.99999976,0.9232502,0.8966209,0.95153534,0.3493956,0.9600566,0.9667068,0.61065614,0.7609391,1.0,0.9566782,0.9999995,0.62766576,0.9999995,0.9999995,0.74537057,0.9975441,0.99999964,0.9102161,0.506553,0.99995506,0.9999994,0.9990551,0.98575276,0.52835184,0.9122154,0.6754162,0.99881774,0.70162714,0.99017334,0.9742677,0.9999747,0.677998,0.42688435,0.9999993,0.99991584,0.99999964,0.99971706,0.9832155,0.77997756,0.9736632,0.9999981,0.8232795,1.0,0.99975663,0.7573654,0.70650256,0.84947467,0.88855916,0.99999547,0.8442894,0.4612836,0.9619746,0.9998516,0.8155458,0.8532934,0.62104553,0.9899567,0.7073325,0.99978596,1.0,0.8033761,0.9987085,0.99882776,0.99999976,0.9847894,0.6497306,0.99973005,0.9999733,0.99995863,0.6033049,0.61521554,0.62437505,0.98278,0.74528205,0.93666315,0.74880314,0.999998,0.48428795,0.9843424,0.9999981,0.99999976,0.8961287,0.8402441,0.99990106,0.8714891,0.6899987,0.41917127,0.9999999,0.8758462,0.9999745,0.99867886,0.93624526,0.88299537,1.0,0.9999999,0.99979275,0.99993515,0.65944296,0.784097,0.40200257,0.6494045,0.9248861,0.9999963,0.9999608,0.8409321,0.99999976,0.95785636,0.9999995,0.99978906,0.5005665,0.9999964,0.99999976,0.9992673,0.99988854,0.8375781,0.973572,0.94749016,0.9972121,0.9997987,0.99999833,0.93847686,0.9916134,0.6742126,0.9999155,0.96769285,0.812834,0.9949096,0.515811,0.87139654,0.8235189,0.98911244,0.8490384,0.97223556,0.9580054,0.9697846,0.60769975,0.758718,0.7661918,0.945297,0.99999964,0.9999958,0.9999944,0.99999714,0.80482817,0.9941282,0.97934306,0.5437938,0.994776,0.7356392,0.5439518,0.99946743,0.9525116,0.81765866,0.9982338,0.9999963,0.8297736,0.69061184,0.9999945,0.99697924,0.6778466,0.51505876,0.9184331,0.9754543,0.53363144,0.9999993,0.38511392,0.3855958,1.0,0.9996644,0.8812637,0.9999995,0.99999976,0.55249566,0.354859,0.6128507,0.9994174,0.999778,0.615584,0.69681525,0.66138595,0.953196,0.9999999,0.61686623,0.999967,0.9967527,0.9999969,0.99999774,0.9999999,0.9999037,0.9449568,0.69672745,0.99999976,0.87513596,0.99984,0.99993885,0.9999993,0.99044305,0.9998822,0.9999999,0.9830941,1.0,0.7622898,0.97426164,0.99999976,0.9999914,0.45294416,0.62469,0.9967534,0.7807018,0.9999999,0.9288055,0.9687585,1.0,0.99721366,0.9563027,0.9703067,0.999778,0.998939,0.9999988,0.40751025,0.9999987,0.87782335,0.9997892,0.9045082,0.9999993,0.99999964,0.93133616,0.9996308,0.99999976,0.97510934,0.99948716,0.99999785,0.9992236,0.999915,0.9999994,0.99998283,0.6270959,0.99868065,0.9999981,0.9999999,0.9984004,0.9999999,0.9994273,0.99999917,0.97571427,0.99994886,0.9999968,0.9877977,0.7312345,0.9999989,0.9987974,0.95627373,0.99999654,0.9999068,0.73197234,0.99999976,0.9999995,0.73559916,0.9999995,0.9999999,0.99984264,0.9903098,0.9999993,0.99999154,0.999961,0.966556,0.73055285,0.5535917,0.9999945,0.9999454,0.9999999,0.86335915,0.998005,0.99996805,0.99997413,0.9999999,0.80092055,0.99983466,0.82190347,0.43551177,0.9999474,0.99997294,1.0,0.99999845,0.9303243,0.9999273,0.99999774,0.99998415,0.48485464,0.9999832,1.0,0.5417398,0.5941401,0.4873973,0.9024322,0.9999999,1.0,0.8890008,0.5983506,0.99999416,0.99999964,0.35843974,0.9997117,0.98326933,0.7374556,0.99968255,0.99968696,0.9999999,0.5561016,0.68455154,0.47805494,0.9987676,0.9008613,0.7119645,0.9999999,0.96192056,0.952233,0.6154813,0.75207555,0.8312952,0.9329931,0.9999989,0.71747714,0.99999964,0.9798462,0.9999994,0.91890186,0.9999999,0.98478115,0.9999988,0.74771804,0.99956995,0.88150465,0.9999194,0.99994993,0.99320424,0.86776567,0.9971306,0.40998203,1.0,0.9989668,0.9962973,0.76269364,0.72033197,0.9545138,0.9999888,0.99999213,0.9877809,0.72142553,0.9823835,0.94703054,0.9991528,0.9999981,0.99999857,0.8061232,0.9983474,0.9999964,0.7204724,0.9999645,0.7836426,0.97278744,0.54089594,0.42158398,0.99999857,0.6257311,0.4438995,0.9999583,0.9995542,0.99999964,0.99999774,0.99106205,0.86992353,0.99999964,0.9998801,0.6462842,0.9973597,0.99999917,0.9793723,0.80723387,0.41906866,0.9999994,0.5572225,0.97457933,0.9999987,0.693047,0.9999989,0.6379282,0.99997675,0.66027236,0.9999428,0.97231054,0.4575755,0.7888743,0.7285673,0.3941374,0.9998024,0.9424771,0.92788714,0.79000616,0.99685234,0.79373395,0.9204363,0.99999905,0.9998543,0.9998795,0.52990675,0.9803155,0.3503617,0.29351228,0.72033936,0.99999845,0.683576,0.95619446,0.999382,0.5114641,0.6936434,0.9933356,0.99999654,0.99986243,0.99999976,0.9999964,0.79522324,0.7983898,0.66220134,0.9954964,0.9999999,0.57957166,0.7629229,0.5509144,0.58740324,0.62939996,0.99999785,0.99759763,0.68129253,0.99902785,0.5231895,0.9609892,0.999721,0.9998568,0.5164309,0.93715316,0.9042767,0.7189456,0.52924156,0.93765366,0.577226,0.9999949,0.82687616,0.99801874,0.99869007,0.99989986,0.9008998,0.999997,0.98359495,0.99971503,0.99999833,0.69288,0.99999976,0.99999976,0.99899274,0.71781987,0.99999976,0.99999905,0.9999989,0.99999845,0.9964142,0.999998,0.62632376,0.9999652,0.8552247,0.77885956,0.99999785,0.9999691,0.43845394,0.99999845,0.99983644,0.9999999,0.90242344,0.763203,0.5627276,0.50438434,0.69821954,0.9999995,0.9871344,0.69895196,0.9495306,0.99998724,0.99998426,0.99999166,0.7431122,0.7944736,0.9999989,0.94347,1.0,0.9990245,0.8017748,0.7560222,0.9999994,0.89798003,0.77891684,0.82018703,0.72546905,0.8805059,0.68096876,0.99999833,0.99997234,0.6992873,0.43459854,0.61884046,0.88540083,0.9999999,0.43942907,0.9980301,0.98436743,0.99999285,0.36579436,0.99999356,0.65189844,0.9921525,0.99964654,0.99479336,0.99989617,0.99978465,0.9856656,0.72824377,0.2794981,0.45978308,0.99938726,0.7557412,0.9999995,0.86125535,0.94678247,0.99762017,0.81501526,0.93814194,0.7502852,0.8439128,0.72890353,0.9999547,0.99999976,0.99999917,0.9999814,0.9988527,0.999681,0.7971307,0.96500325,0.6912509,0.99475795,0.99999547,0.99976844,0.48484483,0.81745565,0.96623516,0.94653255,0.9996512,0.9838225,0.99985456,0.9974936,0.9999993,0.99987817,0.9999318,0.6039875,0.99999833,0.99999845,0.9986204,0.99510807,0.99988794,0.978819,0.9290271,0.9999989,0.9953243,0.9671999,0.7994546,0.51768714,0.9149875,0.73002267,1.0,0.51839036,0.91343063,0.99999666,0.70422554,0.9999893,0.8518447,0.9999982,0.99939203,0.8129122,0.99999964,0.99999905,0.9527496,0.9432055,0.99999464,0.63506997,0.9999995,0.62724406,0.54142225,0.999944,0.45570335,0.99969864,0.49847656,0.85251796,0.61761755,0.99989355,0.99997663,0.9999999,0.9927659,0.9992131,0.6590217,0.99998224,0.9999999,0.8821023,0.8205093,0.83387,0.9999999,0.41449535,0.6253204,0.99999964,0.86842996,0.9933357,0.9999999,0.9933601,0.9984005,0.99999857,0.993455,0.9999875,0.97107095,0.88817954,0.62602633,1.0,0.99953294,0.9998783,0.9548047,0.99997973,0.9999974,0.8098585,0.99992514,0.8127551,0.99999857,0.9999993,0.99999964,0.46394432,0.9999814,0.6266654,0.9999994,1.0,0.6747539,0.99999607,0.99995196,0.39990443,0.81165487,0.7629113,0.99950194,0.9904834,0.66615635,0.73405474,0.49641323,0.59017885,0.75476855,0.9999999,1.0,0.99605286,0.99999774,0.85244095,0.8825221,0.999948,0.9999769,0.6958782,0.7876359,0.54991746,0.99999726,0.8240831,0.995891,0.99286544,0.4409092,0.7018631,0.9995136,0.9861801,0.99982125,0.67756486,0.97078776,0.9999943,0.99999964,0.9845953,0.7893136],\"type\":\"histogram\"},{\"name\":\"Incorrect\",\"nbinsx\":30,\"opacity\":0.7,\"x\":[0.958721,0.61271864,0.9867405,0.5660285,0.8528416,0.7740876,0.7079703,0.5704005,0.5448506,0.9368631,0.45623982,0.56562185,0.7198585,0.8865547,0.73245513,0.49643818,0.455146,0.5603787,0.5390869,0.8194644,0.7935693,0.5391675,0.71608704,0.45266458,0.53003615,0.8712314,0.48812854,0.8477332,0.9995453,0.99987316,0.9734002,0.62046295,0.5797037,0.53589815,0.4644035,0.84900177,0.5529599,0.5844971,0.5377934,0.247588,0.50003266,0.5895782,0.85567576,0.93731767,0.79423463,0.907373,0.5715873,0.8273742,0.6384361,0.88579035,0.46701732,0.9588938,0.6074952,0.520496,0.89650613,0.40311697,0.9369923,0.85450035,0.9995703,0.53270906,0.3933292,0.46421397,0.4730389,0.5896127,0.7587902,0.5536418,0.73269814,0.94187754,0.62826884,0.956788,0.5044451,0.6031623,0.80247235,0.5828645,0.7381322,0.8072149,0.5009095,0.3847779,0.948212,0.9866067,0.9860687,0.4512304,0.39815694,0.41452974,0.41495806,0.6004795,0.8184117,0.8343496,0.6415673,0.8568405,0.59610873,0.93620014,0.9935275,0.9255472,0.952181,0.923289,0.6984985,0.66242296,0.8597371,0.7735,0.9755157,0.8634379,0.59355783,0.76208085,0.7281212,0.39829567,0.506871,0.6390631,0.9974232,0.7230862,0.5834419,0.58635587,0.7090068,0.9820722,0.36383098,0.64684486,0.6610994,0.48128998,0.47676322,0.45514104,0.6768387,0.5041551,0.542161,0.9997644,0.43185264,0.77633566,0.549811,0.63858294,0.76678604,0.97500575,0.20974272,0.5765609,0.7056861,0.51205075,0.7211367,0.6789242,0.5099778,0.77543074,0.8634562,0.41758788,0.37510106,0.8811143,0.7764474,0.7895972,0.49379233,0.66316605,0.35874528,0.6173548,0.9905571,0.7818724,0.57337844,0.5292535,0.6966963,0.5464114,0.90532595,0.7164867,0.99771154,0.8576508,0.46895254,0.6613811,0.317197,0.76340723,0.77032703,0.9322536,0.66398823,0.45727682,0.54198134,0.65088695,0.5795837,0.4795707,0.56777096,0.90020907,0.50336105,0.6192789,0.40835747,0.9175156,0.35061726,0.4754544,0.43456426,0.9954052,0.616663,0.54047275,0.9283715,0.71703845,0.57488704,0.9491315,0.37417793,0.4728369,0.48433778,0.72023135,0.9619188,0.5230902,0.5573559,0.9872285,0.74277943,0.7435983,0.92345023,0.7945831,0.7465817,0.9864053,0.79262936,0.9321684,0.9871241,0.70776623,0.563482,0.74564266,0.5887783,0.9793155,0.9641822,0.46835274,0.667821,0.50446343,0.41477853,0.9460588,0.36503735,0.92408,0.582819,0.46790352,0.4688457,0.99938464,0.35823983,0.9866665,0.45121938,0.6718224,0.71430403,0.40823957,0.70783985,0.9170467,0.6948034,0.7160706,0.8269565,0.6130396,0.6735634,0.28841308,0.99977237,0.29950872,0.3640815,0.98513883,0.4645691,0.6104542,0.68129253,0.3850723,0.9934596,0.7384165,0.75754786,0.34893093,0.97872925,0.556941,0.5808004,0.21054132,0.28141326,0.91723776,0.7144916,0.591273,0.96797794,0.5721229,0.5418763,0.9994636,0.515804,0.59582895,0.9963146,0.973485,0.87661403,0.28705436,0.55160606,0.6313166,0.34128422,0.3874185,0.9024307,0.46698013,0.8685906,0.35383675,0.5809625,0.6448714,0.49455324,0.5836793,0.8069949,0.9498583,0.589519,0.34230953,0.7313634,0.85578173,0.98859626,0.49455225,0.43659163,0.6035664,0.43551397,0.63441765,0.495457,0.5935942,0.5292962,0.55456585,0.4607549,0.7887864,0.68807155,0.7748663,0.4627575,0.9878977,0.7527751,0.74137974,0.28423902,0.64228535,0.867478,0.78259385,0.88437694,0.3985342,0.6691199,0.8049737,0.9903296,0.53451335,0.9879353,0.659934,0.5095975,0.3732375,0.45233068,0.7385552,0.975947,0.66726524,0.6929039,0.6475304,0.96130764,0.90622395,0.39277574,0.49779668,0.3449854,0.48230726,0.9415053,0.920826,0.51341337,0.9391312,0.5882259,0.27011716,0.90365183,0.41182497,0.5927367,0.46575877,0.25735348,0.3254931,0.46905836,0.9998865,0.35939163,0.34710208,0.72417027,0.9936394,0.6908988,0.9986355,0.57819164,0.21803151,0.96049774,0.2300015,0.48935258,0.6595779,0.9187208,0.5128668,0.8611123,0.793674,0.55940145,0.5518503,0.43916452,0.76225555,0.83257484,0.66676193,0.90181565,0.39339563,0.9065304,0.9998714,0.99550325,0.6705443,0.9362702,0.9809884,0.48645854,0.61547303,0.72112507,0.9760601,0.9833143,0.6445434,0.3723687,0.96100724,0.69325453,0.54500264,0.34860265,0.92923635,0.60819936,0.3494839,0.4902637,0.8655871,0.7079721,0.5287209,0.5095258,0.47128955,0.4840889,0.64030075,0.7979602,0.5586345,0.7568876,0.8642323,0.5098273,0.58277524,0.5222894,0.6825268,0.48133498,0.72417045,0.76067466,0.46810165,0.76149154,0.5508464,0.8534171,0.9778661,0.3300099,0.6065607,0.98612624,0.81395036,0.8529089,0.5484871,0.42881325,0.54447174,0.8248653,0.79306465,0.4238103,0.79630965,0.8683221,0.7523648,0.55616534,0.45184475,0.8560552,0.91776943,0.58706564,0.78797686,0.34859833,0.96968746,0.57326883,0.55715615,0.975629,0.9948801,0.6820926,0.45123926,0.5754841,0.6311939,0.7387045,0.51499826,0.31774002,0.9889283,0.97452444,0.7374101,0.6326576,0.9178635,0.99587363,0.3437993,0.52931553,0.99503016,0.3204775,0.96974397,0.59442395,0.7451541,0.61080533,0.4535485,0.91938454,0.32833067,0.6765766,0.57738286,0.9947995,0.41829064,0.59433174,0.683789,0.30251923,0.7962871,0.5433895,0.9054141,0.68513566,0.2956734,0.29932678,0.49023196,0.90906715,0.32509175,0.4629905,0.55119467,0.59318614,0.70708466,0.29993692,0.99672616,0.54347914,0.6936295,0.85271704,0.5855392,0.53881365,0.9994993,0.46445367,0.398502,0.89508075,0.9250562,0.6946642,0.8206501],\"type\":\"histogram\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"Confidence Distribution\"},\"xaxis\":{\"title\":{\"text\":\"Confidence\"}},\"yaxis\":{\"title\":{\"text\":\"Count\"}},\"barmode\":\"overlay\"},                        {\"responsive\": true}                    ).then(function(){\n                            \nvar gd = document.getElementById('adcf52e3-f368-4529-a2fa-0f4b56a9fa2f');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })                };                            </script>        </div>\n</body>\n</html>"},"metadata":{}}],"execution_count":27},{"cell_type":"markdown","source":"# ============================================\n# CELL 15: Save Results and Model\n# ============================================","metadata":{}},{"cell_type":"code","source":"# Save results\nresults = {\n    'test_accuracy': accuracy,\n    'predictions': preds.tolist(),\n    'true_labels': labels.tolist(),\n    'probabilities': probs.tolist(),\n    'confusion_matrix': cm.tolist(),\n    'training_history': {\n        'train_losses': trainer.train_losses,\n        'val_losses': trainer.val_losses,\n        'train_accs': trainer.train_accs,\n        'val_accs': trainer.val_accs\n    }\n}\n\nwith open('/kaggle/working/results.json', 'w') as f:\n    json.dump(results, f)\n\nprint(\"Results saved to results.json\")\n\n# Save model for deployment\ntorch.save({\n    'model_state_dict': model.state_dict(),\n    'model_config': config,\n    'emotion_names': emotion_names[:config.n_classes],\n    'test_accuracy': accuracy\n}, '/kaggle/working/final_model.pth')\n\nprint(\"Model saved to final_model.pth\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T15:24:16.483630Z","iopub.execute_input":"2025-10-26T15:24:16.484261Z","iopub.status.idle":"2025-10-26T15:24:16.537943Z","shell.execute_reply.started":"2025-10-26T15:24:16.484234Z","shell.execute_reply":"2025-10-26T15:24:16.537317Z"}},"outputs":[{"name":"stdout","text":"Results saved to results.json\nModel saved to final_model.pth\n","output_type":"stream"}],"execution_count":28},{"cell_type":"markdown","source":"# ============================================\n# CELL 16: Generate Project Report\n# ============================================","metadata":{}},{"cell_type":"code","source":"report = f\"\"\"\n# Speech Emotion Recognition Project Report\n\n## 1. Project Overview\n- **Objective**: Develop a deep learning system for emotion recognition from speech\n- **Model Type**: {config.model_type.upper()}\n- **Number of Classes**: {config.n_classes}\n- **Total Samples**: {len(file_paths)}\n- **Train/Val/Test Split**: {config.train_size}/{config.val_size}/{config.test_size}\n\n## 2. Model Architecture\n- **Parameters**: {sum(p.numel() for p in model.parameters()):,}\n- **Input Features**: Mel-spectrogram ({config.n_mels} bins)\n- **Batch Size**: {config.batch_size}\n- **Learning Rate**: {config.learning_rate}\n- **Epochs Trained**: {len(trainer.train_losses)}\n\n## 3. Performance Results\n- **Test Accuracy**: {accuracy:.4f}\n- **Best Validation Accuracy**: {checkpoint['val_acc']:.2f}%\n\n## 4. Per-Class Performance\n\"\"\"\n\nfor i, emotion in enumerate(emotion_names[:config.n_classes]):\n    if i < len(per_class_acc):\n        report += f\"- {emotion}: {per_class_acc[i]:.3f}\\n\"\n\nreport += \"\"\"\n## 5. Key Findings\n1. The model successfully learns to distinguish between different emotions\n2. Some emotion pairs show higher confusion rates (see error analysis)\n3. Ensemble models generally perform better than individual architectures\n\n## 6. Future Improvements\n1. Implement data augmentation techniques (pitch shift, time stretch)\n2. Try pre-trained models (Wav2Vec2, HuBERT)\n3. Collect more diverse training data\n4. Implement real-time emotion recognition\n\n## 7. Technologies Used\n- **Deep Learning**: PyTorch, TorchAudio\n- **Audio Processing**: Librosa\n- **Visualization**: Plotly\n- **Environment**: Kaggle GPU\n\"\"\"\n\nprint(report)\n\n# Save report\nwith open('/kaggle/working/project_report.md', 'w') as f:\n    f.write(report)\n\nprint(\"\\nProject completed successfully! üéâ\")\nprint(\"Files saved:\")\nprint(\"- best_model.pth\")\nprint(\"- final_model.pth\")\nprint(\"- results.json\")\nprint(\"- project_report.md\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T15:24:25.430324Z","iopub.execute_input":"2025-10-26T15:24:25.430588Z","iopub.status.idle":"2025-10-26T15:24:25.437970Z","shell.execute_reply.started":"2025-10-26T15:24:25.430569Z","shell.execute_reply":"2025-10-26T15:24:25.437216Z"}},"outputs":[{"name":"stdout","text":"\n# Speech Emotion Recognition Project Report\n\n## 1. Project Overview\n- **Objective**: Develop a deep learning system for emotion recognition from speech\n- **Model Type**: ENSEMBLE\n- **Number of Classes**: 7\n- **Total Samples**: 11682\n- **Train/Val/Test Split**: 0.7/0.15/0.15\n\n## 2. Model Architecture\n- **Parameters**: 3,313,689\n- **Input Features**: Mel-spectrogram (128 bins)\n- **Batch Size**: 64\n- **Learning Rate**: 0.001\n- **Epochs Trained**: 37\n\n## 3. Performance Results\n- **Test Accuracy**: 0.7193\n- **Best Validation Accuracy**: 70.05%\n\n## 4. Per-Class Performance\n- neutral: 0.782\n- happy: 0.682\n- sad: 0.706\n- angry: 0.796\n- fear: 0.564\n- disgust: 0.710\n- surprise: 0.966\n\n## 5. Key Findings\n1. The model successfully learns to distinguish between different emotions\n2. Some emotion pairs show higher confusion rates (see error analysis)\n3. Ensemble models generally perform better than individual architectures\n\n## 6. Future Improvements\n1. Implement data augmentation techniques (pitch shift, time stretch)\n2. Try pre-trained models (Wav2Vec2, HuBERT)\n3. Collect more diverse training data\n4. Implement real-time emotion recognition\n\n## 7. Technologies Used\n- **Deep Learning**: PyTorch, TorchAudio\n- **Audio Processing**: Librosa\n- **Visualization**: Plotly\n- **Environment**: Kaggle GPU\n\n\nProject completed successfully! üéâ\nFiles saved:\n- best_model.pth\n- final_model.pth\n- results.json\n- project_report.md\n","output_type":"stream"}],"execution_count":29},{"cell_type":"markdown","source":"# Memory Management Tips for Kaggle\n\n```python\n# Add these between cells if you run out of memory\nimport gc\ngc.collect()\ntorch.cuda.empty_cache()\n\n# Monitor GPU usage\n!nvidia-smi\n\n# Clear variables\ndel train_loader, val_loader  # After training\n```","metadata":{}}]}
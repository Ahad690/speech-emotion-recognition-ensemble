{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-28T18:48:03.722808Z","iopub.execute_input":"2025-10-28T18:48:03.723026Z","iopub.status.idle":"2025-10-28T18:48:03.728205Z","shell.execute_reply.started":"2025-10-28T18:48:03.723010Z","shell.execute_reply":"2025-10-28T18:48:03.727363Z"}},"outputs":[],"execution_count":23},{"cell_type":"markdown","source":"# ============================================\n# CELL 1: Setup and Installation\n# ============================================","metadata":{}},{"cell_type":"code","source":"# ============================================\n# CELL 1: Setup and Installation (FINAL VERSION)\n# ============================================\n\"\"\"\nSpeech Emotion Recognition System\nFor: Speech Processing & ANN/DL Course\nAuthor: Ahad Imran\n\"\"\"\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Check what's already installed\nimport sys\nprint(f\"Python: {sys.version}\")\n\n# Check librosa\ntry:\n    import librosa\n    print(f\"âœ“ librosa {librosa.__version__}\")\nexcept:\n    print(\"Installing librosa...\")\n    !pip install -q librosa\n\n# Skip audiomentations - not critical, we have built-in augmentation\n\n# Import all required packages\nimport os\nimport gc\nimport random\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom pathlib import Path\nfrom tqdm.auto import tqdm\nfrom typing import Dict, List, Tuple, Optional\nimport pickle\nimport json\nfrom collections import Counter\n\n# Audio processing\nimport librosa\nimport librosa.display\nimport soundfile as sf\nimport IPython.display as ipd\n\n# Deep Learning\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader, random_split\nimport torchaudio\nimport torchaudio.transforms as T\n\n# Machine Learning\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Visualization\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\n# Set seeds\ndef set_seed(seed=42):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n\nset_seed(42)\n\n# Check GPU\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"\\nUsing device: {device}\")\nif torch.cuda.is_available():\n    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n\nprint(\"\\n Setup complete! Ready to proceed.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T18:48:03.728974Z","iopub.execute_input":"2025-10-28T18:48:03.729204Z","iopub.status.idle":"2025-10-28T18:48:03.747089Z","shell.execute_reply.started":"2025-10-28T18:48:03.729183Z","shell.execute_reply":"2025-10-28T18:48:03.746239Z"}},"outputs":[{"name":"stdout","text":"Python: 3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]\nâœ“ librosa 0.11.0\n\nUsing device: cuda\nGPU: Tesla T4\nMemory: 15.83 GB\n\n Setup complete! Ready to proceed.\n","output_type":"stream"}],"execution_count":24},{"cell_type":"markdown","source":"# ============================================\n# CELL 1a: Setup for Dual T4 GPUs\n# ============================================","metadata":{}},{"cell_type":"code","source":"from torch.nn.parallel import DataParallel\n\n# Check available GPUs\nprint(f\"GPUs available: {torch.cuda.device_count()}\")\nfor i in range(torch.cuda.device_count()):\n    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n    print(f\"Memory: {torch.cuda.get_device_properties(i).total_memory / 1e9:.2f} GB\")\n\nif torch.cuda.device_count() > 1:\n    print(\"\\nâœ… Multiple GPUs detected! Will use DataParallel for faster training.\")\nelse:\n    print(\"\\nâœ… Single GPU detected. Will proceed with standard training.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T18:48:03.747958Z","iopub.execute_input":"2025-10-28T18:48:03.748262Z","iopub.status.idle":"2025-10-28T18:48:03.759258Z","shell.execute_reply.started":"2025-10-28T18:48:03.748240Z","shell.execute_reply":"2025-10-28T18:48:03.758721Z"}},"outputs":[{"name":"stdout","text":"GPUs available: 2\nGPU 0: Tesla T4\nMemory: 15.83 GB\nGPU 1: Tesla T4\nMemory: 15.83 GB\n\nâœ… Multiple GPUs detected! Will use DataParallel for faster training.\n","output_type":"stream"}],"execution_count":25},{"cell_type":"markdown","source":"# ============================================\n# CELL 2: Download and Prepare Datasets\n# ============================================","metadata":{}},{"cell_type":"markdown","source":"To set up environment variables for the Kaggle API using Python, you can use the `os` module to assign your credentials directly in your script. This is especially useful when you donâ€™t want to rely on a `kaggle.json` file. Here's how to do it:\n\n---\n\n### ðŸ”‘ Step-by-Step: Set Kaggle API Key with `os.environ`\n\n```python\nimport os\n\n# Set your Kaggle credentials\nos.environ['KAGGLE_USERNAME'] = 'your_kaggle_username'\nos.environ['KAGGLE_KEY'] = 'your_kaggle_api_key'\n```\n\nReplace `'your_kaggle_username'` and `'your_kaggle_api_key'` with the actual values from your [Kaggle account settings](https://www.kaggle.com/settings).\n\n---\n\n### ðŸ“¦ Then You Can Download Datasets Like This\n\n```python\n!pip install kaggle\n\n# Example: Download Titanic dataset\n!kaggle competitions download -c titanic\n```\n\nThis will work in environments like Jupyter, Colab, or Kaggle Notebooks â€” as long as the API key is valid and you've accepted the competition rules (if required).\n\n## Usage Example\n```python\n# !kaggle competitions download -c titanic\n\n\n# import zipfile\n\n# with zipfile.ZipFile('/kaggle/working/titanic.zip', 'r') as zip_ref:\n#    zip_ref.extractall('/kaggle/working')\n```","metadata":{}},{"cell_type":"code","source":"\"\"\"\nUsing Kaggle datasets for emotion recognition\n\"\"\"\n\nimport os\nimport zipfile\nfrom pathlib import Path\n\n# Setup Kaggle API credentials using Secrets\ntry:\n    from kaggle_secrets import UserSecretsClient\n    user_secrets = UserSecretsClient()\n    \n    os.environ['KAGGLE_USERNAME'] = user_secrets.get_secret(\"kaggle_username\")\n    os.environ['KAGGLE_KEY'] = user_secrets.get_secret(\"kaggle_key\")\n    \n    print(\"âœ“ Kaggle API configured with secrets\")\n    api_available = True\nexcept Exception as e:\n    print(f\"âš ï¸ Kaggle secrets not found: {e}\")\n    print(\"Please add datasets via 'Add Data' button or configure secrets.\")\n    api_available = False\n\n# Create directory structure\nos.makedirs('/kaggle/working/data', exist_ok=True)\nos.makedirs('/kaggle/working/models', exist_ok=True)\nos.makedirs('/kaggle/working/results', exist_ok=True)\n\n# Check if datasets are already added via UI\ndatasets_found = False\nif os.path.exists('/kaggle/input/'):\n    input_datasets = os.listdir('/kaggle/input/')\n    if len(input_datasets) > 0:\n        print(\"Datasets found in /kaggle/input/:\")\n        for dataset in input_datasets:\n            print(f\"  âœ“ {dataset}\")\n        datasets_found = True\n        DATA_PATH = '/kaggle/input/'\n\n# Method 2: Download if not added via UI (only if API is available)\nif not datasets_found and api_available:  # <-- FIXED: Added api_available check\n    print(\"\\nNo datasets found in input. Downloading...\")\n    \n    # Only download if not already present\n    if not os.path.exists('/kaggle/working/ravdess'):\n        print(\"Downloading RAVDESS...\")\n        !kaggle datasets download -d uwrfkaggler/ravdess-emotional-speech-audio -p /kaggle/working --quiet\n        \n        if os.path.exists('/kaggle/working/ravdess-emotional-speech-audio.zip'):\n            with zipfile.ZipFile('/kaggle/working/ravdess-emotional-speech-audio.zip', 'r') as zip_ref:\n                zip_ref.extractall('/kaggle/working/ravdess')\n            os.remove('/kaggle/working/ravdess-emotional-speech-audio.zip')\n            print(\"âœ“ RAVDESS downloaded\")\n    \n    if not os.path.exists('/kaggle/working/tess'):\n        print(\"Downloading TESS...\")\n        !kaggle datasets download -d ejlok1/toronto-emotional-speech-set-tess -p /kaggle/working --quiet\n        \n        if os.path.exists('/kaggle/working/toronto-emotional-speech-set-tess.zip'):\n            with zipfile.ZipFile('/kaggle/working/toronto-emotional-speech-set-tess.zip', 'r') as zip_ref:\n                zip_ref.extractall('/kaggle/working/tess')\n            os.remove('/kaggle/working/toronto-emotional-speech-set-tess.zip')\n            print(\"âœ“ TESS downloaded\")\n    \n    if not os.path.exists('/kaggle/working/cremad'):\n        print(\"Downloading CREMA-D...\")\n        !kaggle datasets download -d ejlok1/cremad -p /kaggle/working --quiet\n        \n        if os.path.exists('/kaggle/working/cremad.zip'):\n            with zipfile.ZipFile('/kaggle/working/cremad.zip', 'r') as zip_ref:\n                zip_ref.extractall('/kaggle/working/cremad')\n            os.remove('/kaggle/working/cremad.zip')\n            print(\"âœ“ CREMA-D downloaded\")\n    \n    DATA_PATH = '/kaggle/working/'\n\nelif not datasets_found and not api_available:\n    print(\"\\nâš ï¸ No datasets found and API not configured.\")\n    print(\"Please either:\")\n    print(\"1. Add datasets using the 'Add Data' button, or\")\n    print(\"2. Configure Kaggle API secrets (kaggle_username and kaggle_key)\")\n    DATA_PATH = '/kaggle/working/'  # Set default path anyway\n\nelse:\n    # Datasets already found\n    pass\n\n# Verify final state\nprint(f\"\\nUsing DATA_PATH: {DATA_PATH}\")\nif os.path.exists(DATA_PATH):\n    contents = os.listdir(DATA_PATH)\n    if contents:\n        print(f\"Found {len(contents)} items in {DATA_PATH}\")\n    else:\n        print(\"âš ï¸ DATA_PATH is empty. Please add datasets.\")\n\nprint(\"\\n Setup complete!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T18:48:03.759955Z","iopub.execute_input":"2025-10-28T18:48:03.760111Z","iopub.status.idle":"2025-10-28T18:48:03.918832Z","shell.execute_reply.started":"2025-10-28T18:48:03.760098Z","shell.execute_reply":"2025-10-28T18:48:03.918154Z"}},"outputs":[{"name":"stdout","text":"âœ“ Kaggle API configured with secrets\n\nNo datasets found in input. Downloading...\n\nUsing DATA_PATH: /kaggle/working/\nFound 11 items in /kaggle/working/\n\n Setup complete!\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"# Quick Debug: Check what's actually in the directories\n# DEBUG CELL: Check dataset structure\nimport os\n\nfor dataset in ['ravdess', 'tess', 'cremad']:\n    path = f'/kaggle/working/{dataset}'\n    if os.path.exists(path):\n        print(f\"\\n{dataset.upper()} structure:\")\n        for root, dirs, files in os.walk(path):\n            level = root.replace(path, '').count(os.sep)\n            if level < 3:  # Only show first 3 levels\n                indent = ' ' * 2 * level\n                print(f\"{indent}{os.path.basename(root)}/\")\n                if level < 2:\n                    wav_files = [f for f in files if f.endswith('.wav')]\n                    if wav_files:\n                        print(f\"{indent}  [{len(wav_files)} .wav files]\")\n                        print(f\"{indent}  Sample: {wav_files[0]}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T18:48:03.919665Z","iopub.execute_input":"2025-10-28T18:48:03.919917Z","iopub.status.idle":"2025-10-28T18:48:03.942824Z","shell.execute_reply.started":"2025-10-28T18:48:03.919896Z","shell.execute_reply":"2025-10-28T18:48:03.942120Z"}},"outputs":[{"name":"stdout","text":"\nRAVDESS structure:\nravdess/\n  Actor_07/\n    [60 .wav files]\n    Sample: 03-01-05-01-01-01-07.wav\n  Actor_04/\n    [60 .wav files]\n    Sample: 03-01-03-01-02-02-04.wav\n  Actor_14/\n    [60 .wav files]\n    Sample: 03-01-07-02-02-02-14.wav\n  Actor_15/\n    [60 .wav files]\n    Sample: 03-01-05-02-01-02-15.wav\n  Actor_02/\n    [60 .wav files]\n    Sample: 03-01-08-01-02-02-02.wav\n  Actor_18/\n    [60 .wav files]\n    Sample: 03-01-08-01-02-01-18.wav\n  Actor_08/\n    [60 .wav files]\n    Sample: 03-01-07-02-01-01-08.wav\n  Actor_13/\n    [60 .wav files]\n    Sample: 03-01-08-01-02-02-13.wav\n  Actor_21/\n    [60 .wav files]\n    Sample: 03-01-07-02-02-01-21.wav\n  Actor_01/\n    [60 .wav files]\n    Sample: 03-01-02-02-01-01-01.wav\n  Actor_24/\n    [60 .wav files]\n    Sample: 03-01-08-01-01-01-24.wav\n  Actor_09/\n    [60 .wav files]\n    Sample: 03-01-03-01-01-01-09.wav\n  Actor_20/\n    [60 .wav files]\n    Sample: 03-01-02-01-02-02-20.wav\n  Actor_17/\n    [60 .wav files]\n    Sample: 03-01-02-02-01-02-17.wav\n  Actor_06/\n    [60 .wav files]\n    Sample: 03-01-02-02-02-02-06.wav\n  Actor_23/\n    [60 .wav files]\n    Sample: 03-01-06-01-02-01-23.wav\n  Actor_03/\n    [60 .wav files]\n    Sample: 03-01-07-01-01-01-03.wav\n  Actor_16/\n    [60 .wav files]\n    Sample: 03-01-08-02-01-02-16.wav\n  Actor_19/\n    [60 .wav files]\n    Sample: 03-01-02-01-01-01-19.wav\n  Actor_22/\n    [60 .wav files]\n    Sample: 03-01-08-02-01-01-22.wav\n  Actor_12/\n    [60 .wav files]\n    Sample: 03-01-07-02-01-01-12.wav\n  Actor_05/\n    [60 .wav files]\n    Sample: 03-01-08-02-01-02-05.wav\n  audio_speech_actors_01-24/\n    Actor_07/\n    Actor_04/\n    Actor_14/\n    Actor_15/\n    Actor_02/\n    Actor_18/\n    Actor_08/\n    Actor_13/\n    Actor_21/\n    Actor_01/\n    Actor_24/\n    Actor_09/\n    Actor_20/\n    Actor_17/\n    Actor_06/\n    Actor_23/\n    Actor_03/\n    Actor_16/\n    Actor_19/\n    Actor_22/\n    Actor_12/\n    Actor_05/\n    Actor_11/\n    Actor_10/\n  Actor_11/\n    [60 .wav files]\n    Sample: 03-01-04-01-01-02-11.wav\n  Actor_10/\n    [60 .wav files]\n    Sample: 03-01-05-01-02-02-10.wav\n\nTESS structure:\ntess/\n  tess toronto emotional speech set data/\n    TESS Toronto emotional speech set data/\n  TESS Toronto emotional speech set data/\n    YAF_fear/\n    OAF_angry/\n    OAF_happy/\n    YAF_neutral/\n    OAF_Fear/\n    YAF_sad/\n    OAF_Pleasant_surprise/\n    OAF_neutral/\n    YAF_happy/\n    OAF_Sad/\n    OAF_disgust/\n    YAF_disgust/\n    YAF_pleasant_surprised/\n    YAF_angry/\n\nCREMAD structure:\ncremad/\n  AudioWAV/\n    [7442 .wav files]\n    Sample: 1084_TAI_DIS_XX.wav\n","output_type":"stream"}],"execution_count":27},{"cell_type":"markdown","source":"# ============================================\n# CELL 3: Configuration\n# ============================================","metadata":{}},{"cell_type":"code","source":"# ============================================\n# CELL 3: OPTIMIZED Configuration for Dual T4\n# ============================================\nclass Config:\n    \"\"\"Configuration optimized for maximum GPU usage\"\"\"\n    \n    # Project\n    project_name = \"Speech Emotion Recognition\"\n    \n    # Data\n    sample_rate = 16000\n    duration = 3.0\n    n_classes = 8\n    \n    # Features\n    n_mfcc = 40\n    n_mels = 128\n    n_fft = 2048\n    hop_length = 512\n    \n    # Data splits\n    train_size = 0.7\n    val_size = 0.15\n    test_size = 0.15\n    \n    # OPTIMIZED Training for Dual T4\n    batch_size = 256  # INCREASED from 64 to 256!\n    epochs = 100\n    learning_rate = 1e-3\n    early_stopping_patience = 10\n    \n    # Enable gradient accumulation for even larger effective batch\n    gradient_accumulation_steps = 2  # Effective batch = 512\n    \n    # Model\n    model_type = 'ensemble'\n    dropout = 0.3\n    \n    # Augmentation\n    use_augmentation = True\n    augment_prob = 0.5\n    \n    # Performance optimization\n    num_workers = 4  # For faster data loading\n    pin_memory = True  # For faster GPU transfer\n    \n     # Paths\n    data_path = '/kaggle/working/'  # Or '/kaggle/input/' if using Add Data\n    save_path = '/kaggle/working/'\n    \nconfig = Config()\nprint(f\"âœ… Optimized config: Batch size {config.batch_size} (effective {config.batch_size * config.gradient_accumulation_steps})\")\nprint(\"âœ… Configuration loaded\")\nprint(f\"Model type: {config.model_type}\")\nprint(f\"Batch size: {config.batch_size}\")\nprint(f\"Epochs: {config.epochs}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T18:48:03.943583Z","iopub.execute_input":"2025-10-28T18:48:03.944337Z","iopub.status.idle":"2025-10-28T18:48:03.950551Z","shell.execute_reply.started":"2025-10-28T18:48:03.944307Z","shell.execute_reply":"2025-10-28T18:48:03.949759Z"}},"outputs":[{"name":"stdout","text":"âœ… Optimized config: Batch size 256 (effective 512)\nâœ… Configuration loaded\nModel type: ensemble\nBatch size: 256\nEpochs: 100\n","output_type":"stream"}],"execution_count":28},{"cell_type":"markdown","source":"# ============================================\n# CELL 4: Dataset Class with Memory Optimization\n# ============================================","metadata":{}},{"cell_type":"code","source":"class EmotionDataset(Dataset):\n    \"\"\"\n    Memory-efficient dataset for Kaggle\n    \"\"\"\n    \n    def __init__(\n        self, \n        file_paths: List[str],\n        labels: List[int],\n        config: Config,\n        transform=None,\n        augment=False\n    ):\n        self.file_paths = file_paths\n        self.labels = labels\n        self.config = config\n        self.transform = transform\n        self.augment = augment\n        \n        # Pre-calculate fixed length\n        self.target_length = int(config.sample_rate * config.duration)\n        \n    def __len__(self):\n        return len(self.file_paths)\n    \n    def __getitem__(self, idx):\n        # Load audio on-demand to save memory\n        audio_path = self.file_paths[idx]\n        label = self.labels[idx]\n        \n        try:\n            # Load audio\n            waveform, sr = librosa.load(audio_path, sr=self.config.sample_rate, mono=True)\n            \n            # Pad or truncate\n            if len(waveform) > self.target_length:\n                waveform = waveform[:self.target_length]\n            else:\n                waveform = np.pad(waveform, (0, self.target_length - len(waveform)))\n            \n            # Convert to tensor\n            waveform = torch.FloatTensor(waveform).unsqueeze(0)\n            \n            # Apply augmentation\n            if self.augment and random.random() < self.config.augment_prob:\n                waveform = self.augment_audio(waveform)\n            \n            # Extract features\n            features = self.extract_features(waveform)\n            \n            return features, label\n            \n        except Exception as e:\n            print(f\"Error loading {audio_path}: {e}\")\n            # Return zeros if error\n            return torch.zeros((self.config.n_mels, 94)), label\n    \n    def augment_audio(self, waveform):\n        \"\"\"Simple augmentation\"\"\"\n        # Add noise\n        if random.random() > 0.5:\n            noise = torch.randn_like(waveform) * 0.005\n            waveform = waveform + noise\n        \n        # Time shift\n        if random.random() > 0.5:\n            shift = int(random.uniform(-0.1, 0.1) * waveform.shape[1])\n            waveform = torch.roll(waveform, shift, dims=1)\n        \n        return waveform\n    \n    def extract_features(self, waveform):\n        \"\"\"Extract mel-spectrogram features\"\"\"\n        mel_transform = T.MelSpectrogram(\n            sample_rate=self.config.sample_rate,\n            n_mels=self.config.n_mels,\n            n_fft=self.config.n_fft,\n            hop_length=self.config.hop_length\n        )\n        \n        mel_spec = mel_transform(waveform)\n        mel_spec_db = T.AmplitudeToDB()(mel_spec)\n        \n        return mel_spec_db.squeeze(0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T18:48:03.951358Z","iopub.execute_input":"2025-10-28T18:48:03.951554Z","iopub.status.idle":"2025-10-28T18:48:03.964824Z","shell.execute_reply.started":"2025-10-28T18:48:03.951541Z","shell.execute_reply":"2025-10-28T18:48:03.964138Z"}},"outputs":[],"execution_count":29},{"cell_type":"markdown","source":"# ============================================\n# CELL 5: Data Loading and Preparation\n# ============================================","metadata":{}},{"cell_type":"code","source":"def prepare_data(config):\n    \"\"\"\n    Load and prepare datasets with correct paths\n    \"\"\"\n    all_files = []\n    all_labels = []\n    \n    # Emotion mapping\n    emotion_map = {\n        'neutral': 0, 'calm': 0,  # Merge calm into neutral\n        'happy': 1, 'sad': 2, 'angry': 3,\n        'fearful': 4, 'fear': 4,  # Handle variations\n        'disgust': 5, 'surprised': 6, 'surprise': 6\n    }\n    \n    base_path = Path('/kaggle/working')\n    \n    # RAVDESS dataset - files are in Actor_XX folders\n    ravdess_path = base_path / 'ravdess'\n    if ravdess_path.exists():\n        print(\"Loading RAVDESS dataset...\")\n        # Look for Actor folders\n        for actor_folder in ravdess_path.glob('Actor_*'):\n            if actor_folder.is_dir():\n                for audio_file in actor_folder.glob('*.wav'):\n                    # Parse RAVDESS filename (03-01-06-01-02-01-12.wav)\n                    parts = audio_file.stem.split('-')\n                    if len(parts) >= 3:\n                        emotion_code = int(parts[2])\n                        ravdess_emotions = {\n                            1: 'neutral', 2: 'calm', 3: 'happy', 4: 'sad',\n                            5: 'angry', 6: 'fear', 7: 'disgust', 8: 'surprise'\n                        }\n                        if emotion_code in ravdess_emotions:\n                            emotion = ravdess_emotions[emotion_code]\n                            all_files.append(str(audio_file))\n                            all_labels.append(emotion_map[emotion])\n        print(f\"  Found {len(all_files)} RAVDESS files\")\n    \n    # TESS dataset - files are in emotion-specific folders\n    tess_path = base_path / 'tess' / 'TESS Toronto emotional speech set data'\n    if tess_path.exists():\n        print(\"Loading TESS dataset...\")\n        initial_count = len(all_files)\n        \n        # TESS has folders like OAF_angry, YAF_happy, etc.\n        for emotion_folder in tess_path.glob('*'):\n            if emotion_folder.is_dir():\n                folder_name = emotion_folder.name.lower()\n                \n                # Extract emotion from folder name\n                if 'angry' in folder_name:\n                    emotion = 'angry'\n                elif 'disgust' in folder_name:\n                    emotion = 'disgust'\n                elif 'fear' in folder_name:\n                    emotion = 'fear'\n                elif 'happy' in folder_name:\n                    emotion = 'happy'\n                elif 'sad' in folder_name:\n                    emotion = 'sad'\n                elif 'neutral' in folder_name:\n                    emotion = 'neutral'\n                elif 'surprise' in folder_name or 'surprised' in folder_name:\n                    emotion = 'surprise'\n                else:\n                    continue  # Skip unknown folders\n                \n                # Add all wav files from this emotion folder\n                for audio_file in emotion_folder.glob('*.wav'):\n                    all_files.append(str(audio_file))\n                    all_labels.append(emotion_map[emotion])\n        \n        print(f\"  Found {len(all_files) - initial_count} TESS files\")\n    \n    # CREMA-D dataset - files are in AudioWAV folder\n    cremad_path = base_path / 'cremad' / 'AudioWAV'\n    if cremad_path.exists():\n        print(\"Loading CREMA-D dataset...\")\n        initial_count = len(all_files)\n        \n        for audio_file in cremad_path.glob('*.wav'):\n            # CREMA-D format: 1001_DFA_ANG_XX.wav\n            filename = audio_file.stem\n            if '_' in filename:\n                parts = filename.split('_')\n                if len(parts) >= 3:\n                    emotion_code = parts[2]\n                    cremad_emotions = {\n                        'ANG': 'angry', 'DIS': 'disgust', 'FEA': 'fear',\n                        'HAP': 'happy', 'NEU': 'neutral', 'SAD': 'sad'\n                    }\n                    if emotion_code in cremad_emotions:\n                        emotion = cremad_emotions[emotion_code]\n                        all_files.append(str(audio_file))\n                        all_labels.append(emotion_map[emotion])\n        \n        print(f\"  Found {len(all_files) - initial_count} CREMA-D files\")\n    \n    # Summary\n    if len(all_files) == 0:\n        print(\"\\nâš ï¸ No audio files found. Please check dataset paths.\")\n        print(\"Creating synthetic data for testing...\")\n        for i in range(100):\n            all_files.append(f\"dummy_{i}.wav\")\n            all_labels.append(random.randint(0, 6))\n    else:\n        print(f\"\\nâœ… Successfully loaded all datasets!\")\n    \n    print(f\"Total samples: {len(all_files)}\")\n    \n    # Show label distribution\n    label_counts = Counter(all_labels)\n    emotion_names = {v: k for k, v in emotion_map.items()}\n    print(\"\\nEmotion distribution:\")\n    for label, count in sorted(label_counts.items()):\n        emotion_name = [k for k, v in emotion_map.items() if v == label][0]\n        print(f\"  {emotion_name}: {count} samples\")\n    \n    # Update number of classes\n    config.n_classes = len(set(all_labels))\n    print(f\"\\nNumber of emotion classes: {config.n_classes}\")\n    \n    return all_files, all_labels\n\n# Load data with the fixed function\nfile_paths, labels = prepare_data(config)\n\n# Split data\nX_temp, X_test, y_temp, y_test = train_test_split(\n    file_paths, labels, test_size=config.test_size, \n    stratify=labels, random_state=42\n)\n\nX_train, X_val, y_train, y_val = train_test_split(\n    X_temp, y_temp, test_size=config.val_size/(1-config.test_size),\n    stratify=y_temp, random_state=42\n)\n\nprint(f\"\\nDataset splits:\")\nprint(f\"  Train: {len(X_train)} samples\")\nprint(f\"  Val: {len(X_val)} samples\")\nprint(f\"  Test: {len(X_test)} samples\")","metadata":{"execution":{"iopub.status.busy":"2025-10-28T18:48:03.965506Z","iopub.execute_input":"2025-10-28T18:48:03.965759Z","iopub.status.idle":"2025-10-28T18:48:04.045072Z","shell.execute_reply.started":"2025-10-28T18:48:03.965742Z","shell.execute_reply":"2025-10-28T18:48:04.044348Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Loading RAVDESS dataset...\n  Found 1440 RAVDESS files\nLoading TESS dataset...\n  Found 2800 TESS files\nLoading CREMA-D dataset...\n  Found 7442 CREMA-D files\n\nâœ… Successfully loaded all datasets!\nTotal samples: 11682\n\nEmotion distribution:\n  neutral: 1775 samples\n  happy: 1863 samples\n  sad: 1863 samples\n  angry: 1863 samples\n  fearful: 1863 samples\n  disgust: 1863 samples\n  surprised: 592 samples\n\nNumber of emotion classes: 7\n\nDataset splits:\n  Train: 8176 samples\n  Val: 1753 samples\n  Test: 1753 samples\n","output_type":"stream"}],"execution_count":30},{"cell_type":"markdown","source":"# ============================================\n# CELL 6: Model Architectures\n# ============================================","metadata":{}},{"cell_type":"code","source":"class CNNModel(nn.Module):\n    \"\"\"CNN for emotion recognition\"\"\"\n    \n    def __init__(self, config):\n        super().__init__()\n        \n        self.conv1 = nn.Sequential(\n            nn.Conv2d(1, 64, kernel_size=3, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.MaxPool2d(2)\n        )\n        \n        self.conv2 = nn.Sequential(\n            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(),\n            nn.MaxPool2d(2)\n        )\n        \n        self.conv3 = nn.Sequential(\n            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(),\n            nn.MaxPool2d(2)\n        )\n        \n        # Global pooling\n        self.global_pool = nn.AdaptiveAvgPool2d((1, 1))\n        \n        # Classifier\n        self.classifier = nn.Sequential(\n            nn.Linear(256, 128),\n            nn.ReLU(),\n            nn.Dropout(config.dropout),\n            nn.Linear(128, 64),\n            nn.ReLU(),\n            nn.Dropout(config.dropout),\n            nn.Linear(64, config.n_classes)\n        )\n        \n    def forward(self, x):\n        # Add channel dimension if needed\n        if x.dim() == 3:\n            x = x.unsqueeze(1)\n        \n        x = self.conv1(x)\n        x = self.conv2(x)\n        x = self.conv3(x)\n        x = self.global_pool(x)\n        x = x.view(x.size(0), -1)\n        x = self.classifier(x)\n        \n        return x\n\n\nclass LSTMModel(nn.Module):\n    \"\"\"LSTM for emotion recognition\"\"\"\n    \n    def __init__(self, config):\n        super().__init__()\n        \n        self.lstm = nn.LSTM(\n            input_size=config.n_mels,\n            hidden_size=128,\n            num_layers=2,\n            batch_first=True,\n            dropout=config.dropout,\n            bidirectional=True\n        )\n        \n        self.attention = nn.Sequential(\n            nn.Linear(256, 128),\n            nn.Tanh(),\n            nn.Linear(128, 1)\n        )\n        \n        self.classifier = nn.Sequential(\n            nn.Linear(256, 128),\n            nn.ReLU(),\n            nn.Dropout(config.dropout),\n            nn.Linear(128, config.n_classes)\n        )\n        \n    def forward(self, x):\n        # Reshape for LSTM (batch, time, features)\n        if x.dim() == 4:\n            x = x.squeeze(1)\n        x = x.transpose(1, 2)\n        \n        lstm_out, _ = self.lstm(x)\n        \n        # Attention\n        attn_weights = self.attention(lstm_out)\n        attn_weights = F.softmax(attn_weights, dim=1)\n        attended = torch.sum(lstm_out * attn_weights, dim=1)\n        \n        return self.classifier(attended)\n\n\nclass TransformerModel(nn.Module):\n    \"\"\"Transformer for emotion recognition\"\"\"\n    \n    def __init__(self, config):\n        super().__init__()\n        \n        self.input_projection = nn.Linear(config.n_mels, 256)\n        \n        encoder_layer = nn.TransformerEncoderLayer(\n            d_model=256,\n            nhead=8,\n            dim_feedforward=512,\n            dropout=config.dropout,\n            batch_first=True\n        )\n        \n        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=4)\n        \n        self.classifier = nn.Sequential(\n            nn.Linear(256, 128),\n            nn.ReLU(),\n            nn.Dropout(config.dropout),\n            nn.Linear(128, config.n_classes)\n        )\n        \n    def forward(self, x):\n        # Reshape (batch, time, features)\n        if x.dim() == 4:\n            x = x.squeeze(1)\n        x = x.transpose(1, 2)\n        \n        x = self.input_projection(x)\n        x = self.transformer(x)\n        \n        # Global average pooling\n        x = x.mean(dim=1)\n        \n        return self.classifier(x)\n\n\nclass EnsembleModel(nn.Module):\n    \"\"\"Ensemble of multiple models\"\"\"\n    \n    def __init__(self, config):\n        super().__init__()\n        \n        self.cnn = CNNModel(config)\n        self.lstm = LSTMModel(config)\n        self.transformer = TransformerModel(config)\n        \n        # Learnable weights for ensemble\n        self.weights = nn.Parameter(torch.ones(3) / 3)\n        \n    def forward(self, x):\n        cnn_out = self.cnn(x)\n        lstm_out = self.lstm(x)\n        transformer_out = self.transformer(x)\n        \n        # Weighted average\n        w = F.softmax(self.weights, dim=0)\n        output = w[0] * cnn_out + w[1] * lstm_out + w[2] * transformer_out\n        \n        return output\n\n    def augment_audio(self, waveform):\n        \"\"\"Enhanced augmentation for better generalization\"\"\"\n        \n        # Apply multiple augmentations\n        augmentations_applied = 0\n        \n        # 1. Add noise (30% chance)\n        if random.random() > 0.7:\n            noise_factor = random.uniform(0.002, 0.01)\n            noise = torch.randn_like(waveform) * noise_factor\n            waveform = waveform + noise\n            augmentations_applied += 1\n        \n        # 2. Time shift (30% chance)\n        if random.random() > 0.7:\n            shift = int(random.uniform(-0.2, 0.2) * waveform.shape[1])\n            waveform = torch.roll(waveform, shift, dims=1)\n            augmentations_applied += 1\n        \n        # 3. Speed change simulation (30% chance)\n        if random.random() > 0.7:\n            speed_factor = random.uniform(0.9, 1.1)\n            # Simple speed change by resampling\n            old_length = waveform.shape[1]\n            new_length = int(old_length * speed_factor)\n            indices = torch.linspace(0, old_length - 1, new_length).long()\n            waveform = waveform[:, indices]\n            # Pad or truncate back to original length\n            if waveform.shape[1] > old_length:\n                waveform = waveform[:, :old_length]\n            else:\n                padding = old_length - waveform.shape[1]\n                waveform = torch.nn.functional.pad(waveform, (0, padding))\n            augmentations_applied += 1\n        \n        # 4. Volume change (30% chance)\n        if random.random() > 0.7:\n            volume_factor = random.uniform(0.7, 1.3)\n            waveform = waveform * volume_factor\n            augmentations_applied += 1\n        \n        return waveform","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T18:48:04.045852Z","iopub.execute_input":"2025-10-28T18:48:04.046060Z","iopub.status.idle":"2025-10-28T18:48:04.063869Z","shell.execute_reply.started":"2025-10-28T18:48:04.046045Z","shell.execute_reply":"2025-10-28T18:48:04.063087Z"}},"outputs":[],"execution_count":31},{"cell_type":"markdown","source":"# ============================================\n# CELL 7: Training Functions\n# ============================================","metadata":{}},{"cell_type":"code","source":"# ============================================\n# CELL 7: IMPROVED Trainer with Better Scheduling\n# ============================================\nfrom torch.cuda.amp import autocast, GradScaler\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom tqdm import tqdm\nimport gc\n\nclass Trainer:\n    \"\"\"Training manager with improved learning rate scheduling\"\"\"\n    \n    def __init__(self, model, config, device):\n        self.model = model.to(device)\n        self.config = config\n        self.device = device\n        \n        self.criterion = nn.CrossEntropyLoss()\n        self.optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n        \n        # IMPROVED: Use Cosine Annealing with Warm Restarts for better convergence\n        self.scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n            self.optimizer, \n            T_0=10,  # Restart every 10 epochs\n            T_mult=2,  # Double the restart interval each time\n            eta_min=1e-6  # Minimum learning rate\n        )\n        \n        # Mixed precision for T4\n        self.scaler = GradScaler()\n        \n        self.train_losses = []\n        self.val_losses = []\n        self.train_accs = []\n        self.val_accs = []\n        \n    def train_epoch(self, dataloader):\n        self.model.train()\n        total_loss = 0\n        correct = 0\n        total = 0\n        \n        for batch_idx, (features, labels) in enumerate(tqdm(dataloader, desc=\"Training\")):\n            features = features.to(self.device)\n            labels = labels.to(self.device)\n            \n            self.optimizer.zero_grad()\n            \n            # Mixed precision training\n            with autocast():\n                outputs = self.model(features)\n                loss = self.criterion(outputs, labels)\n            \n            # Scaled backprop for mixed precision\n            self.scaler.scale(loss).backward()\n            \n            # Gradient clipping\n            self.scaler.unscale_(self.optimizer)\n            torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\n            \n            self.scaler.step(self.optimizer)\n            self.scaler.update()\n            \n            total_loss += loss.item()\n            _, predicted = outputs.max(1)\n            total += labels.size(0)\n            correct += predicted.eq(labels).sum().item()\n            \n            # Clear cache periodically\n            if batch_idx % 10 == 0:\n                torch.cuda.empty_cache()\n        \n        return total_loss / len(dataloader), 100. * correct / total\n    \n    def validate(self, dataloader):\n        self.model.eval()\n        total_loss = 0\n        correct = 0\n        total = 0\n        \n        with torch.no_grad():\n            with autocast():\n                for features, labels in tqdm(dataloader, desc=\"Validation\"):\n                    features = features.to(self.device)\n                    labels = labels.to(self.device)\n                    \n                    outputs = self.model(features)\n                    loss = self.criterion(outputs, labels)\n                    \n                    total_loss += loss.item()\n                    _, predicted = outputs.max(1)\n                    total += labels.size(0)\n                    correct += predicted.eq(labels).sum().item()\n        \n        return total_loss / len(dataloader), 100. * correct / total\n    \n    def fit(self, train_loader, val_loader):\n        best_val_acc = 0\n        patience_counter = 0\n        \n        for epoch in range(self.config.epochs):\n            print(f\"\\nEpoch {epoch+1}/{self.config.epochs}\")\n            \n            # Training\n            train_loss, train_acc = self.train_epoch(train_loader)\n            self.train_losses.append(train_loss)\n            self.train_accs.append(train_acc)\n            \n            # Validation\n            val_loss, val_acc = self.validate(val_loader)\n            self.val_losses.append(val_loss)\n            self.val_accs.append(val_acc)\n            \n            # IMPROVED: Step scheduler every epoch (for CosineAnnealingWarmRestarts)\n            self.scheduler.step()\n            current_lr = self.scheduler.get_last_lr()[0]\n            \n            print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n            print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n            print(f\"Learning Rate: {current_lr:.6f}\")\n            \n            # Save best model\n            if val_acc > best_val_acc:\n                best_val_acc = val_acc\n                torch.save({\n                    'epoch': epoch,\n                    'model_state_dict': self.model.state_dict(),\n                    'optimizer_state_dict': self.optimizer.state_dict(),\n                    'val_acc': val_acc,\n                    'config': self.config\n                }, '/kaggle/working/best_model.pth')\n                patience_counter = 0\n                print(f\"âœ“ Saved best model with {val_acc:.2f}% accuracy\")\n            else:\n                patience_counter += 1\n            \n            # Early stopping\n            if patience_counter >= self.config.early_stopping_patience:\n                print(f\"Early stopping at epoch {epoch+1}\")\n                break\n            \n            # Memory cleanup\n            gc.collect()\n            torch.cuda.empty_cache()\n        \n        return self.model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T18:48:04.064674Z","iopub.execute_input":"2025-10-28T18:48:04.065111Z","iopub.status.idle":"2025-10-28T18:48:04.084995Z","shell.execute_reply.started":"2025-10-28T18:48:04.065095Z","shell.execute_reply":"2025-10-28T18:48:04.084291Z"}},"outputs":[],"execution_count":32},{"cell_type":"markdown","source":"# ============================================\n# CELL 8: Create DataLoaders\n# ============================================","metadata":{}},{"cell_type":"code","source":"# ============================================\n# CELL 8: OPTIMIZED DataLoaders for Maximum GPU Usage\n# ============================================\n\n# Create datasets\ntrain_dataset = EmotionDataset(X_train, y_train, config, augment=True)\nval_dataset = EmotionDataset(X_val, y_val, config, augment=False)\ntest_dataset = EmotionDataset(X_test, y_test, config, augment=False)\n\n# OPTIMIZED DataLoaders\ntrain_loader = DataLoader(\n    train_dataset, \n    batch_size=config.batch_size,  # Now 256\n    shuffle=True, \n    num_workers=4,  # INCREASED from 0\n    pin_memory=True,  # Faster GPU transfer\n    prefetch_factor=2,  # Prefetch batches\n    persistent_workers=True  # Keep workers alive\n)\n\nval_loader = DataLoader(\n    val_dataset, \n    batch_size=config.batch_size * 2,  # Can use larger batch for validation\n    shuffle=False, \n    num_workers=4,\n    pin_memory=True,\n    persistent_workers=True\n)\n\ntest_loader = DataLoader(\n    test_dataset, \n    batch_size=config.batch_size * 2,\n    shuffle=False, \n    num_workers=4,\n    pin_memory=True,\n    persistent_workers=True\n)\n\nprint(f\"âœ… Optimized DataLoaders created!\")\nprint(f\"Train batches: {len(train_loader)}, Val batches: {len(val_loader)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T18:48:04.085831Z","iopub.execute_input":"2025-10-28T18:48:04.086617Z","iopub.status.idle":"2025-10-28T18:48:04.102400Z","shell.execute_reply.started":"2025-10-28T18:48:04.086570Z","shell.execute_reply":"2025-10-28T18:48:04.101850Z"}},"outputs":[{"name":"stdout","text":"âœ… Optimized DataLoaders created!\nTrain batches: 32, Val batches: 4\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"# ============================================\n# CELL 8a: GPU Monitoring (NEW CELL - Add after CELL 8)\n# ============================================\n\ndef monitor_gpu():\n    \"\"\"Monitor GPU usage\"\"\"\n    if torch.cuda.is_available():\n        print(\"\\n\" + \"=\"*60)\n        print(\"GPU STATUS BEFORE TRAINING:\")\n        print(\"=\"*60)\n        \n        for i in range(torch.cuda.device_count()):\n            props = torch.cuda.get_device_properties(i)\n            memory_allocated = torch.cuda.memory_allocated(i) / 1e9\n            memory_total = props.total_memory / 1e9\n            \n            print(f\"\\nGPU {i}: {props.name}\")\n            print(f\"  Memory: {memory_allocated:.2f}/{memory_total:.2f} GB allocated\")\n            print(f\"  Free: {memory_total - memory_allocated:.2f} GB\")\n\n# Monitor before training\nmonitor_gpu()\n\n# Check nvidia-smi\nprint(\"\\nNVIDIA-SMI Output:\")\n!nvidia-smi","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T18:48:04.103060Z","iopub.execute_input":"2025-10-28T18:48:04.103383Z","iopub.status.idle":"2025-10-28T18:48:04.390547Z","shell.execute_reply.started":"2025-10-28T18:48:04.103362Z","shell.execute_reply":"2025-10-28T18:48:04.389600Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nGPU STATUS BEFORE TRAINING:\n============================================================\n\nGPU 0: Tesla T4\n  Memory: 0.17/15.83 GB allocated\n  Free: 15.65 GB\n\nGPU 1: Tesla T4\n  Memory: 0.02/15.83 GB allocated\n  Free: 15.81 GB\n\nNVIDIA-SMI Output:\nTue Oct 28 18:48:04 2025       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n| N/A   67C    P0             28W /   70W |    1155MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n|   1  Tesla T4                       Off |   00000000:00:05.0 Off |                    0 |\n| N/A   77C    P0             35W /   70W |    1069MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n+-----------------------------------------------------------------------------------------+\n","output_type":"stream"}],"execution_count":34},{"cell_type":"markdown","source":"# ============================================\n# CELL 9: Train Model with DataParallel\n# ============================================","metadata":{}},{"cell_type":"code","source":"# ============================================\n# CELL 9a: Train Individual Models for Comparison\n# ============================================\n\nresults = {}\n\n# Train CNN only\nprint(\"Training CNN model...\")\nconfig.model_type = 'cnn'\nconfig.epochs = 50\ncnn_model = CNNModel(config)\ncnn_trainer = Trainer(cnn_model, config, device)\ncnn_trainer.fit(train_loader, val_loader)\nresults['CNN'] = max(cnn_trainer.val_accs)\n\n# Train LSTM only\nprint(\"\\nTraining LSTM model...\")\nconfig.model_type = 'lstm'\nlstm_model = LSTMModel(config)\nlstm_trainer = Trainer(lstm_model, config, device)\nlstm_trainer.fit(train_loader, val_loader)\nresults['LSTM'] = max(lstm_trainer.val_accs)\n\n# Train Transformer only\nprint(\"\\nTraining Transformer model...\")\nconfig.model_type = 'transformer'\ntransformer_model = TransformerModel(config)\ntransformer_trainer = Trainer(transformer_model, config, device)\ntransformer_trainer.fit(train_loader, val_loader)\nresults['Transformer'] = max(transformer_trainer.val_accs)\n\nprint(\"\\nIndividual Model Results:\")\nfor model_name, acc in results.items():\n    print(f\"  {model_name}: {acc:.2f}%\")\n\n# Now train ensemble\nprint(\"\\nTraining Ensemble model...\")\nconfig.model_type = 'ensemble'\nconfig.epochs = 100\n# Continue with original CELL 9...","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T18:48:04.391798Z","iopub.execute_input":"2025-10-28T18:48:04.392054Z","iopub.status.idle":"2025-10-28T19:18:03.108369Z","shell.execute_reply.started":"2025-10-28T18:48:04.392032Z","shell.execute_reply":"2025-10-28T19:18:03.107400Z"}},"outputs":[{"name":"stdout","text":"Training CNN model...\n\nEpoch 1/50\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:16<00:00,  1.96it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.7466, Train Acc: 29.98%\nVal Loss: 1.6106, Val Acc: 36.79%\nLearning Rate: 0.000976\nâœ“ Saved best model with 36.79% accuracy\n\nEpoch 2/50\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:16<00:00,  1.94it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.5813, Train Acc: 34.43%\nVal Loss: 1.4836, Val Acc: 37.88%\nLearning Rate: 0.000905\nâœ“ Saved best model with 37.88% accuracy\n\nEpoch 3/50\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:16<00:00,  1.98it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.5216, Train Acc: 36.95%\nVal Loss: 1.5275, Val Acc: 36.57%\nLearning Rate: 0.000794\n\nEpoch 4/50\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:17<00:00,  1.84it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.00s/it]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.4918, Train Acc: 38.20%\nVal Loss: 1.4016, Val Acc: 44.67%\nLearning Rate: 0.000655\nâœ“ Saved best model with 44.67% accuracy\n\nEpoch 5/50\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:18<00:00,  1.76it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.03s/it]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.4613, Train Acc: 39.52%\nVal Loss: 1.3638, Val Acc: 47.46%\nLearning Rate: 0.000501\nâœ“ Saved best model with 47.46% accuracy\n\nEpoch 6/50\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:18<00:00,  1.73it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.06s/it]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.4295, Train Acc: 41.63%\nVal Loss: 1.3238, Val Acc: 49.34%\nLearning Rate: 0.000346\nâœ“ Saved best model with 49.34% accuracy\n\nEpoch 7/50\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:17<00:00,  1.80it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.01s/it]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.4048, Train Acc: 42.94%\nVal Loss: 1.3466, Val Acc: 44.32%\nLearning Rate: 0.000207\n\nEpoch 8/50\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:17<00:00,  1.82it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.02s/it]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.3790, Train Acc: 45.17%\nVal Loss: 1.2994, Val Acc: 49.80%\nLearning Rate: 0.000096\nâœ“ Saved best model with 49.80% accuracy\n\nEpoch 9/50\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:17<00:00,  1.80it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.01it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.3572, Train Acc: 45.56%\nVal Loss: 1.2899, Val Acc: 52.03%\nLearning Rate: 0.000025\nâœ“ Saved best model with 52.03% accuracy\n\nEpoch 10/50\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:17<00:00,  1.80it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.02s/it]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.3472, Train Acc: 46.36%\nVal Loss: 1.2569, Val Acc: 51.74%\nLearning Rate: 0.001000\n\nEpoch 11/50\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.1121, Train Acc: 56.68%\nVal Loss: 1.5907, Val Acc: 45.35%\nLearning Rate: 0.000976\n\nEpoch 35/50\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:17<00:00,  1.88it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.04it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.0844, Train Acc: 58.64%\nVal Loss: 2.0873, Val Acc: 36.51%\nLearning Rate: 0.000962\n\nEpoch 36/50\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:16<00:00,  1.91it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.03it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.0688, Train Acc: 58.72%\nVal Loss: 1.3870, Val Acc: 46.95%\nLearning Rate: 0.000946\n\nEpoch 37/50\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:17<00:00,  1.83it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.01s/it]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.0738, Train Acc: 58.35%\nVal Loss: 1.2393, Val Acc: 55.16%\nLearning Rate: 0.000926\n\nEpoch 38/50\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:16<00:00,  1.90it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.03it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.0436, Train Acc: 60.19%\nVal Loss: 1.1620, Val Acc: 56.42%\nLearning Rate: 0.000905\nEarly stopping at epoch 38\n\nTraining LSTM model...\n\nEpoch 1/50\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:15<00:00,  2.06it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.6568, Train Acc: 33.32%\nVal Loss: 1.3668, Val Acc: 49.06%\nLearning Rate: 0.000976\nâœ“ Saved best model with 49.06% accuracy\n\nEpoch 2/50\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:15<00:00,  2.09it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.2585, Train Acc: 52.53%\nVal Loss: 1.2010, Val Acc: 52.60%\nLearning Rate: 0.000905\nâœ“ Saved best model with 52.60% accuracy\n\nEpoch 3/50\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:15<00:00,  2.08it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.1011, Train Acc: 57.84%\nVal Loss: 1.0928, Val Acc: 58.81%\nLearning Rate: 0.000794\nâœ“ Saved best model with 58.81% accuracy\n\nEpoch 4/50\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:15<00:00,  2.08it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.0270, Train Acc: 60.46%\nVal Loss: 1.0636, Val Acc: 58.76%\nLearning Rate: 0.000655\n\nEpoch 5/50\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:15<00:00,  2.03it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.9411, Train Acc: 64.32%\nVal Loss: 1.0762, Val Acc: 60.07%\nLearning Rate: 0.000501\nâœ“ Saved best model with 60.07% accuracy\n\nEpoch 6/50\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:15<00:00,  2.05it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.8874, Train Acc: 65.64%\nVal Loss: 0.9980, Val Acc: 62.52%\nLearning Rate: 0.000346\nâœ“ Saved best model with 62.52% accuracy\n\nEpoch 7/50\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:15<00:00,  2.06it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.8264, Train Acc: 69.26%\nVal Loss: 0.9867, Val Acc: 62.24%\nLearning Rate: 0.000207\n\nEpoch 8/50\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:15<00:00,  2.08it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.14it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.7786, Train Acc: 71.48%\nVal Loss: 0.9971, Val Acc: 63.03%\nLearning Rate: 0.000096\nâœ“ Saved best model with 63.03% accuracy\n\nEpoch 9/50\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:16<00:00,  1.97it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.10it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.7273, Train Acc: 73.37%\nVal Loss: 0.9917, Val Acc: 62.92%\nLearning Rate: 0.000025\n\nEpoch 10/50\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:15<00:00,  2.06it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.7077, Train Acc: 73.61%\nVal Loss: 0.9887, Val Acc: 63.38%\nLearning Rate: 0.001000\nâœ“ Saved best model with 63.38% accuracy\n\nEpoch 11/50\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:15<00:00,  2.04it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.8325, Train Acc: 68.77%\nVal Loss: 1.0247, Val Acc: 61.89%\nLearning Rate: 0.000994\n\nEpoch 12/50\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:15<00:00,  2.06it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.7957, Train Acc: 70.46%\nVal Loss: 0.9996, Val Acc: 63.32%\nLearning Rate: 0.000976\n\nEpoch 13/50\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:15<00:00,  2.06it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.7753, Train Acc: 70.58%\nVal Loss: 1.1363, Val Acc: 60.18%\nLearning Rate: 0.000946\n\nEpoch 14/50\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:15<00:00,  2.03it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.7574, Train Acc: 71.18%\nVal Loss: 0.9832, Val Acc: 64.18%\nLearning Rate: 0.000905\nâœ“ Saved best model with 64.18% accuracy\n\nEpoch 15/50\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:15<00:00,  2.05it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.7498, Train Acc: 71.60%\nVal Loss: 1.0307, Val Acc: 62.41%\nLearning Rate: 0.000854\n\nEpoch 16/50\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:16<00:00,  1.90it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.7055, Train Acc: 73.74%\nVal Loss: 1.0172, Val Acc: 63.38%\nLearning Rate: 0.000794\n\nEpoch 17/50\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:16<00:00,  1.97it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.14it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.6852, Train Acc: 74.08%\nVal Loss: 0.9942, Val Acc: 64.92%\nLearning Rate: 0.000727\nâœ“ Saved best model with 64.92% accuracy\n\nEpoch 18/50\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:15<00:00,  2.04it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.14it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.6331, Train Acc: 76.39%\nVal Loss: 1.0183, Val Acc: 63.38%\nLearning Rate: 0.000655\n\nEpoch 19/50\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:15<00:00,  2.07it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.6003, Train Acc: 77.79%\nVal Loss: 1.0303, Val Acc: 64.80%\nLearning Rate: 0.000579\n\nEpoch 20/50\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:15<00:00,  2.10it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.5691, Train Acc: 79.04%\nVal Loss: 1.0180, Val Acc: 64.92%\nLearning Rate: 0.000501\n\nEpoch 21/50\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:15<00:00,  2.08it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.14it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.5259, Train Acc: 80.99%\nVal Loss: 1.0892, Val Acc: 66.80%\nLearning Rate: 0.000422\nâœ“ Saved best model with 66.80% accuracy\n\nEpoch 22/50\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:15<00:00,  2.06it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.5012, Train Acc: 81.63%\nVal Loss: 1.0412, Val Acc: 65.89%\nLearning Rate: 0.000346\n\nEpoch 23/50\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:15<00:00,  2.08it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.4660, Train Acc: 82.88%\nVal Loss: 1.0844, Val Acc: 66.97%\nLearning Rate: 0.000274\nâœ“ Saved best model with 66.97% accuracy\n\nEpoch 24/50\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:15<00:00,  2.07it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.4324, Train Acc: 84.42%\nVal Loss: 1.0953, Val Acc: 66.40%\nLearning Rate: 0.000207\n\nEpoch 25/50\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:15<00:00,  2.08it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.4061, Train Acc: 85.32%\nVal Loss: 1.0886, Val Acc: 66.69%\nLearning Rate: 0.000147\n\nEpoch 26/50\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:15<00:00,  2.05it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.3900, Train Acc: 86.09%\nVal Loss: 1.0980, Val Acc: 67.26%\nLearning Rate: 0.000096\nâœ“ Saved best model with 67.26% accuracy\n\nEpoch 27/50\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:15<00:00,  2.04it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.3704, Train Acc: 86.59%\nVal Loss: 1.1167, Val Acc: 67.66%\nLearning Rate: 0.000055\nâœ“ Saved best model with 67.66% accuracy\n\nEpoch 28/50\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:15<00:00,  2.02it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.14it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.3555, Train Acc: 87.24%\nVal Loss: 1.1271, Val Acc: 67.14%\nLearning Rate: 0.000025\n\nEpoch 29/50\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:15<00:00,  2.03it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.14it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.3490, Train Acc: 87.23%\nVal Loss: 1.1285, Val Acc: 67.31%\nLearning Rate: 0.000007\n\nEpoch 30/50\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:15<00:00,  2.05it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.14it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.3376, Train Acc: 87.70%\nVal Loss: 1.1300, Val Acc: 67.26%\nLearning Rate: 0.001000\n\nEpoch 31/50\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:15<00:00,  2.04it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.4970, Train Acc: 81.24%\nVal Loss: 1.1513, Val Acc: 63.95%\nLearning Rate: 0.000998\n\nEpoch 32/50\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:15<00:00,  2.08it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.14it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.5511, Train Acc: 79.83%\nVal Loss: 1.1561, Val Acc: 64.58%\nLearning Rate: 0.000994\n\nEpoch 33/50\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:15<00:00,  2.04it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.5471, Train Acc: 79.50%\nVal Loss: 1.0785, Val Acc: 64.63%\nLearning Rate: 0.000986\n\nEpoch 34/50\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:16<00:00,  1.90it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.5408, Train Acc: 79.99%\nVal Loss: 1.0831, Val Acc: 64.86%\nLearning Rate: 0.000976\n\nEpoch 35/50\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:15<00:00,  2.04it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.5263, Train Acc: 80.34%\nVal Loss: 1.0927, Val Acc: 63.21%\nLearning Rate: 0.000962\n\nEpoch 36/50\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:15<00:00,  2.08it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.4951, Train Acc: 81.93%\nVal Loss: 1.1153, Val Acc: 63.95%\nLearning Rate: 0.000946\n\nEpoch 37/50\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:15<00:00,  2.07it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.4960, Train Acc: 81.51%\nVal Loss: 1.1414, Val Acc: 65.03%\nLearning Rate: 0.000926\nEarly stopping at epoch 37\n\nTraining Transformer model...\n\nEpoch 1/50\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:16<00:00,  1.97it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.6986, Train Acc: 29.43%\nVal Loss: 1.5210, Val Acc: 34.51%\nLearning Rate: 0.000976\nâœ“ Saved best model with 34.51% accuracy\n\nEpoch 2/50\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:16<00:00,  1.99it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.5061, Train Acc: 38.33%\nVal Loss: 1.4464, Val Acc: 42.73%\nLearning Rate: 0.000905\nâœ“ Saved best model with 42.73% accuracy\n\nEpoch 3/50\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:16<00:00,  2.00it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.4761, Train Acc: 40.84%\nVal Loss: 1.4265, Val Acc: 45.07%\nLearning Rate: 0.000794\nâœ“ Saved best model with 45.07% accuracy\n\nEpoch 4/50\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:16<00:00,  2.00it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.5194, Train Acc: 39.30%\nVal Loss: 1.5367, Val Acc: 36.97%\nLearning Rate: 0.000655\n\nEpoch 5/50\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:16<00:00,  1.96it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.5328, Train Acc: 37.90%\nVal Loss: 1.4780, Val Acc: 38.62%\nLearning Rate: 0.000501\n\nEpoch 6/50\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:15<00:00,  2.02it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.10it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.5029, Train Acc: 38.63%\nVal Loss: 1.4393, Val Acc: 43.70%\nLearning Rate: 0.000346\n\nEpoch 7/50\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:16<00:00,  1.99it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.4647, Train Acc: 41.65%\nVal Loss: 1.4497, Val Acc: 43.07%\nLearning Rate: 0.000207\n\nEpoch 8/50\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:15<00:00,  2.07it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.4541, Train Acc: 42.44%\nVal Loss: 1.4508, Val Acc: 43.30%\nLearning Rate: 0.000096\n\nEpoch 9/50\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:15<00:00,  2.05it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.4528, Train Acc: 42.86%\nVal Loss: 1.4416, Val Acc: 43.24%\nLearning Rate: 0.000025\n\nEpoch 10/50\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:15<00:00,  2.03it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.4507, Train Acc: 42.92%\nVal Loss: 1.4423, Val Acc: 43.07%\nLearning Rate: 0.001000\n\nEpoch 11/50\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:15<00:00,  2.04it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.4546, Train Acc: 42.55%\nVal Loss: 1.4391, Val Acc: 42.56%\nLearning Rate: 0.000994\n\nEpoch 12/50\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:15<00:00,  2.04it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.4534, Train Acc: 42.67%\nVal Loss: 1.4391, Val Acc: 42.56%\nLearning Rate: 0.000976\n\nEpoch 13/50\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:15<00:00,  2.02it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.03it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.4570, Train Acc: 42.78%\nVal Loss: 1.4391, Val Acc: 42.56%\nLearning Rate: 0.000946\nEarly stopping at epoch 13\n\nIndividual Model Results:\n  CNN: 62.01%\n  LSTM: 67.66%\n  Transformer: 45.07%\n\nTraining Ensemble model...\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"# ============================================\n# CELL 9: Train Model (FIXED VERSION)\n# ============================================\n\n# Clear any previous model to avoid conflicts\nif 'model' in globals():\n    del model\n    torch.cuda.empty_cache()\n\n# Select model based on config\nif config.model_type == 'cnn':\n    model = CNNModel(config)\nelif config.model_type == 'lstm':\n    model = LSTMModel(config)\nelif config.model_type == 'transformer':\n    model = TransformerModel(config)\nelse:  # ensemble\n    model = EnsembleModel(config)\n\nprint(f\"Model: {config.model_type}\")\nprint(f\"Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n\n# Use DataParallel if multiple GPUs available\nif torch.cuda.device_count() > 1:\n    print(f\"Using {torch.cuda.device_count()} GPUs!\")\n    # Check if model is already wrapped in DataParallel\n    if not isinstance(model, DataParallel):\n        model = DataParallel(model)\n        print(\"Model wrapped in DataParallel\")\n    else:\n        print(\"Model already using DataParallel\")\n\n# Move model to device\nmodel = model.to(device)\n\n# Warm up GPUs (optional)\nprint(\"Warming up GPUs...\")\ntry:\n    dummy_input = torch.randn(min(32, config.batch_size), config.n_mels, 94).to(device)\n    with torch.no_grad():\n        _ = model(dummy_input)\n    print(\"âœ… GPUs ready!\")\nexcept Exception as e:\n    print(f\"Warmup skipped: {e}\")\n\n# Check memory after model loading\nfor i in range(torch.cuda.device_count()):\n    allocated = torch.cuda.memory_allocated(i) / 1e9\n    print(f\"GPU {i}: {allocated:.2f} GB allocated\")\n\n# Create trainer and train\ntrainer = Trainer(model, config, device)\n\nprint(\"\\n\" + \"=\"*50)\nprint(\"Starting Training...\")\nprint(\"=\"*50)\n\ntrained_model = trainer.fit(train_loader, val_loader)\n\nprint(\"\\n\" + \"=\"*50)\nprint(\"Training Complete!\")\nprint(\"=\"*50)\n\n# Verify the model was saved\nimport os\nif os.path.exists('/kaggle/working/best_model.pth'):\n    print(\"âœ… Model saved successfully!\")\n    file_size = os.path.getsize('/kaggle/working/best_model.pth') / (1024*1024)\n    print(f\"Model file size: {file_size:.2f} MB\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T19:21:50.074793Z","iopub.execute_input":"2025-10-28T19:21:50.075519Z","iopub.status.idle":"2025-10-28T19:29:12.612683Z","shell.execute_reply.started":"2025-10-28T19:21:50.075492Z","shell.execute_reply":"2025-10-28T19:29:12.611817Z"}},"outputs":[{"name":"stdout","text":"Model: ensemble\nParameters: 3,313,689\nUsing 2 GPUs!\nModel wrapped in DataParallel\nWarming up GPUs...\nâœ… GPUs ready!\nGPU 0: 0.19 GB allocated\nGPU 1: 0.04 GB allocated\n\n==================================================\nStarting Training...\n==================================================\n\nEpoch 1/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:18<00:00,  1.76it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.03s/it]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.6208, Train Acc: 34.04%\nVal Loss: 1.3970, Val Acc: 44.50%\nLearning Rate: 0.000976\nâœ“ Saved best model with 44.50% accuracy\n\nEpoch 2/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:18<00:00,  1.69it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.06s/it]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.2893, Train Acc: 50.89%\nVal Loss: 1.2155, Val Acc: 55.05%\nLearning Rate: 0.000905\nâœ“ Saved best model with 55.05% accuracy\n\nEpoch 3/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:18<00:00,  1.71it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.00s/it]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.1620, Train Acc: 56.08%\nVal Loss: 1.1971, Val Acc: 54.93%\nLearning Rate: 0.000794\n\nEpoch 4/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:18<00:00,  1.77it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.01s/it]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.0673, Train Acc: 59.45%\nVal Loss: 1.0527, Val Acc: 59.90%\nLearning Rate: 0.000655\nâœ“ Saved best model with 59.90% accuracy\n\nEpoch 5/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:17<00:00,  1.80it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.02it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.9909, Train Acc: 62.65%\nVal Loss: 1.1057, Val Acc: 57.22%\nLearning Rate: 0.000501\n\nEpoch 6/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:17<00:00,  1.80it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.03it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.9348, Train Acc: 64.71%\nVal Loss: 1.0135, Val Acc: 60.35%\nLearning Rate: 0.000346\nâœ“ Saved best model with 60.35% accuracy\n\nEpoch 7/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:17<00:00,  1.81it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.02it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.8644, Train Acc: 68.04%\nVal Loss: 0.9825, Val Acc: 63.15%\nLearning Rate: 0.000207\nâœ“ Saved best model with 63.15% accuracy\n\nEpoch 8/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:17<00:00,  1.81it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.01it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.8170, Train Acc: 69.78%\nVal Loss: 0.9941, Val Acc: 63.15%\nLearning Rate: 0.000096\n\nEpoch 9/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:17<00:00,  1.80it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.00s/it]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.7742, Train Acc: 71.59%\nVal Loss: 0.9841, Val Acc: 62.98%\nLearning Rate: 0.000025\n\nEpoch 10/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:17<00:00,  1.85it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.03it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.7427, Train Acc: 72.68%\nVal Loss: 0.9796, Val Acc: 63.72%\nLearning Rate: 0.001000\nâœ“ Saved best model with 63.72% accuracy\n\nEpoch 11/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:17<00:00,  1.85it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.8681, Train Acc: 67.42%\nVal Loss: 1.0147, Val Acc: 62.92%\nLearning Rate: 0.000994\n\nEpoch 12/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:17<00:00,  1.86it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.8515, Train Acc: 68.05%\nVal Loss: 1.0153, Val Acc: 62.12%\nLearning Rate: 0.000976\n\nEpoch 13/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:17<00:00,  1.84it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.8621, Train Acc: 68.14%\nVal Loss: 1.2220, Val Acc: 55.90%\nLearning Rate: 0.000946\n\nEpoch 14/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:17<00:00,  1.86it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.9816, Train Acc: 64.22%\nVal Loss: 1.2414, Val Acc: 55.68%\nLearning Rate: 0.000905\n\nEpoch 15/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:17<00:00,  1.85it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.07it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.0046, Train Acc: 62.81%\nVal Loss: 1.2438, Val Acc: 55.56%\nLearning Rate: 0.000854\n\nEpoch 16/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:17<00:00,  1.85it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.04it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.0061, Train Acc: 63.28%\nVal Loss: 1.2422, Val Acc: 55.50%\nLearning Rate: 0.000794\n\nEpoch 17/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:16<00:00,  1.88it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.02it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.0052, Train Acc: 63.49%\nVal Loss: 1.2424, Val Acc: 55.68%\nLearning Rate: 0.000727\n\nEpoch 18/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:17<00:00,  1.86it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.11s/it]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.9997, Train Acc: 63.42%\nVal Loss: 1.2425, Val Acc: 55.45%\nLearning Rate: 0.000655\n\nEpoch 19/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:18<00:00,  1.75it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.00s/it]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.0086, Train Acc: 62.99%\nVal Loss: 1.2444, Val Acc: 55.39%\nLearning Rate: 0.000579\n\nEpoch 20/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:19<00:00,  1.64it/s]\nValidation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.03s/it]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.9961, Train Acc: 63.54%\nVal Loss: 1.2423, Val Acc: 55.73%\nLearning Rate: 0.000501\nEarly stopping at epoch 20\n\n==================================================\nTraining Complete!\n==================================================\nâœ… Model saved successfully!\nModel file size: 38.04 MB\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":37},{"cell_type":"markdown","source":"# ============================================\n# CELL 10: Evaluation and Visualization\n# ============================================","metadata":{}},{"cell_type":"code","source":"def evaluate_model(model, test_loader, device):\n    \"\"\"Comprehensive model evaluation\"\"\"\n    model.eval()\n    all_preds = []\n    all_labels = []\n    all_probs = []\n    \n    with torch.no_grad():\n        for features, labels in tqdm(test_loader, desc=\"Testing\"):\n            features = features.to(device)\n            outputs = model(features)\n            probs = F.softmax(outputs, dim=1)\n            _, predicted = outputs.max(1)\n            \n            all_preds.extend(predicted.cpu().numpy())\n            all_labels.extend(labels.numpy())\n            all_probs.extend(probs.cpu().numpy())\n    \n    return np.array(all_preds), np.array(all_labels), np.array(all_probs)\n\n# Load best model - FIXED for PyTorch 2.6\ncheckpoint = torch.load('/kaggle/working/best_model.pth', weights_only=False)  # <-- Added weights_only=False\nmodel.load_state_dict(checkpoint['model_state_dict'])\nprint(f\"âœ… Loaded best model from epoch {checkpoint['epoch']} with {checkpoint['val_acc']:.2f}% validation accuracy\")\n\n# Evaluate on test set\nprint(\"\\nEvaluating on test set...\")\npreds, labels, probs = evaluate_model(model, test_loader, device)\n\n# Calculate metrics\naccuracy = accuracy_score(labels, preds)\nprint(f\"\\nðŸŽ¯ Test Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n\n# Classification report\nemotion_names = ['neutral', 'happy', 'sad', 'angry', 'fear', 'disgust', 'surprise']\nprint(\"\\n\" + \"=\"*60)\nprint(\"Classification Report:\")\nprint(\"=\"*60)\nprint(classification_report(labels, preds, target_names=emotion_names[:config.n_classes], digits=3))\n\n# Confusion Matrix\ncm = confusion_matrix(labels, preds)\nprint(\"\\n\" + \"=\"*60)\nprint(\"Confusion Matrix:\")\nprint(\"=\"*60)\nprint(cm)\n\n# Calculate per-class accuracy\nper_class_acc = cm.diagonal() / cm.sum(axis=1)\nprint(\"\\n\" + \"=\"*60)\nprint(\"Per-Class Accuracy:\")\nprint(\"=\"*60)\nfor i, emotion in enumerate(emotion_names[:config.n_classes]):\n    if i < len(per_class_acc):\n        print(f\"  {emotion:10s}: {per_class_acc[i]:.3f} ({per_class_acc[i]*100:.1f}%)\")\n\nprint(\"\\nâœ… Evaluation complete!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T19:29:23.233707Z","iopub.execute_input":"2025-10-28T19:29:23.233983Z","iopub.status.idle":"2025-10-28T19:29:28.047843Z","shell.execute_reply.started":"2025-10-28T19:29:23.233964Z","shell.execute_reply":"2025-10-28T19:29:28.046520Z"}},"outputs":[{"name":"stdout","text":"âœ… Loaded best model from epoch 9 with 63.72% validation accuracy\n\nEvaluating on test set...\n","output_type":"stream"},{"name":"stderr","text":"Testing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.18s/it]","output_type":"stream"},{"name":"stdout","text":"\nðŸŽ¯ Test Accuracy: 0.6674 (66.74%)\n\n============================================================\nClassification Report:\n============================================================\n              precision    recall  f1-score   support\n\n     neutral      0.642     0.748     0.691       266\n       happy      0.609     0.611     0.610       280\n         sad      0.639     0.652     0.645       279\n       angry      0.811     0.768     0.789       280\n        fear      0.625     0.582     0.603       280\n     disgust      0.622     0.577     0.599       279\n    surprise      0.859     0.888     0.873        89\n\n    accuracy                          0.667      1753\n   macro avg      0.686     0.689     0.687      1753\nweighted avg      0.668     0.667     0.667      1753\n\n\n============================================================\nConfusion Matrix:\n============================================================\n[[199  10  24   2   6  25   0]\n [ 20 171   7  21  33  23   5]\n [ 46   7 182   1  28  13   2]\n [  6  27   1 215  11  16   4]\n [ 10  39  43   7 163  18   0]\n [ 26  25  28  19  18 161   2]\n [  3   2   0   0   2   3  79]]\n\n============================================================\nPer-Class Accuracy:\n============================================================\n  neutral   : 0.748 (74.8%)\n  happy     : 0.611 (61.1%)\n  sad       : 0.652 (65.2%)\n  angry     : 0.768 (76.8%)\n  fear      : 0.582 (58.2%)\n  disgust   : 0.577 (57.7%)\n  surprise  : 0.888 (88.8%)\n\nâœ… Evaluation complete!\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":38},{"cell_type":"markdown","source":"# ============================================\n# CELL 11: Advanced Visualizations\n# ============================================","metadata":{}},{"cell_type":"code","source":"# 1. Training History\nfig = make_subplots(\n    rows=1, cols=2,\n    subplot_titles=('Loss', 'Accuracy')\n)\n\nfig.add_trace(\n    go.Scatter(y=trainer.train_losses, name='Train Loss', mode='lines'),\n    row=1, col=1\n)\nfig.add_trace(\n    go.Scatter(y=trainer.val_losses, name='Val Loss', mode='lines'),\n    row=1, col=1\n)\n\nfig.add_trace(\n    go.Scatter(y=trainer.train_accs, name='Train Acc', mode='lines'),\n    row=1, col=2\n)\nfig.add_trace(\n    go.Scatter(y=trainer.val_accs, name='Val Acc', mode='lines'),\n    row=1, col=2\n)\n\nfig.update_layout(height=400, title_text=\"Training History\")\nfig.show()\n\n# 2. Confusion Matrix Heatmap\nfig = px.imshow(\n    cm,\n    labels=dict(x=\"Predicted\", y=\"True\", color=\"Count\"),\n    x=emotion_names[:config.n_classes],\n    y=emotion_names[:config.n_classes],\n    title=\"Confusion Matrix\",\n    color_continuous_scale=\"Blues\",\n    text_auto=True\n)\nfig.update_layout(width=600, height=500)\nfig.show()\n\n# 3. Per-class Performance\nper_class_acc = cm.diagonal() / cm.sum(axis=1)\nfig = go.Figure(data=[\n    go.Bar(x=emotion_names[:config.n_classes], y=per_class_acc)\n])\nfig.update_layout(\n    title=\"Per-Class Accuracy\",\n    xaxis_title=\"Emotion\",\n    yaxis_title=\"Accuracy\",\n    yaxis_range=[0, 1]\n)\nfig.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T19:29:52.900001Z","iopub.execute_input":"2025-10-28T19:29:52.900532Z","iopub.status.idle":"2025-10-28T19:29:52.966795Z","shell.execute_reply.started":"2025-10-28T19:29:52.900509Z","shell.execute_reply":"2025-10-28T19:29:52.965958Z"}},"outputs":[{"output_type":"display_data","data":{"text/html":"<html>\n<head><meta charset=\"utf-8\" /></head>\n<body>\n    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"00573354-097f-4d79-b757-cd3e6fcdd0d8\" class=\"plotly-graph-div\" style=\"height:400px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"00573354-097f-4d79-b757-cd3e6fcdd0d8\")) {                    Plotly.newPlot(                        \"00573354-097f-4d79-b757-cd3e6fcdd0d8\",                        [{\"mode\":\"lines\",\"name\":\"Train Loss\",\"y\":[1.6207882761955261,1.289320107549429,1.1620099022984505,1.067304264754057,0.9909080117940903,0.9347588773816824,0.8643601518124342,0.8169616721570492,0.774207940325141,0.7427203115075827,0.8681384176015854,0.8515231423079967,0.8620864376425743,0.9815754797309637,1.0046296510845423,1.0061030499637127,1.0052243880927563,0.9997031930834055,1.0085618384182453,0.996122857555747],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"mode\":\"lines\",\"name\":\"Val Loss\",\"y\":[1.3969776332378387,1.2154716849327087,1.1970695853233337,1.0526669025421143,1.1056523621082306,1.0135348439216614,0.9824796617031097,0.9940596520900726,0.984062522649765,0.9795873314142227,1.0146623253822327,1.0153067857027054,1.2220382392406464,1.2414079010486603,1.2437956929206848,1.2421647608280182,1.2423922419548035,1.2424885034561157,1.244399607181549,1.242268443107605],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"mode\":\"lines\",\"name\":\"Train Acc\",\"y\":[34.038649706457925,50.892857142857146,56.07876712328767,59.45450097847358,62.646771037182,64.71379647749511,68.04060665362036,69.77739726027397,71.5875733855186,72.67612524461839,67.41682974559687,68.05283757338552,68.13845401174169,64.22455968688845,62.80577299412916,63.282778864970645,63.490704500978474,63.41731898238748,62.989236790606654,63.53962818003914],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"mode\":\"lines\",\"name\":\"Val Acc\",\"y\":[44.49515116942384,55.04848830576155,54.9343981745579,59.89731888191672,57.216200798630915,60.35367940673132,63.148887621220766,63.148887621220766,62.977752424415286,63.71933827723902,62.92070735881346,62.12207644038791,55.90416428978893,55.67598402738163,55.56189389617798,55.50484883057616,55.67598402738163,55.44780376497433,55.390758699372505,55.73302909298346],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.45]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0]},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.55,1.0]},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.0,1.0]},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Loss\",\"x\":0.225,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Accuracy\",\"x\":0.775,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"title\":{\"text\":\"Training History\"},\"height\":400},                        {\"responsive\": true}                    ).then(function(){\n                            \nvar gd = document.getElementById('00573354-097f-4d79-b757-cd3e6fcdd0d8');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })                };                            </script>        </div>\n</body>\n</html>"},"metadata":{}},{"output_type":"display_data","data":{"text/html":"<html>\n<head><meta charset=\"utf-8\" /></head>\n<body>\n    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"c63a1f86-3607-4d8a-8ae6-1eedbd52aca8\" class=\"plotly-graph-div\" style=\"height:500px; width:600px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"c63a1f86-3607-4d8a-8ae6-1eedbd52aca8\")) {                    Plotly.newPlot(                        \"c63a1f86-3607-4d8a-8ae6-1eedbd52aca8\",                        [{\"coloraxis\":\"coloraxis\",\"name\":\"0\",\"texttemplate\":\"%{z}\",\"x\":[\"neutral\",\"happy\",\"sad\",\"angry\",\"fear\",\"disgust\",\"surprise\"],\"y\":[\"neutral\",\"happy\",\"sad\",\"angry\",\"fear\",\"disgust\",\"surprise\"],\"z\":[[199,10,24,2,6,25,0],[20,171,7,21,33,23,5],[46,7,182,1,28,13,2],[6,27,1,215,11,16,4],[10,39,43,7,163,18,0],[26,25,28,19,18,161,2],[3,2,0,0,2,3,79]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"Predicted: %{x}\\u003cbr\\u003eTrue: %{y}\\u003cbr\\u003eCount: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"scaleanchor\":\"y\",\"constrain\":\"domain\",\"title\":{\"text\":\"Predicted\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"autorange\":\"reversed\",\"constrain\":\"domain\",\"title\":{\"text\":\"True\"}},\"coloraxis\":{\"colorbar\":{\"title\":{\"text\":\"Count\"}},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]]},\"title\":{\"text\":\"Confusion Matrix\"},\"width\":600,\"height\":500},                        {\"responsive\": true}                    ).then(function(){\n                            \nvar gd = document.getElementById('c63a1f86-3607-4d8a-8ae6-1eedbd52aca8');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })                };                            </script>        </div>\n</body>\n</html>"},"metadata":{}},{"output_type":"display_data","data":{"text/html":"<html>\n<head><meta charset=\"utf-8\" /></head>\n<body>\n    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"c86c9520-82ff-47dc-bd47-545b5f5419e3\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"c86c9520-82ff-47dc-bd47-545b5f5419e3\")) {                    Plotly.newPlot(                        \"c86c9520-82ff-47dc-bd47-545b5f5419e3\",                        [{\"x\":[\"neutral\",\"happy\",\"sad\",\"angry\",\"fear\",\"disgust\",\"surprise\"],\"y\":[0.7481203007518797,0.6107142857142858,0.6523297491039427,0.7678571428571429,0.5821428571428572,0.5770609318996416,0.8876404494382022],\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"yaxis\":{\"title\":{\"text\":\"Accuracy\"},\"range\":[0,1]},\"title\":{\"text\":\"Per-Class Accuracy\"},\"xaxis\":{\"title\":{\"text\":\"Emotion\"}}},                        {\"responsive\": true}                    ).then(function(){\n                            \nvar gd = document.getElementById('c86c9520-82ff-47dc-bd47-545b5f5419e3');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })                };                            </script>        </div>\n</body>\n</html>"},"metadata":{}}],"execution_count":40},{"cell_type":"markdown","source":"# ============================================\n# CELL 12: Feature Importance Analysis\n# ============================================","metadata":{}},{"cell_type":"code","source":"def extract_features_classical(file_paths, config):\n    \"\"\"Extract features for classical ML\"\"\"\n    features = []\n    \n    for path in tqdm(file_paths[:100], desc=\"Extracting features\"):  # Limit for demo\n        try:\n            y, sr = librosa.load(path, sr=config.sample_rate)\n            \n            # MFCC\n            mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=config.n_mfcc)\n            mfcc_mean = np.mean(mfcc, axis=1)\n            mfcc_std = np.std(mfcc, axis=1)\n            \n            # Chroma\n            chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n            chroma_mean = np.mean(chroma, axis=1)\n            chroma_std = np.std(chroma, axis=1)\n            \n            # Spectral features\n            spec_cent = np.mean(librosa.feature.spectral_centroid(y=y, sr=sr))\n            spec_bw = np.mean(librosa.feature.spectral_bandwidth(y=y, sr=sr))\n            rolloff = np.mean(librosa.feature.spectral_rolloff(y=y, sr=sr))\n            zcr = np.mean(librosa.feature.zero_crossing_rate(y))\n            \n            # Combine features\n            feature_vector = np.hstack([\n                mfcc_mean, mfcc_std,\n                chroma_mean, chroma_std,\n                spec_cent, spec_bw, rolloff, zcr\n            ])\n            \n            features.append(feature_vector)\n        except:\n            features.append(np.zeros(104))  # Default feature size\n    \n    return np.array(features)\n\n# Extract features for classical ML comparison\nprint(\"Extracting classical features for comparison...\")\nX_train_classical = extract_features_classical(X_train[:100], config)\ny_train_classical = y_train[:100]\n\n# Train Random Forest for comparison\nrf_model = RandomForestClassifier(n_estimators=100, random_state=42)\nrf_model.fit(X_train_classical, y_train_classical)\n\n# Feature importance\nfeature_names = (\n    [f'MFCC_{i}_mean' for i in range(config.n_mfcc)] +\n    [f'MFCC_{i}_std' for i in range(config.n_mfcc)] +\n    [f'Chroma_{i}_mean' for i in range(12)] +\n    [f'Chroma_{i}_std' for i in range(12)] +\n    ['Spec_Centroid', 'Spec_Bandwidth', 'Rolloff', 'ZCR']\n)\n\nimportances = rf_model.feature_importances_\ntop_features_idx = np.argsort(importances)[-20:]\n\nfig = go.Figure(data=[\n    go.Bar(\n        x=importances[top_features_idx],\n        y=[feature_names[i] for i in top_features_idx],\n        orientation='h'\n    )\n])\nfig.update_layout(\n    title=\"Top 20 Most Important Features (Random Forest)\",\n    xaxis_title=\"Importance\",\n    yaxis_title=\"Feature\",\n    height=500\n)\nfig.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T19:30:00.273917Z","iopub.execute_input":"2025-10-28T19:30:00.274204Z","iopub.status.idle":"2025-10-28T19:30:03.566563Z","shell.execute_reply.started":"2025-10-28T19:30:00.274184Z","shell.execute_reply":"2025-10-28T19:30:03.565692Z"}},"outputs":[{"name":"stdout","text":"Extracting classical features for comparison...\n","output_type":"stream"},{"name":"stderr","text":"Extracting features: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:03<00:00, 32.38it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/html":"<html>\n<head><meta charset=\"utf-8\" /></head>\n<body>\n    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"6b89402b-06be-46a1-8da3-231f1cff3865\" class=\"plotly-graph-div\" style=\"height:500px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"6b89402b-06be-46a1-8da3-231f1cff3865\")) {                    Plotly.newPlot(                        \"6b89402b-06be-46a1-8da3-231f1cff3865\",                        [{\"orientation\":\"h\",\"x\":[0.011978125793042464,0.012149219480128601,0.012167562576717318,0.012250043602171112,0.012380699356668523,0.012400065821714285,0.012517040093740195,0.012626544362753775,0.012647726436507998,0.012652320227622312,0.012870107665084368,0.01335794176219209,0.013394090196004805,0.014783108038074933,0.015243644798776386,0.016242659640218406,0.016822921524466915,0.017654415915216867,0.01880828742871719,0.020367075701720475],\"y\":[\"MFCC_10_mean\",\"ZCR\",\"MFCC_18_std\",\"Chroma_4_mean\",\"MFCC_13_std\",\"MFCC_24_mean\",\"MFCC_21_std\",\"MFCC_2_std\",\"Spec_Bandwidth\",\"Chroma_0_std\",\"MFCC_34_mean\",\"MFCC_33_mean\",\"MFCC_23_std\",\"MFCC_24_std\",\"MFCC_4_std\",\"MFCC_22_std\",\"MFCC_18_mean\",\"MFCC_20_mean\",\"MFCC_0_mean\",\"MFCC_26_std\"],\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"Top 20 Most Important Features (Random Forest)\"},\"xaxis\":{\"title\":{\"text\":\"Importance\"}},\"yaxis\":{\"title\":{\"text\":\"Feature\"}},\"height\":500},                        {\"responsive\": true}                    ).then(function(){\n                            \nvar gd = document.getElementById('6b89402b-06be-46a1-8da3-231f1cff3865');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })                };                            </script>        </div>\n</body>\n</html>"},"metadata":{}}],"execution_count":41},{"cell_type":"markdown","source":"# ============================================\n# CELL 13: Model Interpretation (Attention Weights)\n# ============================================","metadata":{}},{"cell_type":"code","source":"# ============================================\n# CELL 13: Model Interpretation (MODIFIED)\n# ============================================\n\n# Since we're using ensemble, let's analyze ensemble weights\nif config.model_type == 'ensemble':\n    # Check if model is wrapped in DataParallel\n    if isinstance(model, DataParallel):\n        weights = model.module.weights\n    else:\n        weights = model.weights\n    \n    weights_normalized = F.softmax(weights, dim=0)\n    \n    print(\"Ensemble Model Weights:\")\n    print(f\"  CNN Weight: {weights_normalized[0].item():.3f}\")\n    print(f\"  LSTM Weight: {weights_normalized[1].item():.3f}\")\n    print(f\"  Transformer Weight: {weights_normalized[2].item():.3f}\")\n    \n    # Visualize ensemble weights\n    import plotly.graph_objects as go\n    \n    fig = go.Figure(data=[\n        go.Bar(\n            x=['CNN', 'LSTM', 'Transformer'],\n            y=weights_normalized.detach().cpu().numpy(),\n            marker_color=['blue', 'green', 'red']\n        )\n    ])\n    fig.update_layout(\n        title=\"Ensemble Model Contribution Weights\",\n        yaxis_title=\"Weight\",\n        yaxis_range=[0, 1]\n    )\n    fig.show()\n\n# Analyze common misclassifications\nprint(\"\\n\" + \"=\"*60)\nprint(\"Most Common Misclassifications:\")\nprint(\"=\"*60)\n\n# Create confusion pairs\nconfusion_pairs = []\nfor true_idx in range(len(cm)):\n    for pred_idx in range(len(cm)):\n        if true_idx != pred_idx and cm[true_idx, pred_idx] > 10:\n            true_emotion = emotion_names[true_idx]\n            pred_emotion = emotion_names[pred_idx]\n            count = cm[true_idx, pred_idx]\n            confusion_pairs.append((true_emotion, pred_emotion, count))\n\n# Sort by frequency\nconfusion_pairs.sort(key=lambda x: x[2], reverse=True)\n\nfor true_em, pred_em, count in confusion_pairs[:10]:\n    print(f\"  {true_em:10s} misclassified as {pred_em:10s}: {count} times\")\n\n# Success rate by emotion\nprint(\"\\n\" + \"=\"*60)\nprint(\"Performance Summary by Emotion:\")\nprint(\"=\"*60)\n\nperformance = []\nfor i, emotion in enumerate(emotion_names[:config.n_classes]):\n    if i < len(per_class_acc):\n        total = cm[i].sum()\n        correct = cm[i, i]\n        performance.append({\n            'Emotion': emotion,\n            'Accuracy': per_class_acc[i],\n            'Correct': correct,\n            'Total': total,\n            'Errors': total - correct\n        })\n\n# Sort by accuracy\nperformance.sort(key=lambda x: x['Accuracy'], reverse=True)\n\nprint(f\"{'Rank':<5} {'Emotion':<10} {'Accuracy':<10} {'Correct/Total':<15}\")\nprint(\"-\" * 50)\nfor rank, perf in enumerate(performance, 1):\n    print(f\"{rank:<5} {perf['Emotion']:<10} {perf['Accuracy']*100:>6.1f}%    {perf['Correct']:>3}/{perf['Total']:<3}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T19:30:14.665990Z","iopub.execute_input":"2025-10-28T19:30:14.666619Z","iopub.status.idle":"2025-10-28T19:30:14.686794Z","shell.execute_reply.started":"2025-10-28T19:30:14.666594Z","shell.execute_reply":"2025-10-28T19:30:14.685887Z"}},"outputs":[{"name":"stdout","text":"Ensemble Model Weights:\n  CNN Weight: 0.311\n  LSTM Weight: 0.375\n  Transformer Weight: 0.314\n","output_type":"stream"},{"output_type":"display_data","data":{"text/html":"<html>\n<head><meta charset=\"utf-8\" /></head>\n<body>\n    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"9ac789ee-2ad1-41c8-8377-a91482e69584\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"9ac789ee-2ad1-41c8-8377-a91482e69584\")) {                    Plotly.newPlot(                        \"9ac789ee-2ad1-41c8-8377-a91482e69584\",                        [{\"marker\":{\"color\":[\"blue\",\"green\",\"red\"]},\"x\":[\"CNN\",\"LSTM\",\"Transformer\"],\"y\":[0.31080252,0.37512228,0.3140752],\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"yaxis\":{\"title\":{\"text\":\"Weight\"},\"range\":[0,1]},\"title\":{\"text\":\"Ensemble Model Contribution Weights\"}},                        {\"responsive\": true}                    ).then(function(){\n                            \nvar gd = document.getElementById('9ac789ee-2ad1-41c8-8377-a91482e69584');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })                };                            </script>        </div>\n</body>\n</html>"},"metadata":{}},{"name":"stdout","text":"\n============================================================\nMost Common Misclassifications:\n============================================================\n  sad        misclassified as neutral   : 46 times\n  fear       misclassified as sad       : 43 times\n  fear       misclassified as happy     : 39 times\n  happy      misclassified as fear      : 33 times\n  sad        misclassified as fear      : 28 times\n  disgust    misclassified as sad       : 28 times\n  angry      misclassified as happy     : 27 times\n  disgust    misclassified as neutral   : 26 times\n  neutral    misclassified as disgust   : 25 times\n  disgust    misclassified as happy     : 25 times\n\n============================================================\nPerformance Summary by Emotion:\n============================================================\nRank  Emotion    Accuracy   Correct/Total  \n--------------------------------------------------\n1     surprise     88.8%     79/89 \n2     angry        76.8%    215/280\n3     neutral      74.8%    199/266\n4     sad          65.2%    182/279\n5     happy        61.1%    171/280\n6     fear         58.2%    163/280\n7     disgust      57.7%    161/279\n","output_type":"stream"}],"execution_count":42},{"cell_type":"markdown","source":"# ============================================\n# CELL 14: Error Analysis\n# ============================================","metadata":{}},{"cell_type":"code","source":"def error_analysis(preds, labels, probs, emotion_names):\n    \"\"\"Analyze model errors\"\"\"\n    \n    # Find misclassified samples\n    errors = preds != labels\n    error_indices = np.where(errors)[0]\n    \n    if len(error_indices) > 0:\n        print(f\"Total errors: {len(error_indices)} / {len(labels)} ({100*len(error_indices)/len(labels):.1f}%)\")\n        \n        # Confusion pairs\n        confusion_pairs = {}\n        for idx in error_indices:\n            true_label = emotion_names[labels[idx]]\n            pred_label = emotion_names[preds[idx]]\n            pair = f\"{true_label} -> {pred_label}\"\n            confusion_pairs[pair] = confusion_pairs.get(pair, 0) + 1\n        \n        # Most common confusions\n        sorted_pairs = sorted(confusion_pairs.items(), key=lambda x: x[1], reverse=True)\n        \n        print(\"\\nMost Common Confusions:\")\n        for pair, count in sorted_pairs[:10]:\n            print(f\"  {pair}: {count} times\")\n        \n        # Confidence analysis\n        correct_confidence = probs[~errors].max(axis=1).mean()\n        error_confidence = probs[errors].max(axis=1).mean()\n        \n        print(f\"\\nAverage Confidence:\")\n        print(f\"  Correct predictions: {correct_confidence:.3f}\")\n        print(f\"  Incorrect predictions: {error_confidence:.3f}\")\n        \n        # Plot confidence distribution\n        fig = go.Figure()\n        fig.add_trace(go.Histogram(\n            x=probs[~errors].max(axis=1),\n            name='Correct',\n            opacity=0.7,\n            nbinsx=30\n        ))\n        fig.add_trace(go.Histogram(\n            x=probs[errors].max(axis=1),\n            name='Incorrect',\n            opacity=0.7,\n            nbinsx=30\n        ))\n        fig.update_layout(\n            title=\"Confidence Distribution\",\n            xaxis_title=\"Confidence\",\n            yaxis_title=\"Count\",\n            barmode='overlay'\n        )\n        fig.show()\n\n# Perform error analysis\nerror_analysis(preds, labels, probs, emotion_names[:config.n_classes])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T19:30:23.694787Z","iopub.execute_input":"2025-10-28T19:30:23.695077Z","iopub.status.idle":"2025-10-28T19:30:23.712953Z","shell.execute_reply.started":"2025-10-28T19:30:23.695056Z","shell.execute_reply":"2025-10-28T19:30:23.712129Z"}},"outputs":[{"name":"stdout","text":"Total errors: 583 / 1753 (33.3%)\n\nMost Common Confusions:\n  sad -> neutral: 46 times\n  fear -> sad: 43 times\n  fear -> happy: 39 times\n  happy -> fear: 33 times\n  disgust -> sad: 28 times\n  sad -> fear: 28 times\n  angry -> happy: 27 times\n  disgust -> neutral: 26 times\n  neutral -> disgust: 25 times\n  disgust -> happy: 25 times\n\nAverage Confidence:\n  Correct predictions: 0.780\n  Incorrect predictions: 0.544\n","output_type":"stream"},{"output_type":"display_data","data":{"text/html":"<html>\n<head><meta charset=\"utf-8\" /></head>\n<body>\n    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"3e22c4e9-7973-4f65-8ffc-1763a2ac0b87\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"3e22c4e9-7973-4f65-8ffc-1763a2ac0b87\")) {                    Plotly.newPlot(                        \"3e22c4e9-7973-4f65-8ffc-1763a2ac0b87\",                        [{\"name\":\"Correct\",\"nbinsx\":30,\"opacity\":0.7,\"x\":[0.38223457,0.98647726,0.42836362,0.98907477,0.82319844,0.93541896,0.96696633,0.99428177,0.5667573,0.9470378,0.94804466,0.31200707,0.77349406,0.97027886,0.7165515,0.5272424,0.9924677,0.5978142,0.9768521,0.43449962,0.41642025,0.9903082,0.99696213,0.9974245,0.9954758,0.5953398,0.5550543,0.37782812,0.4044959,0.52489066,0.9781973,0.4345812,0.89665824,0.7483444,0.6432393,0.92413783,0.9871723,0.6054499,0.7768055,0.9867599,0.41632667,0.72971207,0.80113196,0.9817578,0.9875782,0.58421123,0.6422257,0.47998127,0.9969561,0.9851467,0.9050382,0.981261,0.37139952,0.78791744,0.73621523,0.9716158,0.7024324,0.98365986,0.99512094,0.69905126,0.9961106,0.9837621,0.8408757,0.96798116,0.99316555,0.48582155,0.9271068,0.85763186,0.65157306,0.66906613,0.9544495,0.5090398,0.67994225,0.38617864,0.93868804,0.54314977,0.7826742,0.46151784,0.981794,0.9872903,0.96366936,0.99301445,0.567423,0.6052866,0.9814922,0.56892496,0.3237334,0.97149163,0.85497683,0.9936748,0.738267,0.45818612,0.725019,0.803677,0.927248,0.96928877,0.57627684,0.7380923,0.7941102,0.8904458,0.46648952,0.97255707,0.87113607,0.96984273,0.99744993,0.7687634,0.57143086,0.666685,0.99500567,0.58687353,0.71599495,0.6200304,0.9902738,0.30577156,0.32317728,0.7616184,0.5690089,0.9694221,0.7873481,0.9784883,0.79984653,0.96779734,0.74747896,0.5496258,0.98637277,0.98741907,0.982029,0.8143677,0.99397284,0.7263708,0.9383786,0.961254,0.8460577,0.98929197,0.97310805,0.9566121,0.4748571,0.9942053,0.56134695,0.56758976,0.9031242,0.9769965,0.9980565,0.50530005,0.98271424,0.57845235,0.59241885,0.86251307,0.978785,0.8519475,0.99481493,0.8526526,0.8995411,0.9777359,0.9793459,0.46553814,0.78316575,0.8016037,0.40245306,0.5666773,0.6144582,0.9881253,0.9770129,0.960024,0.76664704,0.65626985,0.9893996,0.884082,0.71644855,0.9691868,0.6053654,0.82469434,0.69182485,0.9820973,0.98809683,0.36611792,0.6686025,0.962584,0.4796909,0.98439366,0.6542987,0.6435572,0.5324963,0.44646436,0.4730515,0.99314487,0.9439751,0.9896932,0.95991635,0.99037486,0.995073,0.9952277,0.97645706,0.7595383,0.853586,0.98863065,0.90838397,0.9838111,0.36374825,0.5394455,0.76142806,0.5130474,0.47656003,0.98095816,0.78175515,0.99755883,0.44801453,0.5008588,0.51877016,0.9967914,0.5783116,0.751471,0.98722935,0.65543705,0.9754146,0.71122277,0.35597348,0.8018646,0.5201557,0.6897246,0.98105824,0.42792037,0.9554382,0.9299102,0.39285398,0.99115026,0.99834096,0.9888487,0.984091,0.47665426,0.9785187,0.7604058,0.95357597,0.99574053,0.9943469,0.9949207,0.6545166,0.9773536,0.90800285,0.924651,0.9063464,0.81601125,0.98384583,0.6290773,0.6368101,0.9866176,0.99115694,0.97055715,0.98509973,0.7515606,0.47772965,0.9890537,0.98457634,0.998251,0.9899014,0.9961461,0.96999705,0.7481476,0.9824552,0.89646196,0.82977474,0.70905524,0.5003614,0.36045903,0.9506512,0.95887715,0.6822325,0.66019523,0.89215785,0.4132195,0.98380554,0.61602885,0.45304245,0.98900056,0.86491454,0.996247,0.93733716,0.54946566,0.5671332,0.7039083,0.63427657,0.65446204,0.40670374,0.989576,0.9976412,0.9919471,0.95250255,0.97873425,0.6502592,0.80669147,0.52219033,0.48826513,0.9867648,0.9966748,0.6601931,0.9141798,0.56821984,0.7183756,0.9778441,0.49858648,0.66656446,0.99102974,0.38091895,0.5754838,0.8632364,0.8588083,0.50022674,0.9962443,0.9440232,0.9876774,0.36330974,0.5809103,0.9948507,0.68573445,0.9968972,0.98440474,0.6453921,0.99378306,0.4174873,0.75877064,0.61511064,0.9294104,0.96897024,0.58887553,0.9964042,0.8682429,0.974519,0.97494113,0.53861904,0.98122084,0.9262498,0.98780805,0.9964036,0.4077206,0.6593387,0.5788453,0.33643502,0.98263645,0.9616885,0.6845721,0.72224796,0.9660456,0.99496067,0.26949093,0.5835259,0.7889403,0.93648946,0.20681652,0.57585007,0.71290517,0.58841205,0.6443897,0.47321808,0.99651355,0.8490732,0.821249,0.99665487,0.994517,0.68855447,0.9438693,0.59803504,0.42874524,0.9955369,0.96097124,0.7774973,0.9697982,0.5926299,0.9100704,0.9867628,0.4898217,0.5368851,0.9963481,0.47964832,0.5835495,0.8643055,0.9757338,0.9622858,0.9815077,0.375776,0.42507988,0.9951381,0.99692494,0.68215793,0.32208514,0.70355415,0.37580627,0.3356696,0.99707186,0.9766119,0.9783197,0.99511886,0.69883424,0.9483119,0.99546885,0.63278073,0.9545011,0.98897064,0.99651176,0.93650734,0.5683314,0.82899034,0.6653383,0.9747302,0.7508532,0.9625603,0.32143754,0.5579082,0.57920206,0.99019134,0.99779797,0.98968726,0.9344497,0.9733912,0.9952766,0.46082208,0.41945615,0.65613586,0.3328387,0.80393165,0.9854117,0.5129657,0.98426557,0.99568653,0.9754648,0.99677294,0.83977264,0.9904254,0.6516444,0.9779108,0.35339248,0.9113039,0.49736813,0.53172314,0.699729,0.9323546,0.5906488,0.9713552,0.96360487,0.9934411,0.72564566,0.9760827,0.42861107,0.6242909,0.9976555,0.4354075,0.73265994,0.33824214,0.9891445,0.98189396,0.5539581,0.98994255,0.97049683,0.9318318,0.4244775,0.98574567,0.9542253,0.6882229,0.52471054,0.97410554,0.4356063,0.9634274,0.44303054,0.709685,0.97136575,0.995764,0.72338754,0.97903013,0.979618,0.4930033,0.9798186,0.99109966,0.67645746,0.9675895,0.51132905,0.97739214,0.44623598,0.92643154,0.9927819,0.8443827,0.74592835,0.9615211,0.9691431,0.7254504,0.55859447,0.4856447,0.98739773,0.99398637,0.6625671,0.99570066,0.39307338,0.7838,0.7493603,0.9963569,0.29456025,0.9949173,0.9784646,0.96773237,0.73635525,0.8570355,0.6557676,0.96213645,0.5060849,0.97316915,0.99336785,0.9952223,0.79516274,0.8554885,0.95635676,0.7957711,0.5320435,0.48946518,0.9809987,0.98426026,0.99469167,0.9798941,0.6434956,0.9757008,0.99679416,0.98891234,0.7134472,0.50035477,0.98037416,0.8895708,0.5376147,0.37652382,0.98092586,0.4337094,0.79996324,0.42675123,0.8624674,0.37596536,0.9803334,0.68687385,0.63478106,0.98973376,0.9746824,0.5538881,0.9860313,0.74104106,0.3849503,0.6847637,0.5831147,0.9942023,0.354997,0.9910033,0.7350631,0.652344,0.59898216,0.6350828,0.9921847,0.388596,0.46137077,0.7913779,0.98375505,0.9840636,0.5106589,0.56968,0.8764715,0.9816139,0.9815685,0.9758675,0.9801777,0.8448485,0.87193966,0.7950848,0.6510326,0.9465061,0.7015307,0.5751522,0.6551886,0.99672866,0.27683643,0.46924478,0.9286088,0.600743,0.8105551,0.9782357,0.7612091,0.9921909,0.80311537,0.92813164,0.5076366,0.32080677,0.9907985,0.7671572,0.96508837,0.9924886,0.43022147,0.42343524,0.6630885,0.9958241,0.46934095,0.9967327,0.31929874,0.64867246,0.98244387,0.86363584,0.9727285,0.9970974,0.51692593,0.46182755,0.30856845,0.8109961,0.43045273,0.9957308,0.98215437,0.9748947,0.8236422,0.73280555,0.9967913,0.825969,0.37594977,0.6253351,0.7006733,0.9819105,0.9270857,0.99144894,0.97224253,0.9091306,0.9634791,0.97310704,0.4727353,0.52658594,0.7546914,0.6328578,0.71514726,0.5763228,0.9842891,0.99490106,0.99694484,0.5911857,0.638002,0.9753049,0.98079336,0.97261965,0.8127578,0.6064351,0.847057,0.4601677,0.9697361,0.9698052,0.67631024,0.9878131,0.73264897,0.82132727,0.67758137,0.9710236,0.9784656,0.39728442,0.6227023,0.6866173,0.8553002,0.7183465,0.44720948,0.9717192,0.84039724,0.64488435,0.33438078,0.7953354,0.29304957,0.93495303,0.96819067,0.9965778,0.8017635,0.47531208,0.52143717,0.7679483,0.6821688,0.99609596,0.57921064,0.8164894,0.6793156,0.6464035,0.9757091,0.8669687,0.57738197,0.54734045,0.94010913,0.83050704,0.39697057,0.8275091,0.54204214,0.6338286,0.73214847,0.3426789,0.9714722,0.5666635,0.9842221,0.9968119,0.5146727,0.4952927,0.98190224,0.99021333,0.56440234,0.7683785,0.46740073,0.39955518,0.9760423,0.72185576,0.63556176,0.98251545,0.49490628,0.98522943,0.5524741,0.98516315,0.9880442,0.99116045,0.4030345,0.9776757,0.71570206,0.9815652,0.94056976,0.9704879,0.99169075,0.99231005,0.51668346,0.996581,0.78180134,0.7381159,0.9662964,0.9913374,0.6551997,0.6537836,0.69945836,0.681319,0.4229293,0.9942544,0.7437685,0.6200038,0.9936765,0.9928496,0.97213745,0.9195939,0.9816975,0.8437555,0.9789877,0.5949258,0.38484138,0.9761905,0.92086005,0.9796841,0.9545665,0.9895375,0.6325986,0.45678216,0.9511358,0.9600484,0.46719992,0.5488027,0.67863053,0.9937836,0.3534245,0.97418344,0.7901054,0.99648154,0.99688417,0.75463396,0.50933766,0.9517221,0.407683,0.9818994,0.97678626,0.99397755,0.99670285,0.97561044,0.47572762,0.98612505,0.54298013,0.47744238,0.9812213,0.98403233,0.7753128,0.74008715,0.98895454,0.996689,0.5503441,0.9960634,0.9910368,0.83024997,0.90120095,0.98415804,0.9914193,0.98327214,0.7104136,0.996135,0.99508035,0.49089992,0.90221566,0.86306745,0.70129937,0.97378665,0.65509164,0.9496968,0.97539777,0.76619333,0.8692231,0.9925333,0.80732334,0.9970251,0.8713056,0.23041211,0.96214825,0.85087025,0.8049272,0.75051856,0.9864422,0.9948073,0.98770684,0.5482627,0.9908009,0.67644835,0.9704113,0.9885533,0.98048556,0.69772124,0.9686715,0.81329256,0.9329269,0.41084072,0.98969054,0.9944829,0.32912397,0.9872656,0.4848319,0.9815424,0.8282926,0.45319438,0.63375735,0.97137153,0.99331325,0.42757288,0.9963246,0.9107005,0.9769539,0.6986564,0.9684852,0.8236943,0.9840905,0.7759444,0.6794128,0.9933287,0.6290231,0.977439,0.4520304,0.98858786,0.5092997,0.5000986,0.99556375,0.7662331,0.97092414,0.94379324,0.9656792,0.62806386,0.98481596,0.9897502,0.47682345,0.86846846,0.9795163,0.99772733,0.6401905,0.73053193,0.9967121,0.47574225,0.97308165,0.9716223,0.69984967,0.44376194,0.5868233,0.9698373,0.979037,0.97066206,0.9882599,0.7604434,0.92473847,0.9949458,0.26327077,0.7060945,0.45780164,0.9890063,0.99208105,0.787887,0.54410535,0.5544195,0.99086106,0.98952764,0.7743516,0.9753062,0.950788,0.46813852,0.8386763,0.72355527,0.92661864,0.9902811,0.9502628,0.4637513,0.72538877,0.93814725,0.53153825,0.7856817,0.98560935,0.43910447,0.9894767,0.8120113,0.9923707,0.69041103,0.842582,0.78109705,0.66955817,0.49040505,0.88539815,0.80707246,0.98387885,0.53447443,0.32109326,0.9961438,0.7812179,0.7503754,0.9854637,0.55118936,0.6039366,0.42514244,0.8542458,0.7349287,0.8140697,0.98917806,0.7894311,0.9672737,0.6184764,0.9911561,0.6201289,0.98459065,0.9708992,0.9983882,0.7103724,0.8069391,0.9006112,0.9665282,0.809614,0.6233925,0.7207206,0.9437689,0.9914693,0.73799145,0.40637404,0.90074205,0.99619555,0.9200537,0.38898864,0.92525685,0.3779286,0.6064331,0.623995,0.50831664,0.29063603,0.9871759,0.9867055,0.28837952,0.99644864,0.80486166,0.99493486,0.5534205,0.44841784,0.99262804,0.90799046,0.519912,0.97874635,0.97745377,0.9482957,0.4166568,0.9884801,0.9298935,0.99504083,0.9935818,0.35477418,0.6878734,0.9901861,0.8486562,0.99863094,0.9904661,0.98553467,0.9318412,0.9203652,0.666333,0.7466195,0.54949975,0.96887815,0.49099624,0.9941718,0.37928945,0.532159,0.9760227,0.99695754,0.99232304,0.80063295,0.9889621,0.6397779,0.7726816,0.9960647,0.97396016,0.7927689,0.8279751,0.8470237,0.99235815,0.56612176,0.7783281,0.39917764,0.37845144,0.5845694,0.98489374,0.99401736,0.33696204,0.5037291,0.7866562,0.44650552,0.9975038,0.62291193,0.99590755,0.42956534,0.9816714,0.5389301,0.9825371,0.59813184,0.4726939,0.9960829,0.99672806,0.5473411,0.286167,0.8704354,0.4106998,0.97397035,0.34226817,0.55361587,0.8309166,0.5752225,0.89074224,0.3266289,0.9799318,0.99581355,0.98893297,0.6582958,0.88643646,0.6655838,0.65182334,0.9888925,0.94682455,0.9501334,0.83049846,0.582167,0.79389584,0.9965893,0.98990834,0.98049223,0.51409847,0.43746686,0.96895885,0.98749,0.9974381,0.9966474,0.9935923,0.75925505,0.5354996,0.35860756,0.414379,0.9965456,0.46030644,0.9345341,0.98911077,0.9850942,0.4923849,0.54689765,0.9959182,0.3436922,0.2788959,0.938019,0.9840718,0.97246563,0.9960836,0.40238297,0.43617788,0.994772,0.7685766,0.978305,0.31831542,0.75856894,0.99564517,0.46504396,0.36761537,0.5944275,0.62618214,0.6999922,0.49137807,0.6786179,0.99259055,0.43382004,0.9570711,0.99322975,0.9885942,0.99457586,0.7746239,0.33204925,0.892512,0.99584705,0.3710238,0.9742973,0.6039299,0.6961587,0.7029999,0.99614716,0.9782202,0.8829187,0.380261,0.6620481,0.9036494,0.39171594,0.9940899,0.9123392,0.61746264,0.84388727,0.98119706,0.79121345,0.9757961,0.56744486,0.8955156,0.98008007,0.9963439,0.52971053,0.5906819,0.8837317,0.9968941,0.9665426,0.9963654,0.49596635,0.994643,0.70945925,0.99706143,0.54209983,0.74370503,0.65836024,0.4933787,0.9732871,0.89046425,0.49680388,0.5773065,0.64002055,0.9884594,0.99727374,0.9966897,0.97919595,0.7191324,0.9563774,0.9750285,0.9942332,0.7411986,0.70971996,0.98608625,0.66466993,0.98556024,0.86510354,0.5763733,0.60429907,0.8232015,0.8778485,0.57097805,0.57816565,0.50447327,0.7194679,0.99115443,0.9673237,0.97930324,0.94586235],\"type\":\"histogram\"},{\"name\":\"Incorrect\",\"nbinsx\":30,\"opacity\":0.7,\"x\":[0.94293255,0.36049402,0.49688056,0.76544803,0.51504487,0.44332954,0.7845448,0.7834438,0.38212115,0.72700334,0.46435827,0.45281744,0.67403185,0.5887517,0.45023543,0.60536426,0.31103203,0.33698165,0.6869158,0.45149985,0.63217944,0.53015715,0.58466244,0.49118024,0.8523916,0.49752048,0.2101016,0.35351846,0.54784775,0.5781626,0.3937657,0.4756752,0.4171856,0.54095846,0.68149555,0.33384615,0.6393993,0.7479732,0.4021567,0.47307193,0.5433218,0.38375092,0.5141987,0.40962672,0.6546743,0.31113973,0.38343257,0.6920593,0.7961863,0.73760885,0.35424128,0.52175707,0.54794717,0.54756534,0.23907728,0.47448435,0.7103901,0.4698309,0.73516035,0.41088098,0.31676245,0.6809942,0.60578525,0.5301056,0.4614527,0.7037189,0.51483953,0.34758362,0.73616266,0.6338779,0.7112125,0.6180882,0.47208017,0.37849462,0.59179425,0.96656024,0.6946429,0.34972438,0.7078907,0.6632352,0.7004904,0.38671526,0.43451372,0.48283014,0.37436,0.43993393,0.28169337,0.31122416,0.41969222,0.58774906,0.5565358,0.8561306,0.7057043,0.70342606,0.46825266,0.83135724,0.7075945,0.7631718,0.35731778,0.47142366,0.3320848,0.88139904,0.4440194,0.4182415,0.97873086,0.51768804,0.75025094,0.63367116,0.3801681,0.6822126,0.50435627,0.32109118,0.6353769,0.47835624,0.49576527,0.59868497,0.7310163,0.40962145,0.48259637,0.64419276,0.5514415,0.7041312,0.5256367,0.68907124,0.74847275,0.32331786,0.4057665,0.5357487,0.69419634,0.64142615,0.40629274,0.7874383,0.52243495,0.33744344,0.7216899,0.46465346,0.26213732,0.29872227,0.2531399,0.7394068,0.33394277,0.4132788,0.36948723,0.89907146,0.62150574,0.31478333,0.21485406,0.9791022,0.3945289,0.55873936,0.76464903,0.5686898,0.72370785,0.43817902,0.9936154,0.42742312,0.3223387,0.83679235,0.4601962,0.3141638,0.4150612,0.6672047,0.5101861,0.72435856,0.40502536,0.76677394,0.52054346,0.5560223,0.58877,0.8133742,0.26712534,0.42360264,0.38740999,0.5873261,0.45841098,0.83409595,0.2777712,0.8345027,0.8361412,0.6600735,0.9459598,0.5334843,0.66971874,0.73872906,0.26332182,0.78993404,0.4440441,0.25868618,0.47855026,0.7361556,0.94922704,0.44192976,0.45661163,0.45163608,0.48720795,0.853737,0.69997746,0.47621694,0.5176673,0.46771812,0.4833434,0.54360306,0.42722479,0.47577572,0.6617111,0.23746528,0.5351743,0.4221201,0.5242486,0.52078557,0.65673006,0.3455391,0.39118534,0.6292241,0.8419266,0.4392093,0.3873601,0.41311342,0.4634945,0.47090033,0.4321377,0.7853915,0.38078782,0.45974013,0.58720165,0.7568819,0.36998507,0.5392926,0.59697753,0.3909448,0.9367221,0.49273464,0.3981958,0.48089188,0.68983626,0.43247625,0.64029175,0.6990543,0.9051299,0.46409324,0.8025016,0.723287,0.46692342,0.5758053,0.59984285,0.6931157,0.6911087,0.6425343,0.85340035,0.5076887,0.41336885,0.56425494,0.84534377,0.7615487,0.2853459,0.46326143,0.39737508,0.33204883,0.5070022,0.6804196,0.50338405,0.3928892,0.53880376,0.53089887,0.5099423,0.7223065,0.32263595,0.60053355,0.63858664,0.3376367,0.68458116,0.4897987,0.6228144,0.34799403,0.44784012,0.5123199,0.48322955,0.4633027,0.42276776,0.47886053,0.69827145,0.97968984,0.8489023,0.7379106,0.2572346,0.8482966,0.4975604,0.3923332,0.5120426,0.53632426,0.36531097,0.59545875,0.39405757,0.7132465,0.47572762,0.38576356,0.5546654,0.9141902,0.36981478,0.5123481,0.6265482,0.68894446,0.55918217,0.57568306,0.690266,0.20951448,0.88125163,0.41424763,0.673669,0.35130852,0.30214387,0.4424392,0.6115704,0.8519827,0.40616772,0.9689887,0.29693633,0.4040672,0.3907805,0.6056543,0.753097,0.70823354,0.69433564,0.79617757,0.32960615,0.635543,0.36926505,0.6835781,0.3928707,0.44388166,0.6740235,0.47930154,0.42880774,0.759184,0.5853651,0.55182534,0.48358044,0.58238727,0.52490747,0.7900692,0.45387852,0.36060646,0.27146173,0.64968884,0.619564,0.6845822,0.40896887,0.5786085,0.583459,0.8632009,0.751832,0.3857151,0.6678241,0.832767,0.5845735,0.39542595,0.4643445,0.49979362,0.39675552,0.5934609,0.41728294,0.62210715,0.83405316,0.41293126,0.82662535,0.270304,0.5638437,0.79368925,0.49330452,0.35881966,0.30933696,0.4497373,0.40193206,0.6964243,0.7247879,0.6636743,0.6518799,0.7924243,0.5190323,0.40569657,0.42838678,0.4717288,0.4370329,0.3308653,0.6906305,0.36046413,0.56673855,0.661498,0.45591915,0.3003243,0.48340654,0.78020835,0.36892334,0.5516405,0.6390814,0.42618978,0.3720269,0.36281267,0.47783154,0.3623799,0.55189234,0.47860903,0.60405713,0.5479937,0.3595275,0.5722363,0.5809068,0.43648556,0.6291006,0.737188,0.4926992,0.7410218,0.37746978,0.49512005,0.45351848,0.56798995,0.44312692,0.6459731,0.5248712,0.45356464,0.3410762,0.5932846,0.43602318,0.6035025,0.4100364,0.4154531,0.62304896,0.51392126,0.4875374,0.49130595,0.8382327,0.81720924,0.45975223,0.5128153,0.4649373,0.45910385,0.74075127,0.46078578,0.28499562,0.40093118,0.5149811,0.5081615,0.6204859,0.43213224,0.24404262,0.46167347,0.49481443,0.42359143,0.40226394,0.6540948,0.5727376,0.5943722,0.51951003,0.38107786,0.7606455,0.5762062,0.27182484,0.817537,0.43951243,0.5498088,0.65106076,0.3089151,0.3657311,0.34023473,0.5880148,0.6905638,0.7551211,0.42142874,0.5755908,0.8432845,0.3312267,0.44070742,0.24584171,0.5092712,0.7059374,0.3066499,0.70948744,0.6378584,0.44600204,0.7926925,0.6168663,0.42603233,0.6209233,0.3075533,0.30249217,0.5035701,0.63342077,0.39294222,0.40246087,0.80295485,0.34736276,0.43893886,0.76392025,0.65348995,0.4129569,0.24940115,0.49139252,0.37168056,0.81402797,0.98991513,0.58628505,0.67892915,0.63033897,0.59095955,0.3296395,0.6445334,0.44338766,0.46047625,0.3579195,0.5163571,0.59586746,0.6806297,0.5775475,0.55335003,0.5918733,0.85533696,0.2880306,0.47820795,0.4009552,0.5781153,0.3989827,0.7721248,0.8133698,0.38508856,0.5699483,0.72844607,0.8089509,0.35017666,0.34843323,0.30527744,0.37989613,0.5631453,0.5393889,0.5906508,0.50826156,0.57032335,0.36121246,0.44788244,0.37082183,0.7447704,0.33126584,0.46962872,0.43504277,0.5375051,0.4211073,0.4675086,0.89408064,0.38722906,0.4069282,0.78314614,0.46917558,0.48226917,0.6892518,0.5413287,0.63542837,0.47063532,0.5058171,0.5452358,0.34847242,0.5029382,0.73674357,0.6423785,0.6579495,0.30668962,0.44997573,0.58990836,0.5812102,0.7650148,0.2579819,0.43736845,0.62349457,0.6092708,0.59113777,0.9929103,0.48528606,0.76806515,0.5901488,0.45908302,0.27823845,0.26437503,0.592712,0.311666,0.9002545],\"type\":\"histogram\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"Confidence Distribution\"},\"xaxis\":{\"title\":{\"text\":\"Confidence\"}},\"yaxis\":{\"title\":{\"text\":\"Count\"}},\"barmode\":\"overlay\"},                        {\"responsive\": true}                    ).then(function(){\n                            \nvar gd = document.getElementById('3e22c4e9-7973-4f65-8ffc-1763a2ac0b87');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })                };                            </script>        </div>\n</body>\n</html>"},"metadata":{}}],"execution_count":43},{"cell_type":"markdown","source":"# ============================================\n# CELL 15: Save Results and Model\n# ============================================","metadata":{}},{"cell_type":"code","source":"# Save results\nresults = {\n    'test_accuracy': accuracy,\n    'predictions': preds.tolist(),\n    'true_labels': labels.tolist(),\n    'probabilities': probs.tolist(),\n    'confusion_matrix': cm.tolist(),\n    'training_history': {\n        'train_losses': trainer.train_losses,\n        'val_losses': trainer.val_losses,\n        'train_accs': trainer.train_accs,\n        'val_accs': trainer.val_accs\n    }\n}\n\nwith open('/kaggle/working/results.json', 'w') as f:\n    json.dump(results, f)\n\nprint(\"Results saved to results.json\")\n\n# Save model for deployment\ntorch.save({\n    'model_state_dict': model.state_dict(),\n    'model_config': config,\n    'emotion_names': emotion_names[:config.n_classes],\n    'test_accuracy': accuracy\n}, '/kaggle/working/final_model.pth')\n\nprint(\"Model saved to final_model.pth\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T19:30:30.274392Z","iopub.execute_input":"2025-10-28T19:30:30.274699Z","iopub.status.idle":"2025-10-28T19:30:30.343018Z","shell.execute_reply.started":"2025-10-28T19:30:30.274679Z","shell.execute_reply":"2025-10-28T19:30:30.342245Z"}},"outputs":[{"name":"stdout","text":"Results saved to results.json\nModel saved to final_model.pth\n","output_type":"stream"}],"execution_count":44},{"cell_type":"markdown","source":"# ============================================\n# CELL 16: Generate Project Report\n# ============================================","metadata":{}},{"cell_type":"code","source":"report = f\"\"\"\n# Speech Emotion Recognition Project Report\n\n## 1. Project Overview\n- **Objective**: Develop a deep learning system for emotion recognition from speech\n- **Model Type**: {config.model_type.upper()}\n- **Number of Classes**: {config.n_classes}\n- **Total Samples**: {len(file_paths)}\n- **Train/Val/Test Split**: {config.train_size}/{config.val_size}/{config.test_size}\n\n## 2. Model Architecture\n- **Parameters**: {sum(p.numel() for p in model.parameters()):,}\n- **Input Features**: Mel-spectrogram ({config.n_mels} bins)\n- **Batch Size**: {config.batch_size}\n- **Learning Rate**: {config.learning_rate}\n- **Epochs Trained**: {len(trainer.train_losses)}\n\n## 3. Performance Results\n- **Test Accuracy**: {accuracy:.4f}\n- **Best Validation Accuracy**: {checkpoint['val_acc']:.2f}%\n\n## 4. Per-Class Performance\n\"\"\"\n\nfor i, emotion in enumerate(emotion_names[:config.n_classes]):\n    if i < len(per_class_acc):\n        report += f\"- {emotion}: {per_class_acc[i]:.3f}\\n\"\n\nreport += \"\"\"\n## 5. Key Findings\n1. The model successfully learns to distinguish between different emotions\n2. Some emotion pairs show higher confusion rates (see error analysis)\n3. Ensemble models generally perform better than individual architectures\n\n## 6. Future Improvements\n1. Implement data augmentation techniques (pitch shift, time stretch)\n2. Try pre-trained models (Wav2Vec2, HuBERT)\n3. Collect more diverse training data\n4. Implement real-time emotion recognition\n\n## 7. Technologies Used\n- **Deep Learning**: PyTorch, TorchAudio\n- **Audio Processing**: Librosa\n- **Visualization**: Plotly\n- **Environment**: Kaggle GPU\n\"\"\"\n\nprint(report)\n\n# Save report\nwith open('/kaggle/working/project_report.md', 'w') as f:\n    f.write(report)\n\nprint(\"\\nProject completed successfully! ðŸŽ‰\")\nprint(\"Files saved:\")\nprint(\"- best_model.pth\")\nprint(\"- final_model.pth\")\nprint(\"- results.json\")\nprint(\"- project_report.md\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T19:30:40.753395Z","iopub.execute_input":"2025-10-28T19:30:40.753701Z","iopub.status.idle":"2025-10-28T19:30:40.763049Z","shell.execute_reply.started":"2025-10-28T19:30:40.753681Z","shell.execute_reply":"2025-10-28T19:30:40.762373Z"}},"outputs":[{"name":"stdout","text":"\n# Speech Emotion Recognition Project Report\n\n## 1. Project Overview\n- **Objective**: Develop a deep learning system for emotion recognition from speech\n- **Model Type**: ENSEMBLE\n- **Number of Classes**: 7\n- **Total Samples**: 11682\n- **Train/Val/Test Split**: 0.7/0.15/0.15\n\n## 2. Model Architecture\n- **Parameters**: 3,313,689\n- **Input Features**: Mel-spectrogram (128 bins)\n- **Batch Size**: 256\n- **Learning Rate**: 0.001\n- **Epochs Trained**: 20\n\n## 3. Performance Results\n- **Test Accuracy**: 0.6674\n- **Best Validation Accuracy**: 63.72%\n\n## 4. Per-Class Performance\n- neutral: 0.748\n- happy: 0.611\n- sad: 0.652\n- angry: 0.768\n- fear: 0.582\n- disgust: 0.577\n- surprise: 0.888\n\n## 5. Key Findings\n1. The model successfully learns to distinguish between different emotions\n2. Some emotion pairs show higher confusion rates (see error analysis)\n3. Ensemble models generally perform better than individual architectures\n\n## 6. Future Improvements\n1. Implement data augmentation techniques (pitch shift, time stretch)\n2. Try pre-trained models (Wav2Vec2, HuBERT)\n3. Collect more diverse training data\n4. Implement real-time emotion recognition\n\n## 7. Technologies Used\n- **Deep Learning**: PyTorch, TorchAudio\n- **Audio Processing**: Librosa\n- **Visualization**: Plotly\n- **Environment**: Kaggle GPU\n\n\nProject completed successfully! ðŸŽ‰\nFiles saved:\n- best_model.pth\n- final_model.pth\n- results.json\n- project_report.md\n","output_type":"stream"}],"execution_count":45},{"cell_type":"markdown","source":"# ============================================\n# CELL 17: Test Time Augmentation for Better Accuracy\n# ============================================","metadata":{}},{"cell_type":"code","source":"def evaluate_with_tta(model, test_loader, device, n_augmentations=5):\n    \"\"\"\n    Evaluate with Test Time Augmentation\n    This can improve accuracy by 0.5-2% without retraining!\n    \"\"\"\n    model.eval()\n    all_preds = []\n    all_labels = []\n    all_probs_list = []\n    \n    print(f\"Applying Test Time Augmentation with {n_augmentations} augmentations per sample...\")\n    \n    with torch.no_grad():\n        for features, labels in tqdm(test_loader, desc=\"TTA Testing\"):\n            batch_probs = []\n            \n            # Original prediction\n            features_gpu = features.to(device)\n            with autocast():\n                outputs = model(features_gpu)\n            probs = F.softmax(outputs, dim=1)\n            batch_probs.append(probs.cpu())\n            \n            # Augmented predictions\n            for aug_idx in range(n_augmentations - 1):\n                # Apply different augmentations\n                aug_features = features.clone()\n                \n                if aug_idx == 0:\n                    # Add slight noise\n                    aug_features = aug_features + torch.randn_like(aug_features) * 0.003\n                elif aug_idx == 1:\n                    # Slight time shift\n                    shift_amount = torch.randint(-5, 5, (1,)).item()\n                    aug_features = torch.roll(aug_features, shifts=shift_amount, dims=-1)\n                elif aug_idx == 2:\n                    # Slight amplitude scaling\n                    scale = 1.0 + (torch.rand(1).item() - 0.5) * 0.1\n                    aug_features = aug_features * scale\n                else:\n                    # Random small perturbation\n                    aug_features = aug_features + torch.randn_like(aug_features) * 0.002\n                \n                aug_features = aug_features.to(device)\n                with autocast():\n                    aug_outputs = model(aug_features)\n                aug_probs = F.softmax(aug_outputs, dim=1)\n                batch_probs.append(aug_probs.cpu())\n            \n            # Average predictions from all augmentations\n            avg_probs = torch.stack(batch_probs).mean(dim=0)\n            _, predicted = avg_probs.max(1)\n            \n            all_preds.extend(predicted.numpy())\n            all_labels.extend(labels.numpy())\n            all_probs_list.append(avg_probs.numpy())\n    \n    return np.array(all_preds), np.array(all_labels), np.vstack(all_probs_list)\n\n# Apply TTA to your already trained model\nprint(\"=\"*60)\nprint(\"EVALUATING WITH TEST TIME AUGMENTATION\")\nprint(\"=\"*60)\n\n# Load best model if not already loaded\nif not 'model' in globals():\n    checkpoint = torch.load('/kaggle/working/best_model.pth', weights_only=False)\n    model.load_state_dict(checkpoint['model_state_dict'])\n    print(f\"Loaded model with {checkpoint['val_acc']:.2f}% validation accuracy\")\n\n# Run TTA evaluation\ntta_preds, tta_labels, tta_probs = evaluate_with_tta(model, test_loader, device, n_augmentations=5)\n\n# Calculate improved metrics\ntta_accuracy = accuracy_score(tta_labels, tta_preds)\nprint(f\"\\nðŸŽ¯ Original Test Accuracy: 71.93%\")\nprint(f\"ðŸš€ TTA Test Accuracy: {tta_accuracy:.4f} ({tta_accuracy*100:.2f}%)\")\nprint(f\"ðŸ“ˆ Improvement: +{(tta_accuracy - 0.7193)*100:.2f}%\")\n\n# Detailed classification report\nprint(\"\\n\" + \"=\"*60)\nprint(\"TTA Classification Report:\")\nprint(\"=\"*60)\nprint(classification_report(tta_labels, tta_preds, target_names=emotion_names[:config.n_classes], digits=3))\n\n# Confusion Matrix\ntta_cm = confusion_matrix(tta_labels, tta_preds)\nprint(\"\\n\" + \"=\"*60)\nprint(\"TTA Confusion Matrix:\")\nprint(\"=\"*60)\nprint(tta_cm)\n\n# Per-class accuracy\ntta_per_class_acc = tta_cm.diagonal() / tta_cm.sum(axis=1)\nprint(\"\\n\" + \"=\"*60)\nprint(\"TTA Per-Class Accuracy:\")\nprint(\"=\"*60)\nfor i, emotion in enumerate(emotion_names[:config.n_classes]):\n    if i < len(tta_per_class_acc):\n        improvement = (tta_per_class_acc[i] - per_class_acc[i]) * 100\n        print(f\"  {emotion:10s}: {tta_per_class_acc[i]:.3f} ({tta_per_class_acc[i]*100:.1f}%) [{'â†‘' if improvement > 0 else 'â†“'}{abs(improvement):.1f}%]\")\n\nprint(\"\\nâœ… TTA Evaluation Complete!\")\nprint(\"ðŸ’¡ TTA typically improves accuracy by 0.5-2% without any retraining!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T19:31:30.972285Z","iopub.execute_input":"2025-10-28T19:31:30.972889Z","iopub.status.idle":"2025-10-28T19:31:36.907067Z","shell.execute_reply.started":"2025-10-28T19:31:30.972865Z","shell.execute_reply":"2025-10-28T19:31:36.906107Z"}},"outputs":[{"name":"stdout","text":"============================================================\nEVALUATING WITH TEST TIME AUGMENTATION\n============================================================\nApplying Test Time Augmentation with 5 augmentations per sample...\n","output_type":"stream"},{"name":"stderr","text":"TTA Testing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.48s/it]","output_type":"stream"},{"name":"stdout","text":"\nðŸŽ¯ Original Test Accuracy: 71.93%\nðŸš€ TTA Test Accuracy: 0.6663 (66.63%)\nðŸ“ˆ Improvement: +-5.30%\n\n============================================================\nTTA Classification Report:\n============================================================\n              precision    recall  f1-score   support\n\n     neutral      0.638     0.748     0.689       266\n       happy      0.608     0.614     0.611       280\n         sad      0.643     0.652     0.648       279\n       angry      0.804     0.761     0.782       280\n        fear      0.625     0.582     0.603       280\n     disgust      0.623     0.573     0.597       279\n    surprise      0.859     0.888     0.873        89\n\n    accuracy                          0.666      1753\n   macro avg      0.685     0.688     0.686      1753\nweighted avg      0.667     0.666     0.666      1753\n\n\n============================================================\nTTA Confusion Matrix:\n============================================================\n[[199  10  24   2   6  25   0]\n [ 20 172   7  22  32  22   5]\n [ 46   7 182   1  28  13   2]\n [  6  28   1 213  12  16   4]\n [ 11  39  42   7 163  18   0]\n [ 27  25  27  20  18 160   2]\n [  3   2   0   0   2   3  79]]\n\n============================================================\nTTA Per-Class Accuracy:\n============================================================\n  neutral   : 0.748 (74.8%) [â†“0.0%]\n  happy     : 0.614 (61.4%) [â†‘0.4%]\n  sad       : 0.652 (65.2%) [â†“0.0%]\n  angry     : 0.761 (76.1%) [â†“0.7%]\n  fear      : 0.582 (58.2%) [â†“0.0%]\n  disgust   : 0.573 (57.3%) [â†“0.4%]\n  surprise  : 0.888 (88.8%) [â†“0.0%]\n\nâœ… TTA Evaluation Complete!\nðŸ’¡ TTA typically improves accuracy by 0.5-2% without any retraining!\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":48},{"cell_type":"markdown","source":"# Memory Management Tips for Kaggle\n\n```python\n# Add these between cells if you run out of memory\nimport gc\ngc.collect()\ntorch.cuda.empty_cache()\n\n# Monitor GPU usage\n!nvidia-smi\n\n# Clear variables\ndel train_loader, val_loader  # After training\n```","metadata":{}}]}